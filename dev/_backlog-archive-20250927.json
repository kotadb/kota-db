[{"url":"https://api.github.com/repos/kotadb/kota-db/issues/717","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/717/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/717/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/717/events","html_url":"https://github.com/kotadb/kota-db/issues/717","id":3460511094,"node_id":"I_kwDOPFZ-b87OQzV2","number":717,"title":"Roadmap: close gap with Cursor on chunking, sync, and ranking","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9066998567,"node_id":"LA_kwDOPFZ-b88AAAACHG9rJw","url":"https://api.github.com/repos/kotadb/kota-db/labels/performance","name":"performance","color":"fbca04","default":false,"description":"Performance related issues"},{"id":9113577132,"node_id":"LA_kwDOPFZ-b88AAAACHzYmrA","url":"https://api.github.com/repos/kotadb/kota-db/labels/security","name":"security","color":"d73a4a","default":false,"description":"Security vulnerabilities and concerns"},{"id":9113577148,"node_id":"LA_kwDOPFZ-b88AAAACHzYmvA","url":"https://api.github.com/repos/kotadb/kota-db/labels/api","name":"api","color":"fbca04","default":false,"description":"API design and functionality issues"},{"id":9113577180,"node_id":"LA_kwDOPFZ-b88AAAACHzYm3A","url":"https://api.github.com/repos/kotadb/kota-db/labels/search","name":"search","color":"0e8a16","default":false,"description":"Search functionality related issues"},{"id":9117255530,"node_id":"LA_kwDOPFZ-b88AAAACH25Hag","url":"https://api.github.com/repos/kotadb/kota-db/labels/infrastructure","name":"infrastructure","color":"6c757d","default":false,"description":"Infrastructure and environment issues"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2025-09-27T16:40:21Z","updated_at":"2025-09-27T16:48:16Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\nWe are close on raw search speed and relationship graph fidelity, but compared to Cursor we lag in chunking, incremental sync, privacy hygiene, and default ranking quality. This issue tracks the full upgrade program to close that gap and deliver hybrid retrieval with first-class chunk metadata.\n\n## Current gaps vs Cursor\n- **Sources** – Git-only ingestion; no enrichment from PRs/issues/build logs.\n- **Chunking** – File-level indexing only; no AST-aware chunks or span IDs.\n- **Incremental sync** – SHA-per-file + webhook deltas; no Merkle/rename detection.\n- **Storage/privacy** – Hosted Postgres stores raw code + clear paths; no obfuscation or client hydration.\n- **Ranking** – Manual lexical/vector/symbol toggles; no default hybrid pipeline or reranker.\n- **Metadata** – Embeddings tied to whole documents; no per-chunk provenance.\n- **DX** – MCP/HTTP streaming is manual; no auto query-plan/context assembly.\n- **Scale proof** – No public data beyond our internal ~21k-symbol corpus.\n\n## High-leverage upgrades (must ship in order)\n- [ ] **AST-aware chunking + spans** – Emit per-symbol/per-block chunks with `{doc_id, span, lang, symbol_id?}` and overlapping sibling windows (≈180 LOC Rust, 150 TS/JS, 120 Python, ±20 LOC halo).\n- [ ] **Hybrid retrieval default** – Pipeline: lexical recall → vector prerank → cross-encoder rerank → span dedupe with lexical must-match guards.\n- [ ] **Span hydration API** – `POST /snippets` returning exact lines + commit SHA + provenance (`file:path:line`).\n- [ ] **Incremental sync v1.5** – Merkle/hash tree per chunk, rename detection via `git log --name-status` similarity, re-embed only changed chunks.\n- [ ] **Privacy hardening** – Server stores `{repo_id, chunk_id, hash, span, obf_path, lang, embedding}`; full code hydrated client-side. Salted path tokens for hosted UX.\n- [ ] **Reranker** – MiniLM-L6 (or equivalent) over top-16 spans; budget ≤30 ms @ P50 / 70 ms @ P95.\n- [ ] **Diff-aware retriever** – `POST /context/diff` to surface impacted callers/callees + spans for active changes.\n- [ ] **Evaluation harness** – Who-calls-X / definition / modification tasks; metrics: success@k, MRR, time-to-first-useful-span, token waste. Compare with/without graph & reranker.\n- [ ] **Latency & scale proof** – Publish cold/warm index + search/hydrate P50/P95 on ≥1 M LOC repo. Add vector quantization (PQ or HNSW shrink) and shard by `repo_id` for SaaS.\n\n## Key inputs already scoped\n- Chunk size policy per language and existing symbol spans (tree-sitter already returns start/end line+column).\n- Hosted SaaS hydration is feasible but requires new ingestion flow and backwards-compatible Supabase migration.\n- Storage growth estimate: ≈7 KB per chunk (~4.2 MB per 100 k LOC) for embeddings+metadata; <100 MB for 1 M LOC.\n- Reranker budget: keep cross-encoder under 30 ms (P50) / 70 ms (P95) per query.\n- Rename detection target: ≥95 % true-positive, ≤5 % FN, ≤1 % FP (rename+edit falls back to “modified+move”).\n- Path obfuscation blockers: CLI/MCP rely on readable paths; need reversible client-held map or salted tokens to avoid breaking UX.\n\n## Success metrics\n- Hybrid search success@5 ≥ Cursor benchmark; MRR +15 % vs today on internal eval set.\n- Incremental reindex <10 s for 5 k-file repo with heavy rename; <5 % redundant chunk re-embeds.\n- Hosted mode retains <10 MB / 100 k LOC server storage while preserving UX via obfuscated paths.\n- Published 1 M LOC latency numbers: search P95 <150 ms, snippet hydrate P95 <120 ms.\n\n## Labels & owners\n- Primary: search, performance, api, security, infrastructure, priority-medium.\n- Leads: @jayminwest for infra/privacy, @agent-team for retriever/reranker, @mcp-integrations for DX.\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/717/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/717/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/716","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/716/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/716/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/716/events","html_url":"https://github.com/kotadb/kota-db/issues/716","id":3460471646,"node_id":"I_kwDOPFZ-b87OQpte","number":716,"title":"Stabilize core engine durability and scalability","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998567,"node_id":"LA_kwDOPFZ-b88AAAACHG9rJw","url":"https://api.github.com/repos/kotadb/kota-db/labels/performance","name":"performance","color":"fbca04","default":false,"description":"Performance related issues"},{"id":9067347045,"node_id":"LA_kwDOPFZ-b88AAAACHHS8ZQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/rust","name":"rust","color":"000000","default":false,"description":"Pull requests that update rust code"},{"id":9113577109,"node_id":"LA_kwDOPFZ-b88AAAACHzYmlQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/data-integrity","name":"data-integrity","color":"b60205","default":false,"description":"Issues affecting data integrity"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-27T16:00:07Z","updated_at":"2025-09-27T16:00:07Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n- Primary index WAL isn\\'t used and lazy-load races can fail startup under load.\n- Native graph storage writes aren\\'t crash-safe and hybrid deletes don\\'t prune graph nodes.\n- Vector index and primary index still do linear scans, so search won\\'t scale.\n\n## Recommended Actions\n1. Wire WAL writes and recovery for primary index insert/delete paths and remove the one-shot lazy-load timeout.\n2. Persist graph node/edge writes and delete graph entries when documents vanish.\n3. Implement incremental persistence or true HNSW traversal so semantic search and wildcard queries don\\'t walk the entire dataset on every request.\n\n## Notes\nRef: internal engine review.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/716/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/716/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/715","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/715/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/715/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/715/events","html_url":"https://github.com/kotadb/kota-db/issues/715","id":3459727309,"node_id":"I_kwDOPFZ-b87ONz_N","number":715,"title":"Codex integration insights: fuzzy filename search vs KotaDB and local sync feed","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998489,"node_id":"LA_kwDOPFZ-b88AAAACHG9q2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/mcp","name":"mcp","color":"0052cc","default":false,"description":"Model Context Protocol related"},{"id":9113577180,"node_id":"LA_kwDOPFZ-b88AAAACHzYm3A","url":"https://api.github.com/repos/kotadb/kota-db/labels/search","name":"search","color":"0e8a16","default":false,"description":"Search functionality related issues"},{"id":9136360593,"node_id":"LA_kwDOPFZ-b88AAAACIJHMkQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/integration","name":"integration","color":"1d76db","default":false,"description":"Integration issues between system components"},{"id":9175575816,"node_id":"LA_kwDOPFZ-b88AAAACIugtCA","url":"https://api.github.com/repos/kotadb/kota-db/labels/agent-experience","name":"agent-experience","color":"6f42c1","default":false,"description":"Issues affecting agent/LLM interaction patterns and workflows"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-27T04:33:51Z","updated_at":"2025-09-27T04:38:57Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Context\nI'm experimenting with Codex and wanted to document how it currently handles search/indexing, where KotaDB could slot in as an MCP tool, and an idea for keeping KotaDB in sync with an active workspace.\n\n### Current Codex Search Pipeline\n1. The Rust TUI watches for search trigger tokens (for example `search:` markers) and, after each edit, invokes a debounced fuzzy-search helper.\n2. That helper walks the working tree with `ignore::WalkBuilder` (the same walker used by ripgrep), applies `.gitignore`/`.ignore` exclusion rules, and keeps only the top *N* hits in memory.\n3. Ranking relies on the `skim` crate's fzf-style fuzzy score over path strings and can optionally return character indices for highlighting.\n4. There is no persistent index, no on-disk storage, and no content or metadata awareness; every lookup re-scans the directory tree.\n\n### Where KotaDB Would Help Codex\n- Provide fast **content search** (wildcards + trigram) so the agent can find references, usages, or docs—not just filenames.\n- Enable **tag- or metadata-filtered** queries when repos add annotations (e.g. ownership or component labels).\n- Supply **semantic search** and Reciprocal Rank Fusion results for intent-driven prompts.\n- Return full document payloads (bytes + metadata) in a single call so the agent can reason without extra shell commands.\n\n### Where KotaDB Is Overkill\n- The inline filename popup thrives on near-zero latency and tiny payloads; keeping the fuzzy helper in-process still feels right for that experience.\n- Putting KotaDB into that loop would add network hops, require continuous indexing, and complicate simple filename completion without a clear win.\n\n### Suggested Integration Approach\n- Treat KotaDB as an MCP tool that Codex calls for **content** and **semantic** lookups while the existing fuzzy helper keeps handling quick filename hints.\n- Use the SaaS deployment as the durable index, but pair it with an **optional local daemon**. The daemon would watch the repo (file watcher and/or git events), batch and compress updates, then push them to KotaDB over a persistent channel (WebSocket/gRPC).\n- When offline, the daemon could queue changes or maintain a lightweight local index, replaying the feed once connectivity returns.\n- This hybrid keeps cloud-powered search features while ensuring Codex can see uncommitted edits immediately—crucial for interactive coding sessions.\n\n### Questions / Follow-Ups\n1. Would a documented streaming ingestion endpoint fit into KotaDB's roadmap?\n2. How should the daemon negotiate match thresholds or embedding refreshes to avoid thrashing on large repos?\n3. Are there plans for client libraries or SDKs that could wrap this synchronization feed pattern?\n\nHappy to expand on any of the Codex-side requirements if it helps planning. Thanks for building such a powerful search stack!\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/715/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/715/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/714","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/714/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/714/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/714/events","html_url":"https://github.com/kotadb/kota-db/issues/714","id":3458574456,"node_id":"I_kwDOPFZ-b87OJah4","number":714,"title":"feat: Implement SaaS provisioning API endpoint","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9066998313,"node_id":"LA_kwDOPFZ-b88AAAACHG9qKQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/high-priority","name":"high-priority","color":"d73a4a","default":false,"description":"High priority issues that need immediate attention"},{"id":9113577148,"node_id":"LA_kwDOPFZ-b88AAAACHzYmvA","url":"https://api.github.com/repos/kotadb/kota-db/labels/api","name":"api","color":"fbca04","default":false,"description":"API design and functionality issues"},{"id":9117255530,"node_id":"LA_kwDOPFZ-b88AAAACH25Hag","url":"https://api.github.com/repos/kotadb/kota-db/labels/infrastructure","name":"infrastructure","color":"6c757d","default":false,"description":"Infrastructure and environment issues"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-26T17:51:04Z","updated_at":"2025-09-26T17:51:40Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Goal\nBuild a backend-only provisioning endpoint on the Fly.io API service that finalizes tenant setup after Stripe checkout.\n\n## Why\nThe SaaS dashboard currently fakes provisioning by inserting repositories and API keys directly from the client using Supabase anon credentials. For launch we need a backend-controlled flow that owns secret management, indexing jobs, and status updates.\n\n## Scope\n- Expose a secured HTTP endpoint (e.g. POST /internal/provision) that accepts Stripe session metadata (session_id, plan, email, etc.).\n- Validate the Stripe session using the secret key and derive the tenant/user identifiers.\n- Create or update Supabase records using the service-role key: user metadata, repositories placeholder, API keys (generated server-side), quotas.\n- Schedule initial indexing jobs and enqueue webhook registration tasks as needed.\n- Return a provisioning status payload the dashboard can poll. Persist status in Supabase so the frontend can show progress via existing queries.\n- Enforce idempotency (safe to retry with the same session_id).\n\n## Dependencies / References\n- Stripe checkout + webhook flow added in #706/#707.\n- Supabase schema additions tracked in #711 (repositories.sync_state, indexing_job_events, etc.).\n- Frontend onboarding doc (:warning: update once API ships) describes the desired call.\n\n## Acceptance Criteria\n- Client onboarding flow calls the new endpoint instead of writing Supabase directly.\n- Newly provisioned tenants receive backend-generated API keys and a queued indexing job without using anon credentials.\n- Dashboard reflects the backend-managed status fields after the endpoint runs.\n- Documentation updated to describe the final flow and remove the “client-side provisional” warnings.\n],timeout_ms:120000,","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/714/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/714/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/713","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/713/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/713/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/713/events","html_url":"https://github.com/kotadb/kota-db/issues/713","id":3458574045,"node_id":"I_kwDOPFZ-b87OJabd","number":713,"title":"feat: Implement SaaS provisioning API endpoint","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-26T17:50:52Z","updated_at":"2025-09-26T17:50:52Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Goal\nBuild a backend-only provisioning endpoint on the Fly.io API service that finalizes tenant setup after Stripe checkout.\n\n## Why\nThe SaaS dashboard currently fakes provisioning by inserting repositories and API keys directly from the client using Supabase anon credentials. For launch we need a backend-controlled flow that owns secret management, indexing jobs, and status updates.\n\n## Scope\n- Expose a secured HTTP endpoint (e.g. POST /internal/provision) that accepts Stripe session metadata (session_id, plan, email, etc.).\n- Validate the Stripe session using the secret key and derive the tenant/user identifiers.\n- Create or update Supabase records using the service-role key: user metadata, repositories placeholder, API keys (generated server-side), quotas.\n- Schedule initial indexing jobs and enqueue webhook registration tasks as needed.\n- Return a provisioning status payload the dashboard can poll. Persist status in Supabase so the frontend can show progress via existing queries.\n- Enforce idempotency (safe to retry with the same session_id).\n\n## Dependencies / References\n- Stripe checkout + webhook flow added in #706/#707.\n- Supabase schema additions tracked in #711 (repositories.sync_state, indexing_job_events, etc.).\n- Frontend onboarding doc () describes the desired call.\n\n## Acceptance Criteria\n- Client onboarding flow calls the new endpoint instead of writing Supabase directly.\n- Newly provisioned tenants receive backend-generated API keys and a queued indexing job without using anon credentials.\n- Dashboard reflects the backend-managed status fields after the endpoint runs.\n- Update documentation to describe the final flow and remove the “client-side provisional” warnings.\n],","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/713/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/713/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/712","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/712/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/712/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/712/events","html_url":"https://github.com/kotadb/kota-db/issues/712","id":3455346724,"node_id":"I_kwDOPFZ-b87N9Ggk","number":712,"title":"Add preview environment smoke test automation","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998984,"node_id":"LA_kwDOPFZ-b88AAAACHG9syA","url":"https://api.github.com/repos/kotadb/kota-db/labels/tests","name":"tests","color":"c2e0c6","default":false,"description":"Testing related"},{"id":9117255530,"node_id":"LA_kwDOPFZ-b88AAAACH25Hag","url":"https://api.github.com/repos/kotadb/kota-db/labels/infrastructure","name":"infrastructure","color":"6c757d","default":false,"description":"Infrastructure and environment issues"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-25T23:45:23Z","updated_at":"2025-09-25T23:45:55Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\nWe now have a working preview deployment flow but no automated smoke coverage to validate that the preview instance is usable. Let’s wire up a lightweight suite that reuses the existing SaaS smoke tooling and end-to-end flows so every preview deployment is verified before manual review.\n\n## Background / Motivation\n- `scripts/saas_smoke.sh` already performs health, repository listing, and MCP checks against staging/production.\n- `docs/FLY_DEPLOYMENT.md` documents those checks, but the preview flow does not run them yet.\n- End-to-end CLI tests (`tests/e2e/test_codebase_analysis_journey.rs`) and the Supabase repository lifecycle smoke (`tests/supabase_repository_store_test.rs`) show the core user journey and database expectations we want to cover remotely.\n- With limited solo bandwidth (~20 hrs/week) we should avoid maintaining a separate harness repo; extending the existing tooling keeps maintenance friction low.\n\n## Goals\n- Automatically validate each preview deployment (health, Supabase connectivity, authenticated repo listing, MCP endpoints, and key search/analysis flows).\n- Keep the suite fast (<5 minutes) and deterministic so it can guard preview promotion.\n- Document how to run/debug the preview smoke locally using the same script.\n\n## Proposed Approach\n1. **Script consolidation**: Promote `scripts/saas_smoke.sh` to a generic smoke driver that accepts preview URLs/API keys and optionally triggers extended checks (search, callers, impact) by calling the HTTP endpoints exposed in `src/services_http_server.rs`.\n2. **Helper extraction**: Factor any repeated API-call logic from the CLI E2E tests into shared helpers (Rust or shell) so the smoke script can reuse the same expectations (success + latency thresholds).\n3. **CI wiring**: Add a preview-specific job to the deployment workflow (or a new workflow triggered on preview-ready events) that injects preview credentials/seeds and runs `just preview-smoke` (wrapper command).\n4. **State seeding**: Ensure the preview Supabase instance has a deterministic test tenant/repository (seed migration or internal endpoint) before the smoke runs, so searches and impact analysis return data.\n5. **Reporting**: Surface results back to the PR (GitHub deployment status, job summary, or comment) including response times and any failing endpoint payloads for quick triage.\n\n## Work Items\n- [ ] Refactor/extend `scripts/saas_smoke.sh` for preview compatibility and additional endpoint checks.\n- [ ] Introduce a `just preview-smoke` command (and docs) that wraps the script with required env vars.\n- [ ] Extract reusable HTTP helpers from existing tests or create a small Rust/TypeScript client to share assertions.\n- [ ] Update the preview deployment workflow to seed preview data and invoke the smoke command with appropriate secrets.\n- [ ] Capture run output as an artifact or PR comment for debugging.\n- [ ] Document the preview smoke flow in `docs/FLY_DEPLOYMENT.md` (or a new preview-specific doc) with instructions for local runs.\n\n## Acceptance Criteria\n- Every preview deployment runs the smoke suite automatically and fails the preview status if any check fails.\n- Suite covers: `/health`, Supabase metrics, authenticated `/api/v1/repositories`, `/api/v1/search/code`, `/api/v1/search/symbols`, `/api/v1/find-callers`, `/api/v1/analyze-impact`, and optional MCP probes when an API key is available.\n- Execution finishes within ~5 minutes and produces actionable logs when failures occur.\n- Documentation explains how to run the same checks locally against a preview/staging instance.\n\n## Risks / Open Questions\n- Need a deterministic dataset in preview to make search/impact checks meaningful—decide between seeded fixtures vs. a lightweight onboarding API.\n- Confirm how preview URLs/API keys are generated and surfaced to the workflow.\n- Determine whether the smoke should block merge or simply gate promotion to staging/production.\n\n## References\n- `scripts/saas_smoke.sh`\n- `docs/FLY_DEPLOYMENT.md`\n- `tests/e2e/test_codebase_analysis_journey.rs`\n- `tests/supabase_repository_store_test.rs`\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/712/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/712/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/711","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/711/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/711/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/711/events","html_url":"https://github.com/kotadb/kota-db/issues/711","id":3455212397,"node_id":"I_kwDOPFZ-b87N8ltt","number":711,"title":"Staging job worker stalls after repository registration","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998313,"node_id":"LA_kwDOPFZ-b88AAAACHG9qKQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/high-priority","name":"high-priority","color":"d73a4a","default":false,"description":"High priority issues that need immediate attention"},{"id":9117255530,"node_id":"LA_kwDOPFZ-b88AAAACH25Hag","url":"https://api.github.com/repos/kotadb/kota-db/labels/infrastructure","name":"infrastructure","color":"6c757d","default":false,"description":"Infrastructure and environment issues"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2025-09-25T22:13:31Z","updated_at":"2025-09-25T22:39:54Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\nWhile validating the SaaS staging walkthrough I switched the Fly deployment to the direct Supabase Postgres endpoint and finished the initial environment bring-up, but the Supabase job worker now leaves indexing jobs in  and never emits completion events.\n\n## Work completed\n- Pointed  at the direct Postgres endpoint () to avoid pgBouncer prepared-statement issues and redeployed staging.\n- Set  in staging so auth middleware will proceed while we debug the DB connection behaviour.\n- Generated a new staging API key () tied to a fresh Supabase user and verified ℹ️  Checking https://kotadb-api-staging.fly.dev/health\nSupabase status: ok\nSupabase latency: 3 ms\nQueued jobs: 0\nFailed jobs (last hour): 0\n⚠️  Skipping authenticated checks (no API key provided) succeeds.\n- Found staging was missing the  table; applied the  migration against the direct database so  no longer fails to persist webhook secrets.\n- Registered  via  and confirmed job  is enqueued with status .\n\n## What’s still blocking\n- The Supabase job worker never progresses past the initial  event—no clone directory is created under , no  event, and  stays on  indefinitely.\n- Worker logs only show the SQL polling () but no downstream logging from , which suggests the clone/index step might be missing prerequisites (e.g., usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system. binary) or failing silently before it can record an event.\n\n## Next steps\n1. Inspect the Fly VM for worker prerequisites: verify the runtime image includes git and other tooling needed by .\n2. Add temporary trace logging (or capture stderr) around  /  so we can see why the job never records completion.\n3. Once a job completes, re-run the staging walkthrough (repo registration → job status → webhook smoke) and document the final checklist for #709.\n\n## References\n- Job ID: \n- Repository ID: \n- Staging API key ID: \n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/711/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/711/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/710","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/710/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/710/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/710/events","html_url":"https://github.com/kotadb/kota-db/issues/710","id":3451213648,"node_id":"I_kwDOPFZ-b87NtVdQ","number":710,"title":"Document frontend integration: Next.js + Supabase + Stripe","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-24T22:45:15Z","updated_at":"2025-09-24T22:45:15Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\nWe need a guide for wiring the hosted KotaDB backend into the upcoming Next.js frontend. The frontend will run on Cloudflare, share the Supabase project with the SaaS API, and manage Stripe-enabled subscriptions.\n\n## Scope\n- Connection flow from the Next.js app to the KotaDB SaaS API (authentication via Supabase, API key management, rate limits).\n- How the frontend shares Supabase tables (auth, repositories, indexing jobs, token usage) with the backend safely.\n- Stripe subscription flow: plan/price mapping, webhooks, provisioning API keys/repositories on successful payment.\n- Deployment considerations (Cloudflare worker/pages environment, secret management, staging vs production).\n- Sample environment configuration and architecture diagrams.\n\n## Deliverables\n- A doc in `docs/` covering architecture, env setup, and end-to-end flow.\n- Checklist for spinning up a new environment (linking Supabase, Fly, Cloudflare, Stripe).\n\n(Blocks frontend kickoff)\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/710/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/710/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/709","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/709/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/709/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/709/events","html_url":"https://github.com/kotadb/kota-db/issues/709","id":3451213442,"node_id":"I_kwDOPFZ-b87NtVaC","number":709,"title":"Stage SaaS environment walkthrough","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-24T22:45:07Z","updated_at":"2025-09-24T22:45:07Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Goal\nBefore inviting more users to staging we should run a scripted walkthrough of the Supabase SaaS environment (repo registration, webhook flow, job status, search) against the deployed API.\n\n## Why\n- `/health` currently reports `supabase_status: error`; we need to confirm secrets/networking are correct and the worker can talk to Supabase.\n- A guided run-through will validate the registration + webhook + indexing + MCP surfacing path end-to-end on real infrastructure, not just in tests.\n\n## Tasks\n- [ ] Verify Supabase connectivity on staging (check Fly logs, secrets, database URL, service key).\n- [ ] Exercise repository registration with a staging API key and confirm job lifecycle in Supabase.\n- [ ] Trigger a webhook payload and inspect incremental indexing behavior.\n- [ ] Document the steps/assertions so we can repeat after future deploys.\n\n(Refs: #706, #708)\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/709/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/709/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/708","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/708/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/708/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/708/events","html_url":"https://github.com/kotadb/kota-db/issues/708","id":3451202297,"node_id":"I_kwDOPFZ-b87NtSr5","number":708,"title":"Follow-up on #706: finalize Supabase SaaS launch instrumentation","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-24T22:38:30Z","updated_at":"2025-09-24T22:38:30Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\nIssue #706 and PR #707 got us to a functional Supabase-backed SaaS flow, but two gaps remain before we can check off the full launch readiness scope:\n\n- `token_usage` records are never written today, so quotas, usage dashboards, and alerting can’t rely on Supabase data yet.\n- MCP validation on staging stops at simple smoke checks. We still need a scripted end-to-end (repo registration → job status → query) to prove hosted MCP parity and prevent regressions.\n\n## Why\nThese were explicitly called out in the #706 acceptance criteria as launch requirements. Leaving them open means we can’t enforce tenant limits or guarantee MCP agents can self-serve on the hosted API without manual babysitting.\n\n## Requested follow-up\n- [ ] Persist token usage information into Supabase for hosted API requests (and backfill if needed).\n- [ ] Extend MCP staging verification to cover repo onboarding, job tracking, and search queries against the Supabase-backed data (ideally via automated smoke).\n\n—\nContext: #706, PR #707\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/708/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/708/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/690","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/690/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/690/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/690/events","html_url":"https://github.com/kotadb/kota-db/issues/690","id":3431455635,"node_id":"I_kwDOPFZ-b87Mh9uT","number":690,"title":"Verify preview pipeline: GitHub ↔ Supabase ↔ Fly.io ↔ Cloudflare","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9117255494,"node_id":"LA_kwDOPFZ-b88AAAACH25HRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/ci/cd","name":"ci/cd","color":"ffd33d","default":false,"description":"Continuous Integration/Deployment issues"},{"id":9117255530,"node_id":"LA_kwDOPFZ-b88AAAACH25Hag","url":"https://api.github.com/repos/kotadb/kota-db/labels/infrastructure","name":"infrastructure","color":"6c757d","default":false,"description":"Infrastructure and environment issues"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-18T18:13:12Z","updated_at":"2025-09-18T18:13:12Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n- Comprehensive integration test to ensure GitHub (CI/CD), Supabase preview branch, Fly.io deploy previews, and Cloudflare DNS/edge routing all work together.\n\n## Why\n- We’re building a canonical preview environment template so that production can be cloned from a known-good setup.\n- Need confidence that deploying from develop → preview hits all services end-to-end (code -> migrations -> deploy -> DNS).\n\n## Acceptance Criteria\n- [ ] Document current pipeline flow (GitHub Actions, Supabase branch, Fly preview app, Cloudflare config).\n- [ ] Run a dry-run or sample deploy verifying API connectivity, migrations, and DNS resolution.\n- [ ] Capture any blockers or missing configuration.\n- [ ] Produce checklist for repeated preview setups / future prod cutover.\n\n## Notes\n- Use repo `develop` branch + Supabase preview `ayqyjipagotnvvdflclu` (current staged env).\n- Confirm secrets (Supabase keys, Fly tokens, Cloudflare API keys) are scoped & available.\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/690/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/690/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/684","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/684/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/684/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/684/events","html_url":"https://github.com/kotadb/kota-db/issues/684","id":3430765815,"node_id":"I_kwDOPFZ-b87MfVT3","number":684,"title":"Post-launch plan for production embeddings","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9113577180,"node_id":"LA_kwDOPFZ-b88AAAACHzYm3A","url":"https://api.github.com/repos/kotadb/kota-db/labels/search","name":"search","color":"0e8a16","default":false,"description":"Search functionality related issues"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-18T14:57:55Z","updated_at":"2025-09-18T14:57:55Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Background\nThe embeddings architecture landed in #33 / #165 with pluggable providers, but the local ONNX pathway still short-circuits with roadmap messaging and the HTTP surface routes semantic requests onto text search fallbacks. Now that launch is behind us, we should finish the implementation work so semantic search becomes a first-class capability instead of a stub.\n\n## What needs to happen\n- Deliver a functional local embedding pipeline (either finalize ONNX Runtime 2.0 integration or adopt a stop-gap inference backend) so  stops erroring.\n- Revisit the default  so out-of-the-box setups pick a working provider (likely OpenAI) until local inference is confirmed production-ready.\n- Wire the semantic/hybrid search endpoints to , including configuration plumbing and operational toggles.\n- Add guardrails around the in-memory embedding cache (eviction policy, metrics) so production workloads stay healthy.\n- Benchmark the vector index path and decide whether to keep the linear scan or land a proper HNSW traversal before GA.\n\n## Non-goals\n- Broader search ranking improvements or new query languages—this should stay focused on getting embeddings to production quality.\n\n## Definition of done\n- Local and managed providers both pass integration tests under .\n- HTTP semantic and hybrid endpoints return embedding-backed results when the feature flag is enabled.\n- Operational docs updated with provider setup instructions and rollout considerations.\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/684/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/684/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/683","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/683/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/683/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/683/events","html_url":"https://github.com/kotadb/kota-db/issues/683","id":3428488923,"node_id":"I_kwDOPFZ-b87MWpbb","number":683,"title":"feat: Multiagent coordination layer for parallel AI development","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-18T03:19:14Z","updated_at":"2025-09-18T03:19:14Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Problem Statement\nDevelopers are starting to run multiple AI coding agents (Claude Code, Codex, etc.) in parallel, but these agents are blind to each other's activities. This leads to:\n- Merge conflicts when agents modify the same files\n- Redundant work on the same problems\n- Wasted compute on conflicting changes\n- No visibility into what each agent is doing\n\n## Proposed Solution\nKotaDB becomes the coordination layer for multiagent development - providing real-time awareness and orchestration.\n\n## Core Features\n- **Symbol-level locking**: Agents claim symbols before modification, preventing conflicts\n- **Activity broadcasting**: All agents see what others are working on in real-time\n- **Task boundaries**: Define which modules/files each agent can touch\n- **Dependency awareness**: Agents automatically wait when their work depends on others\n- **Collision detection**: Warn before agents converge on the same code\n\n## Value Proposition\nAs AI agent usage scales from 1 to N agents per developer, coordination becomes critical. KotaDB positions itself as essential infrastructure for the multiagent development paradigm - making parallel agent execution actually cheaper and more effective than single agent usage.\n\n## Success Metrics\n- Zero merge conflicts in multiagent sessions\n- Reduced total compute time through better task distribution\n- Clear visibility into all agent activities\n- Automatic prevention of redundant work\n\nThis positions KotaDB for the coming wave where developers orchestrate agent swarms rather than writing code directly.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/683/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/683/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/682","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/682/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/682/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/682/events","html_url":"https://github.com/kotadb/kota-db/issues/682","id":3428469510,"node_id":"I_kwDOPFZ-b87MWksG","number":682,"title":"feat: Symbol Intelligence System - Deep numerical analysis for proactive agent decision-making","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-18T03:06:55Z","updated_at":"2025-09-18T03:06:55Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Overview\nTransform KotaDB from reactive code search to proactive codebase intelligence for autonomous coding agents. Provide rich statistical analysis of symbols and relationships to enable agents to make informed decisions BEFORE modifying code.\n\n## Core Vision\nKotaDB becomes the situational awareness layer for AI agents - not \"what changed in this PR\" but \"what will break if I touch this function?\"\n\n## Proposed Symbol Intelligence Schema\n```\n{\n  symbol: \"function_name\",\n  \n  // Network metrics\n  direct_callers: 12,\n  transitive_dependents: 129,\n  depth_from_entry: 3,\n  centrality_score: 0.89,\n  \n  // Risk metrics  \n  change_frequency: 47,\n  change_volatility: 0.73,\n  blast_radius: \"high\",\n  coupling_score: 0.81,\n  \n  // Temporal metrics\n  last_modified: { date, pr, author },\n  age_days: 234,\n  staleness_score: 0.2,\n  churn_rate: 0.15,\n  \n  // Complexity metrics\n  cyclomatic_complexity: 12,\n  cognitive_complexity: 18,\n  line_count: 145,\n  test_coverage: 0.67,\n  \n  // Team metrics\n  primary_authors: [\"dev1:0.6\", \"dev2:0.3\"],\n  knowledge_concentration: 0.6,\n  review_frequency: \"low\",\n  \n  // Architecture position\n  layer: \"business_logic\",\n  module_boundary_crossings: 4,\n  abstraction_level: \"concrete\"\n}\n```\n\n## Agent Use Cases\n- \"I need to refactor processPayment - what's the risk score?\"\n- \"Where are the landmines in this module?\"\n- \"What symbols are safe to modify without human review?\"\n- \"What's the criticality path through this feature?\"\n\n## Implementation Ideas\n1. Historical analysis engine - learn from git history patterns\n2. Predictive impact scoring - \"changing this has 73% chance of breaking tests\"\n3. Symbol health scores - combine coverage, complexity, coupling\n4. Relationship quality metrics - not just \"A calls B\" but HOW (tight_coupling, brittle_interface, etc)\n\n## Success Metrics\n- Agents can autonomously decide when to request human review\n- Reduced production breaks from automated refactors\n- Faster agent execution on \"safe\" code paths\n- Quantifiable risk assessment before changes\n\n## Next Steps\n- Define comprehensive metrics list\n- Design data collection pipeline\n- Build predictive models from historical data\n- Create agent-friendly query interface\n\nThis positions KotaDB as essential infrastructure for the coming wave of autonomous coding agents - giving them the spatial awareness they need to work safely and effectively in complex codebases.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/682/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/682/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/681","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/681/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/681/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/681/events","html_url":"https://github.com/kotadb/kota-db/issues/681","id":3428000817,"node_id":"I_kwDOPFZ-b87MUyQx","number":681,"title":"[CI] Investigate failing stress and performance tests","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2025-09-17T22:46:12Z","updated_at":"2025-09-18T02:30:00Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\nFull-suite run (`just test` / `cargo nextest run --all --no-fail-fast`) is currently failing on `develop`.\n\n## Failing tests\n- `tests/code_analysis_integration_test.rs::test_edge_cases`\n- `tests/concurrent_stress_test.rs::test_enhanced_concurrent_stress`\n- `tests/concurrent_stress_test.rs::test_lock_contention_analysis`\n- `tests/e2e_integration_test.rs::test_codebase_analysis_journey::test_error_recovery_scenarios`\n- `tests/performance_regression_test.rs::test_search_performance_regression`\n- `tests/write_performance_test.rs::test_write_performance_consistency`\n\nInitial run also surfaced:\n- `tests/performance_regression_test.rs::test_performance_stability`\n- `tests/relationship_query_pipeline_test.rs::test_no_mocking_verification`\n- `tests/graph_storage_test.rs::test_batch_operations`\n\n## Reproduction\n```bash\njust test\n# or\ncargo nextest run --all --no-fail-fast\n```\n\n## Notes\n`just test-fast` still passes. Need to stabilize these integration/perf suites or adjust gating to avoid blocking future releases.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/681/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/681/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/679","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/679/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/679/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/679/events","html_url":"https://github.com/kotadb/kota-db/issues/679","id":3427904183,"node_id":"I_kwDOPFZ-b87MUaq3","number":679,"title":"feat: GitHub App deployment readiness for SaaS indexing","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9117255530,"node_id":"LA_kwDOPFZ-b88AAAACH25Hag","url":"https://api.github.com/repos/kotadb/kota-db/labels/infrastructure","name":"infrastructure","color":"6c757d","default":false,"description":"Infrastructure and environment issues"},{"id":9118359020,"node_id":"LA_kwDOPFZ-b88AAAACH38d7A","url":"https://api.github.com/repos/kotadb/kota-db/labels/git-integration","name":"git-integration","color":"0366d6","default":false,"description":"Git repository and version control features"},{"id":9118359026,"node_id":"LA_kwDOPFZ-b88AAAACH38d8g","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-large","name":"effort-large","color":"f85149","default":false,"description":"Large effort - more than 3 days"},{"id":9124823878,"node_id":"LA_kwDOPFZ-b88AAAACH-HDRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/feature","name":"feature","color":"0075ca","default":false,"description":"Major new feature implementation"},{"id":9167968495,"node_id":"LA_kwDOPFZ-b88AAAACInQY7w","url":"https://api.github.com/repos/kotadb/kota-db/labels/production-readiness","name":"production-readiness","color":"d93f0b","default":false,"description":"Production deployment readiness items"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-17T21:55:26Z","updated_at":"2025-09-17T21:55:26Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Background\nThe SaaS API can deploy automatically via CI, but the GitHub App vision (auto-indexing via webhook-triggered git clones) requires additional infrastructure. Today the Fly app has no persistent storage, secret management for GitHub/Stripe keys, or webhook/job orchestration.\n\n## Problem\nEven with automated deploys, the staging/prod instances lose state on redeploy, lack verified webhook endpoints, and can’t run background clone/index jobs reliably. This blocks the GitHub App play (auto re-indexing with per-repo billing).\n\n## Requirements\n- Provision Fly volumes (or equivalent) for repo working trees and job metadata with automated attachment during deploy.\n- Extend deployment configs to manage secrets (GitHub App private key, Stripe keys, Supabase creds) securely.\n- Introduce a webhook handler service/process with signature verification, replay protection, and queuing for `push` events.\n- Add durable background job execution (clone/fetch + IndexingService) with retries, logging, and status persistence.\n- Wire health/observability: logs, metrics, alerts for failed clones, webhook errors, rate limits.\n- Document deployment runbook (CI pipeline, rollback, volume management, secret rotation).\n\n## Acceptance Criteria\n- CI deploy attaches required volumes and preserves indexed repos across releases.\n- Webhooks from the GitHub App can be received, verified, and enqueue indexing jobs without manual steps.\n- Background worker runs in the deployment, with status surfaced via `/api/v1/index/status` and logs.\n- Secrets are provisioned through Fly (or external secret manager) and referenced without hardcoding.\n- Observability dashboards (logs/metrics) and alerts cover webhook failures and job errors.\n- Runbook describes end-to-end deployment and recovery (including rollback).\n\n## Notes\n- Payments/API-key provisioning handled by the separate web app repo, but this service must expose the webhook/job endpoints and persistent storage.\n- Consider isolating webhook handling as a separate minimal Fly machine if needed for scaling.\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/679/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/679/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/678","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/678/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/678/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/678/events","html_url":"https://github.com/kotadb/kota-db/issues/678","id":3427878669,"node_id":"I_kwDOPFZ-b87MUUcN","number":678,"title":"feat: Enable git-based indexing for SaaS API","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9113577148,"node_id":"LA_kwDOPFZ-b88AAAACHzYmvA","url":"https://api.github.com/repos/kotadb/kota-db/labels/api","name":"api","color":"fbca04","default":false,"description":"API design and functionality issues"},{"id":9117255530,"node_id":"LA_kwDOPFZ-b88AAAACH25Hag","url":"https://api.github.com/repos/kotadb/kota-db/labels/infrastructure","name":"infrastructure","color":"6c757d","default":false,"description":"Infrastructure and environment issues"},{"id":9118359020,"node_id":"LA_kwDOPFZ-b88AAAACH38d7A","url":"https://api.github.com/repos/kotadb/kota-db/labels/git-integration","name":"git-integration","color":"0366d6","default":false,"description":"Git repository and version control features"},{"id":9118359026,"node_id":"LA_kwDOPFZ-b88AAAACH38d8g","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-large","name":"effort-large","color":"f85149","default":false,"description":"Large effort - more than 3 days"},{"id":9124823878,"node_id":"LA_kwDOPFZ-b88AAAACH-HDRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/feature","name":"feature","color":"0075ca","default":false,"description":"Major new feature implementation"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-17T21:41:32Z","updated_at":"2025-09-17T21:41:32Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Background\nStaging SaaS deployment currently exposes the services API but indexing requires a path that exists on the Fly.io filesystem. `git_url` requests are rejected, so no repositories can be indexed remotely.\n\n## Problem\nCustomers using the hosted API cannot index code because they cannot provide a local path. `POST /api/v1/repositories` needs to accept git metadata, manage clones/fetches, and trigger indexing jobs inside the deployment.\n\n## Proposal\n- Allow repository registration payloads to include `git_url`, optional `branch`/`commit`, and authentication hints.\n- Provision managed working directories on the SaaS server (backed by a Fly volume) and clone/fetch before invoking `IndexingService`.\n- Persist repo metadata and reuse existing job registry to track clone/index progress plus errors.\n- Enforce limits (repo size, allowed branches, concurrency) and surface actionable failures via `/api/v1/index/status`.\n- Optionally add scheduled refresh to `git fetch` + reindex and document the flow.\n\n## Acceptance Criteria\n- SaaS POST `/api/v1/repositories` with `git_url` + `branch` starts a job that clones and indexes a public repo.\n- Successful job populates symbols so `/api/v1/search/*` endpoints return matches.\n- Repository metadata includes git source info in `/api/v1/repositories`.\n- Errors for missing refs, auth failures, or size limits are returned as `StandardApiError`.\n\n## Open Questions\n- Where to store credentials for private repos (Supabase, Fly secrets, other)?\n- How aggressively should we prune working directories vs. reuse for incremental indexing?\n- Do we need per-repo concurrency controls beyond the existing job queue?","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/678/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/678/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/677","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/677/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/677/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/677/events","html_url":"https://github.com/kotadb/kota-db/issues/677","id":3424176469,"node_id":"I_kwDOPFZ-b87MGMlV","number":677,"title":"Support multi-codebase indexing and routing for MCP server","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-17T00:56:42Z","updated_at":"2025-09-17T00:56:42Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\nKotaDB's Streamable HTTP MCP endpoint currently operates over a single `KOTADB_DATA_DIR`, which effectively constrains it to a single indexed codebase per running instance. Teams that want multiple agents working on separate repositories at once would need to stand up multiple MCP containers or processes manually.\n\n## Problem\n- MCP server lacks first-class support for hosting multiple independent indexes simultaneously.\n- No routing or namespacing mechanism exists to select a repository/database per request/session.\n- Operationally, users must run one MCP server per codebase and juggle separate ports/volumes.\n\n## Proposal\n- Research designs for multi-tenant MCP operation (e.g., per-session repository selection, dynamic index mounting, namespace-aware storage paths).\n- Consider CLI/config surface for registering multiple repositories and routing requests accordingly.\n- Evaluate impact on storage abstractions, tool registry, and health checks.\n\n## Acceptance Criteria\n- Design document or initial implementation plan for serving multiple codebases through a single MCP endpoint.\n- Clear story for how agents specify which repository they intend to work with (headers, session metadata, etc.).\n- Compatibility strategy for existing single-tenant deployments.\n\n/label enhancement mcp priority-medium","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/677/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/677/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/676","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/676/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/676/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/676/events","html_url":"https://github.com/kotadb/kota-db/issues/676","id":3423629193,"node_id":"I_kwDOPFZ-b87MEG-J","number":676,"title":"Implement spec-compliant Streamable HTTP MCP endpoint","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9066998489,"node_id":"LA_kwDOPFZ-b88AAAACHG9q2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/mcp","name":"mcp","color":"0052cc","default":false,"description":"Model Context Protocol related"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-16T20:18:41Z","updated_at":"2025-09-16T20:18:41Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\nClaude Code expects MCP servers declared in `.mcp.json` to speak the Streamable HTTP transport described in the official spec. Our current HTTP surface is only the bespoke `/mcp/tools/*` bridge plus the legacy JSON-RPC server that returns single JSON responses. There is no `/mcp` endpoint that handles POST/GET with SSE, nor do we emit/inspect `MCP-Protocol-Version`, `Mcp-Session-Id`, or `Accept` headers as required.\n\n## Problem\n* `.mcp.json` advertises `type: \"http\"` pointing at the server root, but no endpoint matches the Streamable HTTP contract.\n* The bridge routes (`/mcp/tools`, `/mcp/tools/<tool>`) are tightly coupled to our internal REST layer and incompatible with the spec that Claude Code and the CLI assume.\n* Without spec-compliant behavior we cannot connect Claude Code via project-only configuration; the CLI falls back to local stdio or errors out on remote transport negotiation.\n\n## Proposal\n1. Add a single `/mcp` endpoint that proxies to the existing `MCPServer` JSON-RPC implementation and supports both behaviors defined in the spec:\n   * HTTP POST with `Accept: application/json, text/event-stream`, proper status handling, and optional SSE response streaming.\n   * HTTP GET that opens a long-lived SSE stream for server-initiated messages (including resumability and Last-Event-ID handling).\n2. Honor MCP-required headers (`MCP-Protocol-Version`, `Mcp-Session-Id`, `Origin` validation, optional authentication hooks) and document defaults for the dev server.\n3. Preserve the legacy `/mcp/tools` bridge for backwards compatibility but clearly mark it as deprecated once the compliant endpoint exists.\n4. Update `.mcp.json` / docs to point at the new endpoint and add integration tests that exercise the Claude CLI workflow (`claude mcp list`, tool invocation) against the dev server.\n\n## Acceptance Criteria\n- Claude CLI / Claude Code can connect using only `.mcp.json` with `type: \"http\"` and successfully list/call tools.\n- POST/GET flows conform to https://modelcontextprotocol.io/specification/2025-06-18/basic/transports#streamable-http (including security notes).\n- Unit/integration coverage for both success and error cases (bad headers, unsupported protocol version, etc.).\n- Documentation updated to describe the new endpoint and migration guidance from `/mcp/tools`.\n\n## References\n- Streamable HTTP transport spec: https://modelcontextprotocol.io/specification/2025-06-18/basic/transports#streamable-http\n- Claude Code MCP setup: https://docs.claude.com/en/docs/claude-code/mcp\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/676/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/676/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/675","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/675/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/675/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/675/events","html_url":"https://github.com/kotadb/kota-db/issues/675","id":3423111612,"node_id":"I_kwDOPFZ-b87MCIm8","number":675,"title":"feat(mcp/http): Add SSE bridge endpoint compatible with Claude Code","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998489,"node_id":"LA_kwDOPFZ-b88AAAACHG9q2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/mcp","name":"mcp","color":"0052cc","default":false,"description":"Model Context Protocol related"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9124823878,"node_id":"LA_kwDOPFZ-b88AAAACH-HDRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/feature","name":"feature","color":"0075ca","default":false,"description":"Major new feature implementation"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-16T17:14:35Z","updated_at":"2025-09-16T17:14:35Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\nImplement an MCP-over-HTTP SSE bridge so Claude Code and other HTTP clients can connect without OAuth and without the Node/STDIO wrapper.\n\n## Problem\n- Today the Rust MCP server (mcp_server) exposes JSON-RPC over HTTP POST at  and returns  for GET.\n- Claude Code’s project-level HTTP transport expects an SSE stream on the server URL (GET) plus a companion endpoint for sending requests.\n- Result: project-level config with  fails to connect, even though the server is healthy (ping/tools work via POST).\n- We worked around this by switching to a process/STDIO server in , but that defeats the goal of a simple HTTP-only setup in Claude Code.\n\n## Proposal\nAdd an SSE bridge that conforms to the MCP-over-HTTP expectations used by Claude Code:\n- Introduce a new router, e.g. , mounted under  when the  feature is enabled.\n- Endpoints:\n  -  → text/event-stream. Keeps a client event stream open, heartbeats, and yields JSON-RPC results/events.\n  -  → Accept a JSON-RPC request (initialize, tools/list, tools/call, etc.), route to the existing MCP tool registry, and emit the matching response on the SSE stream (correlate via request uid=501(jayminwest) gid=20(staff) groups=20(staff),12(everyone),61(localaccounts),79(_appserverusr),80(admin),81(_appserveradm),98(_lpadmin),701(com.apple.sharepoint.group.1),33(_appstore),100(_lpoperator),204(_developer),250(_analyticsusers),395(com.apple.access_ftp),398(com.apple.access_screensharing),399(com.apple.access_ssh-disabled),400(com.apple.access_remote_ae)).\n  - (Optional) For compatibility, support  as the SSE stream and  for requests so  can be set to  in clients that don’t customize paths.\n- Preserve current auth behavior:\n  - Local dev: no auth required\n  - Remote: accept  and propagate through as today\n- CORS + keepalive: enable permissive CORS like the existing HTTP server and send periodic heartbeats to keep connections alive.\n\n## Acceptance Criteria\n- With the following Claude Code project config, connection succeeds without OAuth fields:\n  \n-  (or ) returns  and streams heartbeats.\n-  (or ) accepts JSON-RPC requests and responses are emitted on the SSE stream with matching uid=501(jayminwest) gid=20(staff) groups=20(staff),12(everyone),61(localaccounts),79(_appserverusr),80(admin),81(_appserveradm),98(_lpadmin),701(com.apple.sharepoint.group.1),33(_appstore),100(_lpoperator),204(_developer),250(_analyticsusers),395(com.apple.access_ftp),398(com.apple.access_screensharing),399(com.apple.access_ssh-disabled),400(com.apple.access_remote_ae).\n- , , and a representative  work end-to-end from Claude Code.\n\n## Implementation Notes\n- Build on the existing  handlers used by mcp_server and the HTTP bridge ().\n- Consider reusing the request routing in  to avoid duplication; the SSE layer can be a thin transport shim.\n- Ensure backpressure and client disconnect handling; keep SSE connections bounded and cleaned up.\n\n## Risks\n- SSE fanout/concurrency; ensure per-connection state is cleaned up.\n- Cross-browser/CORS behavior (should be fine for local Claude Code).\n\n## Labels\n- mcp, feature, priority-high\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/675/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/675/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/671","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/671/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/671/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/671/events","html_url":"https://github.com/kotadb/kota-db/issues/671","id":3419130256,"node_id":"I_kwDOPFZ-b87Ly8mQ","number":671,"title":"Triage: failing tests after Dependabot updates – tighten sanitization + reduce trigram false positives","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998567,"node_id":"LA_kwDOPFZ-b88AAAACHG9rJw","url":"https://api.github.com/repos/kotadb/kota-db/labels/performance","name":"performance","color":"fbca04","default":false,"description":"Performance related issues"},{"id":9066998984,"node_id":"LA_kwDOPFZ-b88AAAACHG9syA","url":"https://api.github.com/repos/kotadb/kota-db/labels/tests","name":"tests","color":"c2e0c6","default":false,"description":"Testing related"},{"id":9120925735,"node_id":"LA_kwDOPFZ-b88AAAACH6ZIJw","url":"https://api.github.com/repos/kotadb/kota-db/labels/trigram-index","name":"trigram-index","color":"0366d6","default":false,"description":"Trigram index implementation and functionality"},{"id":9121112429,"node_id":"LA_kwDOPFZ-b88AAAACH6khbQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/input-sanitization","name":"input-sanitization","color":"d73a4a","default":false,"description":"Input validation and sanitization security issues"},{"id":9241980773,"node_id":"LA_kwDOPFZ-b88AAAACJt1vZQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/needs-dogfooding","name":"needs-dogfooding","color":"d73a4a","default":false,"description":"Requires testing against KotaDB's own codebase"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-15T18:56:56Z","updated_at":"2025-09-15T18:56:56Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"Summary\n- After merging Dependabot updates into develop (#670), several tests fail in full-suite runs. Fast gating tests pass.\n- Fail groups:\n  - Query sanitization (3): stricter expectations on removing SQL/LDAP/path traversal markers.\n  - Trigram index false positives (1): long single-term “nonsense” queries still match multiple docs.\n  - Concurrency/perf stress (2–3): strict latency thresholds occasionally exceeded locally/CI; runtime contention observed.\n\nWhat passed\n- just test-fast: green (lib tests + doctests with required features).\n- Dogfooding HTTP API against this repo: indexed 33k files; queries returned sane results; benchmark ~65 ops/s overall (search ~182 ops/s, ~5.5ms avg).\n\nDetails\n- Sanitization tests failing: test_sql_injection_prevention, test_path_traversal_prevention, test_ldap_injection_prevention.\n  - sanitize_search_query currently preserves some normal chars and only removes SQL keywords when used with SQL syntax; tests expect broader removal (e.g., forbid table/select/union/drop words, strip (), \\\\, ,, =; fully remove .. and %2e encodings).\n- Trigram: implemented tiered min-match thresholds in BinaryTrigramIndex (1–3: 100%, 4–6: ~80%, >=7: ~70%) using unique trigrams; most tests now pass but one case (xyzabc123impossible) still returns >1 result.\n- Concurrency/perf: lock contention/read-avg threshold too strict across environments; write perf p95/p99 and outlier rates borderline on some machines.\n\nProposed fixes (phase 1)\n1) Sanitization (non-path-aware):\n   - Remove standalone SQL words: select|union|drop|table|insert|update|delete|create|alter (case-insensitive) regardless of context.\n   - Strip LDAP-special chars [()\\\\,=] after pattern removal.\n   - Final sweep to eliminate path traversal tokens: remove \"..\" and case-insensitive %2e encodings.\n   - Keep sanitize_path_aware_query permissive for paths; adjust unit tests accordingly.\n2) Trigram false positives:\n   - For single-token queries that are long (>= 12) or contain digits, bump threshold to max(current, 80% of unique trigrams, absolute floor 12 capped at n). Retain existing tiered thresholds for others.\n3) Stress tests (phase 2 follow-up):\n   - Make thresholds configurable or CI-aware; audit/remove nested Runtime::block_on in code paths used by async tests.\n\nAcceptance\n- All sanitization tests pass.\n- Trigram precision tests pass including false-positive reduction.\n- Gating (just test-fast) remains green.\n\nArtifacts\n- Develop commit 74ea9357e includes Dependabot roll-up.\n- Dogfood logs: dogfood_http.log; artifacts in /tmp/kotadb_*.json.\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/671/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/671/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/655","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/655/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/655/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/655/events","html_url":"https://github.com/kotadb/kota-db/issues/655","id":3413824966,"node_id":"I_kwDOPFZ-b87LetXG","number":655,"title":"Dogfooding: Notable Issues (relationships, symbols, search, stats, benchmarks)","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9113577148,"node_id":"LA_kwDOPFZ-b88AAAACHzYmvA","url":"https://api.github.com/repos/kotadb/kota-db/labels/api","name":"api","color":"fbca04","default":false,"description":"API design and functionality issues"},{"id":9113577180,"node_id":"LA_kwDOPFZ-b88AAAACHzYm3A","url":"https://api.github.com/repos/kotadb/kota-db/labels/search","name":"search","color":"0e8a16","default":false,"description":"Search functionality related issues"},{"id":9118359001,"node_id":"LA_kwDOPFZ-b88AAAACH38d2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/dogfooding","name":"dogfooding","color":"6f42c1","default":false,"description":"Self-analysis and validation features"},{"id":9118359059,"node_id":"LA_kwDOPFZ-b88AAAACH38eEw","url":"https://api.github.com/repos/kotadb/kota-db/labels/symbols","name":"symbols","color":"0e8a16","default":false,"description":"Symbol extraction and reference tracking"},{"id":9121001904,"node_id":"LA_kwDOPFZ-b88AAAACH6dxsA","url":"https://api.github.com/repos/kotadb/kota-db/labels/needs-investigation","name":"needs-investigation","color":"6c757d","default":false,"description":"Requires analysis and investigation"},{"id":9169206531,"node_id":"LA_kwDOPFZ-b88AAAACIob9Aw","url":"https://api.github.com/repos/kotadb/kota-db/labels/relationships","name":"relationships","color":"0052cc","default":false,"description":"Symbol relationships and dependency tracking"},{"id":9220190392,"node_id":"LA_kwDOPFZ-b88AAAACJZDwuA","url":"https://api.github.com/repos/kotadb/kota-db/labels/benchmarking","name":"benchmarking","color":"0052cc","default":false,"description":"Performance benchmarking and comparative testing"},{"id":9232698802,"node_id":"LA_kwDOPFZ-b88AAAACJk_Nsg","url":"https://api.github.com/repos/kotadb/kota-db/labels/stats","name":"stats","color":"0052cc","default":false,"description":"Statistics and metrics functionality"},{"id":9241966134,"node_id":"LA_kwDOPFZ-b88AAAACJt02Ng","url":"https://api.github.com/repos/kotadb/kota-db/labels/interface-consistency","name":"interface-consistency","color":"fbca04","default":false,"description":"Consistency across different interfaces (CLI/API/MCP)"},{"id":9246417891,"node_id":"LA_kwDOPFZ-b88AAAACJyEj4w","url":"https://api.github.com/repos/kotadb/kota-db/labels/api-ux","name":"api-ux","color":"0052cc","default":false,"description":"API user experience issues"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2025-09-13T16:50:12Z","updated_at":"2025-09-13T16:56:44Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"# Notable Issues from Dogfooding\n\nConsolidated findings from recent dogfooding sessions. These span relationships/stats consistency, symbol matching semantics, search response shapes, benchmark run semantics, and symbol count inflation by comments.\n\n## Relationship count inconsistency across endpoints\n- Indexing: `relationships_found: 900`\n- Overview: `total_relationships: 900`\n- Stats: `relationship_stats.total_relationships: 2818`\n- Stats breakdown (`relationship_types`) sums to 1102, not 2818. Either the totals include additional categories not shown or there’s a counting mismatch. This is confusing for users comparing services and undermines trust in the numbers.\n\nQuestions / next steps:\n- What is the single source of truth for relationship totals per repo or dataset?\n- Are there hidden categories contributing to `total_relationships` that the breakdown omits?\n- Align definitions and ensure all endpoints and UIs compute/return the same metrics.\n\n## Symbol matching semantics for analysis endpoints\n- `find-callers` for `\"WalkDir::new\"` returned “Symbol not found”.\n- Using a plain function name (e.g., `device_num`) works well.\n\nQuestions / next steps:\n- What are the expected naming rules for symbols (e.g., fully qualified like `src/lib.rs::WalkDir::new` or a canonical `crate::module::Type::method` form)?\n- Provide guidance/validation and consider normalizing inputs to canonical forms.\n\n## Search response shape varies and is confusing without docs\n- `search-code` with `format=rich` returns results under `llm_response.results` and often has empty `documents`.\n- The `format=simple` mode returns clear file paths.\n- `search-symbols` simple returns `\"total_count\": 1409`, which appears to be total symbols in the DB, not the match count. Rich mode uses `total_symbols`.\n\nSuggestions:\n- Standardize naming (e.g., `total_matches` for results after filters) and keep it consistent across formats.\n- Document response shapes explicitly for `format=rich|simple|cli` for both code and symbol search.\n\n## Benchmark run semantics\n- Requested operations: 200; response shows warmup of 100 and `operations_completed: 100`.\n- Either the run ignores the requested count or the response fields don’t reflect the full run.\n\nExpectations:\n- Counters and reported run parameters should align; clarify how warmup interacts with requested ops and ensure fields reflect the entire execution.\n\n## Inflated symbol counts by “comment” category\n- Comments counted as symbols (892/1409) dominate statistics, skewing coverage and density metrics.\n\nQuestions / options:\n- If intentional, document the rationale and provide guidance on interpreting metrics.\n- Otherwise, consider filtering comment/documentation tokens or reporting them separately so they don’t dominate symbol statistics.\n\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/655/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/655/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/654","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/654/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/654/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/654/events","html_url":"https://github.com/kotadb/kota-db/issues/654","id":3413792311,"node_id":"I_kwDOPFZ-b87LelY3","number":654,"title":"[V1 Follow-ups] git_url repo registration, docs alignment, index status WS, API cleanup","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-13T16:31:45Z","updated_at":"2025-09-13T16:31:45Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"Tracking follow-ups for the new /api/v1 implementation (PR #653) to reach full parity and polish before launch.\n\nScope\n- git_url support for repository registration\n  - Shallow clone + branch selection in POST /api/v1/repositories\n  - Input validation, safe temp dirs, cleanup; reuse existing git ingestion\n  - Idempotency by repo identity (url+branch)\n- Documentation alignment\n  - Update GitHub Pages and README examples to /api/v1 paths\n  - Add endpoint reference for search/symbols/callers/impact/repos/status/files symbols\n  - Deprecation notes for legacy /api routes; link to #638\n- Index status improvements\n  - Optional WS progress stream for long-running operations\n  - Better states + progress %; sample client snippets\n- API cleanup and finalization (ties to #638)\n  - Remove duplicate non-v1 routes after docs/webapp align\n  - Ensure consistent error schema and tracing across v1\n\nLabels\n- api, documentation, launch-prep, production-readiness, refactoring, github-integration\n\nLinks\n- #480, #638, #466, #598\n- PR #653 (/api/v1 endpoints)\n\nAcceptance\n- git_url registry end-to-end tested (clone+index+status)\n- Docs reflect /api/v1; legacy routes marked deprecated\n- Optional WS status available behind feature or documented as roadmap\n- Non-v1 routes retired post webapp update\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/654/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/654/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/649","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/649/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/649/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/649/events","html_url":"https://github.com/kotadb/kota-db/issues/649","id":3404246028,"node_id":"I_kwDOPFZ-b87K6KwM","number":649,"title":"Dogfooding HTTP API & Code Intelligence DX improvements","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504075,"node_id":"LA_kwDOPFZ-b88AAAACEQVxyw","url":"https://api.github.com/repos/kotadb/kota-db/labels/documentation","name":"documentation","color":"0075ca","default":true,"description":"Improvements or additions to documentation"},{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-10T23:43:17Z","updated_at":"2025-09-10T23:43:17Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"# Dogfooding HTTP API & Code Intelligence DX improvements\n\nSummary\n- Following successful local dogfooding, let’s harden and smooth the HTTP + CLI path for everyday developer use and CI. This issue tracks concrete, high‑impact follow‑ups to improve reliability, UX, and integrations.\n\nGoals\n- Make dogfooding one‑command, resilient, and CI‑ready.\n- Improve analysis outputs for humans and agents (clear lists, formats).\n- Reduce CLI flag friction and polish API/doc consistency.\n- Showcase integrations (MCP + IDE examples) to accelerate adoption.\n\nProposed Tasks\n- [ ] Add “quiet/summary” mode to `scripts/dogfood.sh` and `just dogfood`\n  - Prints only summarized JSON lines; non‑interactive; exits non‑zero on failures.\n  - Accepts `--summary` flag or `DOGFOOD_SUMMARY=1`.\n  - Emits: server port, index stats, search sample count, symbols count, overview totals, stats totals, benchmark ops/sec.\n- [ ] Create `just dogfood-ci` target\n  - Tailored for GitHub Actions; runs with summary mode; uses a small sample repo to keep runtime under ~1–2 minutes.\n  - Fails PR if health/index/search/overview checks fail.\n  - Add CI job “dogfood” to run on PRs touching `src/**` and `docs/**`.\n- [ ] Enrich analysis outputs (CLI + HTTP)\n  - `find-callers`: optional detailed listing with file:line, grouped by file; formats: `format=simple|cli|rich`; include `include_indirect` toggle.\n  - `analyze-impact`: list top impacted files/symbols with counts and locations; same formats as above.\n  - Acceptance: CLI shows top N entries with file:line; HTTP `format=cli` returns `{ output: string }`; `format=simple` returns arrays.\n- [ ] CLI boolean ergonomics\n  - Allow `--flag=true/false` and `--no-flag` (Clap settings) in addition to presence/absence.\n  - Update help text and README examples accordingly.\n- [ ] Docs consistency and guides\n  - Update API docs to reflect current code‑intelligence endpoints; remove stale CRUD examples or gate behind a legacy note.\n  - Add “Dogfood via HTTP” page referencing `just dogfood` and outputs; include troubleshooting (ports, jq).\n  - Expand MCP bridge docs with curl examples and a quickstart to try MCP tools over HTTP.\n- [ ] Minimal IDE integration examples\n  - VS Code sample: tasks to hit `search-code`/`search-symbols`; or a lightweight extension snippet to query and show results.\n  - JetBrains note or HTTP request collection.\n- [ ] Overview endpoint polish\n  - Ensure stable schema (avoid nulls) and document wrapper (`overview_data`). Consider `format=simple` for flattened summary keys.\n- [ ] Add lightweight HTTP smoke tests\n  - Test `/health`, `POST /api/index-codebase` with a tiny fixture, `GET /api/search-code`, `GET /api/codebase-overview` in CI.\n  - Guard runtime under ~60–90s.\n- [ ] Optional: stats output formatting\n  - Add `format=simple|cli|rich` to `/api/stats` mirroring search endpoint pattern for consistency.\n\nAcceptance Criteria\n- One‑command dogfood reliable locally and in CI, with clear summaries and non‑zero failures when expectations aren’t met.\n- Analysis endpoints and CLI provide useful default listings (humans) and machine‑friendly formats (agents/automation).\n- CLI flags are intuitive; docs and help reflect actual behavior.\n- At least one IDE/MCP example to demonstrate integration path end‑to‑end.\n\nNotes\n- `just dogfood` already handles port conflicts and now prints stats/benchmarks.\n- Keep CI runtime modest; prefer tiny fixture repos or a curated subset of this repo.\n\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/649/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/649/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/648","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/648/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/648/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/648/events","html_url":"https://github.com/kotadb/kota-db/issues/648","id":3400719381,"node_id":"I_kwDOPFZ-b87KstwV","number":648,"title":"Dogfooding report: indexing UX, CLI flags, tests, find-callers output, MCP warnings","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504068,"node_id":"LA_kwDOPFZ-b88AAAACEQVxxA","url":"https://api.github.com/repos/kotadb/kota-db/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9066998984,"node_id":"LA_kwDOPFZ-b88AAAACHG9syA","url":"https://api.github.com/repos/kotadb/kota-db/labels/tests","name":"tests","color":"c2e0c6","default":false,"description":"Testing related"},{"id":9118359001,"node_id":"LA_kwDOPFZ-b88AAAACH38d2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/dogfooding","name":"dogfooding","color":"6f42c1","default":false,"description":"Self-analysis and validation features"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-10T03:10:38Z","updated_at":"2025-09-10T03:10:38Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n\nDogfooding KotaDB locally surfaced several UX issues and test fragility. Core flows (build, index repo, search, relationships, MCP health) work well and feel fast.\n\n## Environment\n\n- macOS sandbox (restricted network)\n- cargo 1.88.0; rust 1.79+ toolchain\n- commands run from repo root\n\n## Repro Steps\n\n- Build: cargo build\n- Unit tests: cargo test --lib\n- Index (works): cargo run --bin kotadb -- -d ./kotadb-data index-codebase .\n- Index (fails): cargo run --bin kotadb -- -d ./kotadb-data index-codebase ./src\n- Query: kotadb search-code \"pub struct RepositoryIngester\"\n- Relationships: kotadb find-callers RepositoryIngester -l 10 -v verbose\n- MCP health: cargo run --bin mcp_server --features mcp-server -- --health-check\n\n## Findings\n\n1. **Indexing non-repo path gives generic error**\n   - Error: Failed to ingest repository with symbol and relationship extraction when indexing ./src.\n   - Ask: Detect non-git paths and return actionable message: \"Path is not a Git repository. Try: kotadb index-codebase .\"\n\n2. **Global flags ordering is brittle**\n   - kotadb index-codebase ./src --db-path ./kotadb-data fails; only -d before subcommand works.\n   - Ask: Document flag placement and consider allowing trailing global args via clap.\n\n3. **find-callers default output lacks call sites**\n   - Prints counts and timing but not locations.\n   - Ask: Default to showing first N locations (file:line, snippet). Add --format json.\n\n4. **Two unit tests fail in restricted env**\n   - embeddings::tests::test_embedding_service_caching\n   - semantic_search::tests::test_reciprocal_rank_fusion\n   - Ask: Skip/gate without OPENAI_API_KEY or when system proxy lookup isn't available; fallback to no-proxy in tests.\n\n5. **MCP warnings**\n   - Unreachable code warnings in src/mcp_http_bridge.rs.\n   - Ask: Clean up control flow to silence warnings.\n\n6. **Stats UX**\n   - \"Extraction coverage: 0.7%\" is confusing with many non-code files.\n   - Ask: Filter to code extensions by default or clarify metric.\n\n## Suggested Tasks\n\n- [ ] Add git-repo check + helpful error for index-codebase\n- [ ] Improve clap config/docs for global flag placement\n- [ ] Enhance find-callers default output + --format json\n- [ ] Gate/skip embedding tests in restricted env; avoid Proxy::system in tests\n- [ ] Remove unreachable branches in mcp_http_bridge.rs\n- [ ] Clarify/adjust stats extraction coverage or default filters","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/648/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/648/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/644","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/644/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/644/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/644/events","html_url":"https://github.com/kotadb/kota-db/issues/644","id":3400350220,"node_id":"I_kwDOPFZ-b87KrToM","number":644,"title":"📖 Update GitHub Pages Documentation to Reflect Accurate Project State","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504075,"node_id":"LA_kwDOPFZ-b88AAAACEQVxyw","url":"https://api.github.com/repos/kotadb/kota-db/labels/documentation","name":"documentation","color":"0075ca","default":true,"description":"Improvements or additions to documentation"},{"id":9118359037,"node_id":"LA_kwDOPFZ-b88AAAACH38d_Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-medium","name":"effort-medium","color":"fbca04","default":false,"description":"Medium effort (1-3 days)"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9157121677,"node_id":"LA_kwDOPFZ-b88AAAACIc6WjQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/developer-experience","name":"developer-experience","color":"84b6eb","default":false,"description":"Features that improve developer productivity and workflow"},{"id":9167968495,"node_id":"LA_kwDOPFZ-b88AAAACInQY7w","url":"https://api.github.com/repos/kotadb/kota-db/labels/production-readiness","name":"production-readiness","color":"d93f0b","default":false,"description":"Production deployment readiness items"},{"id":9175575880,"node_id":"LA_kwDOPFZ-b88AAAACIugtSA","url":"https://api.github.com/repos/kotadb/kota-db/labels/usability","name":"usability","color":"84b6eb","default":false,"description":"User experience and interface usability issues"},{"id":9187707818,"node_id":"LA_kwDOPFZ-b88AAAACI6FLqg","url":"https://api.github.com/repos/kotadb/kota-db/labels/meta","name":"meta","color":"8B5CF6","default":false,"description":"Meta issues for strategic planning and architecture"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-09T23:51:01Z","updated_at":"2025-09-09T23:51:01Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Problem Statement\n\nThe GitHub Pages documentation currently reflects the same misaligned claims found in AGENT.md (addressed in issue #643). Public-facing documentation must accurately represent the current project state to maintain credibility with users, contributors, and the broader developer community.\n\n## Current Documentation Issues\n\n### 1. Public Perception vs. Reality\n**Current Public Claims:**\n- Production-ready system with 99% reliability\n- Completed core features ready for deployment\n- Stable API and feature set\n\n**Actual Project State:**\n- Pre-launch development phase (v0.6.0)\n- Multiple production blockers preventing deployment\n- Active architecture migrations and system refactoring\n- Launch preparation still in progress\n\n### 2. User Expectations Management\n**Risk of Misaligned Expectations:**\n- Users expecting production-stable software\n- Developers assuming ready-to-deploy systems\n- Contributors working with outdated capability assumptions\n- Community feedback based on inaccurate feature claims\n\n### 3. GitHub Pages Specific Concerns\n**Documentation Locations Requiring Updates:**\n- Main project README displayed on GitHub Pages\n- Feature documentation and capability claims\n- Architecture documentation and stability assertions\n- Getting started guides and deployment instructions\n\n## Required Updates\n\n### Phase 1: Immediate Public Documentation Corrections\n- [ ] **Homepage/README accuracy** - Update reliability and completion claims\n- [ ] **Feature documentation** - Mark features as \"development\" vs \"production-ready\"  \n- [ ] **Getting started guides** - Add appropriate development phase disclaimers\n- [ ] **API documentation** - Clearly mark stability levels and expected changes\n\n### Phase 2: Transparent Development Communication\n- [ ] **Development phase clarity** - Prominently display pre-launch status\n- [ ] **Production blocker disclosure** - Transparent about current limitations\n- [ ] **Roadmap accuracy** - Realistic timelines and milestone expectations\n- [ ] **Contribution guidelines** - Align with actual project priorities\n\n### Phase 3: Ongoing Accuracy Maintenance\n- [ ] **Documentation review process** - Regular audits of public-facing content\n- [ ] **Version synchronization** - Keep docs aligned with actual capabilities\n- [ ] **Community communication** - Transparent updates on progress and blockers\n- [ ] **Feedback integration** - Responsive corrections based on community input\n\n## Specific Documentation Targets\n\n### GitHub Pages Content\n1. **Main README.md**\n   - Update project status to \"pre-launch development\"\n   - Replace reliability claims with realistic development targets\n   - Add clear disclaimers about production readiness\n\n2. **Feature Documentation**\n   - Mark experimental vs stable features clearly\n   - Update performance claims to reflect current testing\n   - Add appropriate caveats about ongoing development\n\n3. **Installation/Setup Guides**\n   - Emphasize development/testing usage\n   - Add warnings about production deployment\n   - Provide realistic expectations for stability\n\n4. **API Documentation**\n   - Mark API stability levels appropriately\n   - Document expected changes and breaking updates\n   - Provide migration guidance for evolving features\n\n### Consistency Requirements\n- [ ] All public documentation aligns with corrected AGENT.md\n- [ ] No unsubstantiated performance or reliability claims\n- [ ] Clear development phase indicators throughout\n- [ ] Appropriate technical disclaimers and expectations\n\n## Success Criteria\n\n### Accuracy Metrics\n- [ ] Public documentation matches actual project capabilities\n- [ ] No misleading stability or readiness claims\n- [ ] Clear development phase communication\n- [ ] Realistic timeline and expectation setting\n\n### Community Impact\n- [ ] Users have accurate expectations about system capabilities\n- [ ] Contributors understand actual development priorities\n- [ ] Community feedback based on realistic feature assessment\n- [ ] Professional presentation that maintains credibility\n\n### Maintenance Process\n- [ ] Regular documentation accuracy reviews established\n- [ ] Automated checks for consistency between internal and public docs\n- [ ] Community feedback integration process\n- [ ] Version-based documentation update triggers\n\n## Implementation Strategy\n\n### 1. Audit Current Public Documentation\n- **Systematic review** of all GitHub Pages content\n- **Cross-reference** with corrected AGENT.md for consistency\n- **Identify specific claims** requiring correction or context\n- **Document gaps** between public claims and internal reality\n\n### 2. Coordinated Update Process\n- **Sequence updates** to maintain consistency across all platforms\n- **Draft revisions** maintaining professional tone while being accurate\n- **Review process** ensuring technical accuracy and appropriate messaging\n- **Deployment coordination** to minimize confusion during transition\n\n### 3. Long-term Maintenance Framework\n- **Documentation lifecycle** tied to development milestones\n- **Regular audit schedule** for accuracy verification\n- **Community feedback channels** for accuracy reporting\n- **Automated consistency checks** where technically feasible\n\n## Dependencies\n\n- **Issue #643 completion**: This issue should be completed after the internal documentation audit\n- **Version 1.0.0 planning**: Public documentation strategy should align with launch timeline\n- **Community communication**: Changes should be communicated transparently to existing users\n\n## Risk Mitigation\n\n### Transition Communication\n- [ ] **Clear change communication** - Explain documentation updates to community\n- [ ] **Maintain professional tone** - Accurate but not apologetic about development phase\n- [ ] **Preserve credibility** - Honest assessment builds rather than damages trust\n- [ ] **Future reliability** - Establish pattern of accurate, trustworthy documentation\n\n### Community Management\n- [ ] **Proactive communication** - Address potential concerns before they arise\n- [ ] **Responsive feedback** - Quick response to community questions about changes\n- [ ] **Transparent roadmap** - Clear communication about actual development timeline\n- [ ] **Professional consistency** - Maintain quality standards while being realistic\n\nThis update ensures that KotaDB's public-facing documentation accurately represents the current development state, building appropriate user expectations while maintaining professional credibility for the eventual production launch.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/644/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/644/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/643","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/643/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/643/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/643/events","html_url":"https://github.com/kotadb/kota-db/issues/643","id":3400349253,"node_id":"I_kwDOPFZ-b87KrTZF","number":643,"title":"🔍 CRITICAL: Documentation Accuracy Audit - Address Misalignments Between Claims and Project Reality","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504075,"node_id":"LA_kwDOPFZ-b88AAAACEQVxyw","url":"https://api.github.com/repos/kotadb/kota-db/labels/documentation","name":"documentation","color":"0075ca","default":true,"description":"Improvements or additions to documentation"},{"id":9113577095,"node_id":"LA_kwDOPFZ-b88AAAACHzYmhw","url":"https://api.github.com/repos/kotadb/kota-db/labels/critical","name":"critical","color":"d73a4a","default":false,"description":"Critical issues requiring immediate attention"},{"id":9118359026,"node_id":"LA_kwDOPFZ-b88AAAACH38d8g","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-large","name":"effort-large","color":"f85149","default":false,"description":"Large effort - more than 3 days"},{"id":9167968495,"node_id":"LA_kwDOPFZ-b88AAAACInQY7w","url":"https://api.github.com/repos/kotadb/kota-db/labels/production-readiness","name":"production-readiness","color":"d93f0b","default":false,"description":"Production deployment readiness items"},{"id":9174838498,"node_id":"LA_kwDOPFZ-b88AAAACItzs4g","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-critical","name":"priority-critical","color":"b60205","default":false,"description":"Critical priority - immediate attention required"},{"id":9182337439,"node_id":"LA_kwDOPFZ-b88AAAACI09Znw","url":"https://api.github.com/repos/kotadb/kota-db/labels/technical-debt","name":"technical-debt","color":"fbca04","default":false,"description":"Technical debt that needs to be addressed"},{"id":9187707818,"node_id":"LA_kwDOPFZ-b88AAAACI6FLqg","url":"https://api.github.com/repos/kotadb/kota-db/labels/meta","name":"meta","color":"8B5CF6","default":false,"description":"Meta issues for strategic planning and architecture"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2025-09-09T23:50:22Z","updated_at":"2025-09-09T23:58:39Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Problem Statement\n\nA comprehensive analysis has revealed significant misalignments between the claims made in AGENT.md and the current project state. The documentation presents an overly optimistic view of system reliability and completion status that doesn't match the production blockers and critical issues currently present.\n\n## Key Misalignments Discovered\n\n### 1. Reliability Claims vs. Production Reality\n**AGENT.md Claims:**\n- \"99% success rate\" from 6-stage risk reduction methodology (line 103, 370)\n- \"99% reliability\" maintained (line 357)\n- \"KotaDB's 99% reliability while shipping AI-first features\" (line 357)\n\n**Current Production State:**\n- Issue #640: CRITICAL HTTP Server Architecture Migration (production-blocker)\n- Issue #638: LAUNCH PREP - Remove legacy HTTP server (production-blocker, launch-prep)\n- Issue #631: Release blocker - IndexingService tests failing (production-blocker)\n- Issue #561: CRITICAL Comprehensive Testing Suite Analysis - Security Vulnerabilities (production-blocker)\n\n### 2. Completion Status vs. Active Development\n**AGENT.md Claims:**\n- \"✅ COMPLETED (DO NOT BREAK)\" sections listed as stable (line 108)\n- Multiple systems described as production-ready\n\n**Actual Status:**\n- Multiple launch-blocking issues preventing production deployment\n- Active refactoring of core HTTP server architecture\n- Test failures in critical system components\n- Security vulnerabilities requiring immediate attention\n\n### 3. Testing Claims vs. Test Infrastructure State\n**AGENT.md Claims:**\n- \"243 tests currently passing\" (line 442)\n- Comprehensive test coverage requirements listed\n\n**Current Issues:**\n- Issue #633: \"Restore Full Test Coverage\" - indicates coverage gaps\n- Issue #631: \"IndexingService tests failing\" - core tests not passing\n- Issue #561: Security vulnerabilities in testing suite\n\n### 4. Performance Claims vs. Monitoring Reality\n**AGENT.md Claims:**\n- Sub-10ms query latency validated (line 104, 667)\n- Specific performance targets as requirements (lines 663-677)\n\n**Actual Development State:**\n- Issue #545: \"CLI indexing operation times out on moderate codebases\"\n- Performance optimization epics still in progress (Issue #607)\n\n## Impact Analysis\n\n### 1. Agent Confusion and Misdirection\n- New agents may make incorrect assumptions about system stability\n- Documentation suggests production readiness when system has launch blockers\n- Agents might skip necessary validation steps believing systems are \"completed\"\n\n### 2. Strategic Planning Issues\n- Unrealistic reliability claims may lead to premature deployment decisions\n- Documentation doesn't reflect actual technical debt and critical issues\n- Gap between claimed capabilities and actual system state\n\n### 3. Development Workflow Problems\n- Agents may not prioritize critical production blockers appropriately\n- Documentation suggests optional validation when comprehensive testing is needed\n- Misalignment between documentation tone and actual project phase\n\n## Required Actions\n\n### Phase 1: Immediate Accuracy Corrections\n- [ ] **Update reliability claims** - Replace \"99% reliability\" with \"targeting production readiness\"\n- [ ] **Correct completion status** - Move items from \"COMPLETED\" to appropriate development phases\n- [ ] **Update test status** - Reflect actual test infrastructure state and coverage gaps\n- [ ] **Revise performance claims** - Present as targets rather than validated achievements\n\n### Phase 2: Documentation Reality Alignment\n- [ ] **Review AGENT.md thoroughly** - Line-by-line accuracy check against current issues\n- [ ] **Update project phase descriptions** - Reflect pre-launch development status accurately\n- [ ] **Align tone with reality** - Professional but realistic about current state\n- [ ] **Add production blocker context** - Acknowledge critical issues preventing launch\n\n### Phase 3: Accuracy Maintenance Systems\n- [ ] **Create documentation review checklist** - Prevent future misalignments\n- [ ] **Link docs to actual metrics** - Base claims on measurable project state\n- [ ] **Establish regular doc audits** - Quarterly accuracy reviews\n- [ ] **Agent handoff protocol** - Include doc accuracy verification\n\n## Specific Files Requiring Updates\n\n### Primary Target: AGENT.md\n- **Lines 103, 370, 357**: Remove unsubstantiated \"99% reliability\" claims\n- **Lines 108-113**: Update \"COMPLETED\" status to reflect production blockers\n- **Lines 442-446**: Correct test status and coverage claims  \n- **Lines 663-677**: Present performance targets as goals, not achievements\n- **Lines 114-124**: Update development priorities to reflect launch blockers\n\n### Secondary Targets\n- **README.md**: Ensure consistency with corrected AGENT.md\n- **DEV_GUIDE.md**: Update if it contains similar reliability claims\n- **docs/** directory: Review for consistency with corrected documentation\n\n## Success Criteria\n\n### Accuracy Metrics\n- [ ] Zero unsubstantiated reliability or completion claims\n- [ ] All documentation claims verifiable against current project state\n- [ ] Realistic timeline and capability expectations set for agents\n- [ ] Production blocker acknowledgment and prioritization\n\n### Agent Experience\n- [ ] New agents receive accurate project state information\n- [ ] Documentation supports appropriate prioritization of critical issues\n- [ ] Agent decision-making based on realistic system capabilities\n- [ ] Clear distinction between aspirational goals and current state\n\n## Implementation Approach\n\n1. **Systematic Review**: Go through AGENT.md line by line, fact-checking against current issues\n2. **Reality-Based Rewrite**: Replace optimistic language with neutral, accurate descriptions\n3. **Production Context**: Add appropriate context about launch blockers and critical issues\n4. **Validation**: Ensure all revised claims can be verified against measurable project state\n5. **Consistency Check**: Update related documentation to maintain alignment\n\n## References\n\n- **Current Version**: v0.6.0 (pre-launch development phase)\n- **Production Blockers**: Issues #640, #638, #631, #561\n- **Critical Issues**: 20+ open issues requiring attention before production\n- **Testing State**: Multiple test failures and coverage gaps documented\n- **Performance Issues**: Timeout problems and optimization needs documented\n\nThis audit addresses the fundamental disconnect between documentation promises and project reality, ensuring agents receive accurate information for effective development work.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/643/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/643/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/637","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/637/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/637/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/637/events","html_url":"https://github.com/kotadb/kota-db/issues/637","id":3396529241,"node_id":"I_kwDOPFZ-b87KcuxZ","number":637,"title":"[Post-Launch] Implement Git-Based Symbol Statistics with Cultural Syntax Analysis for Enhanced LLM Understanding","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9118359020,"node_id":"LA_kwDOPFZ-b88AAAACH38d7A","url":"https://api.github.com/repos/kotadb/kota-db/labels/git-integration","name":"git-integration","color":"0366d6","default":false,"description":"Git repository and version control features"},{"id":9118359026,"node_id":"LA_kwDOPFZ-b88AAAACH38d8g","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-large","name":"effort-large","color":"f85149","default":false,"description":"Large effort - more than 3 days"},{"id":9169161132,"node_id":"LA_kwDOPFZ-b88AAAACIoZLrA","url":"https://api.github.com/repos/kotadb/kota-db/labels/vision","name":"vision","color":"8B5CF6","default":false,"description":"Vision and long-term direction issues"},{"id":9249595021,"node_id":"LA_kwDOPFZ-b88AAAACJ1GejQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/post-launch","name":"post-launch","color":"84b6eb","default":false,"description":"Features planned for after initial launch/v1.0.0"},{"id":9249595234,"node_id":"LA_kwDOPFZ-b88AAAACJ1GfYg","url":"https://api.github.com/repos/kotadb/kota-db/labels/symbol-intelligence","name":"symbol-intelligence","color":"6f42c1","default":false,"description":"Advanced symbol analysis and intelligence features"},{"id":9249595458,"node_id":"LA_kwDOPFZ-b88AAAACJ1GgQg","url":"https://api.github.com/repos/kotadb/kota-db/labels/llm-enhancement","name":"llm-enhancement","color":"d73a4a","default":false,"description":"Features specifically designed to improve LLM understanding and interaction"},{"id":9249595709,"node_id":"LA_kwDOPFZ-b88AAAACJ1GhPQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/cultural-analysis","name":"cultural-analysis","color":"8B5CF6","default":false,"description":"Code culture, team patterns, and evolutionary analysis features"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-09T04:23:40Z","updated_at":"2025-09-09T04:23:40Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Problem Statement\n\nLLMs need to understand not just what code does, but **how it evolved** and the **cultural patterns** that shaped it. As we know: **\"Syntax is about culture\"** - code carries team DNA through naming conventions, architectural patterns, error handling styles, and evolutionary decisions.\n\nCurrently, KotaDB provides excellent structural analysis of codebases, but lacks the temporal and cultural context that would enable LLMs to understand:\n- Why code was written a certain way\n- How teams collaborate and evolve patterns\n- Which symbols are stable vs. experimental\n- What architectural decisions reveal about team culture\n- How to suggest culturally-aligned changes\n\nThis represents a fundamental gap between structural code analysis and cultural code understanding.\n\n## Current State\n\n**Strengths we can build upon:**\n- ✅ Excellent binary symbol storage (`PackedSymbol`) with 10x performance improvements\n- ✅ Robust git integration with commit history and file change tracking\n- ✅ High-performance indexing (primary, trigram, vector indices)\n- ✅ Comprehensive symbol extraction (functions, classes, variables, imports)\n\n**Current limitations:**\n- ❌ Symbol and git data exist in separate domains without correlation\n- ❌ No temporal metadata linking symbols to their creation/evolution context\n- ❌ Missing cultural pattern detection (naming styles, architectural evolution)\n- ❌ No team collaboration intelligence or knowledge concentration metrics\n- ❌ Limited predictive insights about change likelihood or impact radius\n\n## Proposed Solution: Cultural Symbol Intelligence\n\nTransform KotaDB from a structural code analyzer into a **cultural intelligence platform** that understands how code evolves and what it reveals about team patterns.\n\n### Core Architecture Extensions\n\n#### 1. Enhanced PackedSymbol Format\n```rust\n// Extend existing PackedSymbol with temporal git metadata\npub struct PackedSymbolWithEvolution {\n    // Existing symbol data\n    pub symbol: PackedSymbol,\n    \n    // Temporal metadata\n    pub creation_commit: CommitHash,\n    pub creation_time: ValidatedTimestamp,\n    pub last_modified: ValidatedTimestamp,\n    pub modification_frequency: f32,\n    pub stability_score: f32,  // Lower = more volatile\n    pub author_diversity: u8,  // Number of different authors\n    \n    // Cultural metadata\n    pub naming_style_id: u16,  // Reference to detected naming convention\n    pub abstraction_level: u8, // 0=concrete, 255=highly abstract\n    pub cultural_cluster_id: Option<u16>, // Similar pattern group\n}\n```\n\n#### 2. Cultural Intelligence Metadata\n```rust\npub struct CulturalSymbolMetadata {\n    // Naming pattern analysis\n    pub naming_conventions: HashMap<String, NamingStyle>,\n    pub style_evolution: Vec<StyleChange>,\n    \n    // Team culture indicators\n    pub error_handling_patterns: Vec<ErrorPattern>,\n    pub abstraction_preferences: AbstractionProfile,\n    pub collaboration_patterns: TeamPattern,\n    \n    // Architectural evolution\n    pub design_pattern_usage: HashMap<String, PatternUsage>,\n    pub refactoring_events: Vec<RefactoringEvent>,\n    pub technical_debt_indicators: Vec<DebtIndicator>,\n}\n```\n\n#### 3. Symbol Evolution Timeline\n```rust\npub struct SymbolEvolutionEntry {\n    pub symbol_id: ValidatedDocumentId,\n    pub event_type: EvolutionEvent,  // Created, Modified, Refactored, Deleted\n    pub commit_hash: CommitHash,\n    pub timestamp: ValidatedTimestamp,\n    pub author: String,\n    pub cultural_context: CulturalContext,  // What was happening in codebase\n    pub impact_radius: f32,  // How many other symbols affected\n}\n```\n\n### Key Features to Implement\n\n#### 📊 **Symbol Maturity Indicators**\n- **Age tracking**: When symbols were first introduced\n- **Modification frequency**: How often symbols change (stability indicators)\n- **Author diversity**: Single-author vs. collaborative symbols\n- **Lifecycle stages**: Experimental → Stable → Legacy → Deprecated\n\n#### 🎨 **Cultural Pattern Detection**\n- **Naming style evolution**: Track how team naming conventions change over time\n- **Error handling culture**: Evolution from panic! → Result → anyhow → custom errors\n- **Abstraction preferences**: Concrete implementations → trait abstractions → generic patterns\n- **Architecture patterns**: MVC → Components → Clean Architecture → Domain-Driven Design\n\n#### 👥 **Team Collaboration Intelligence**\n- **Knowledge concentration**: Which symbols have single points of failure (one author)\n- **Collaboration patterns**: Pair programming indicators, review patterns, knowledge sharing\n- **Cultural transmission**: How patterns spread across the team\n- **Onboarding insights**: Which areas require most cultural knowledge\n\n#### ⏰ **Evolutionary Context**\n- **Creation context**: What was the codebase state when symbol was added?\n- **Refactoring events**: Major architectural changes and their cultural triggers\n- **Feature velocity**: How quickly features are developed in different areas\n- **Cultural debt detection**: Inconsistencies that indicate cultural drift\n\n#### 🔮 **Predictive Cultural Insights**\n- **Change likelihood**: Predict which symbols are likely to change based on patterns\n- **Impact radius**: Cultural blast radius of changes (affects team patterns)\n- **Risk indicators**: Symbols that violate established cultural norms\n- **Refactoring candidates**: Areas where cultural evolution suggests improvements needed\n\n### Benefits for LLM Understanding\n\n#### 🧠 **From Structure to Story**\nTransform KotaDB from \"what exists\" to \"why it exists and how it got there\":\n- **Temporal narratives**: \"This error handling pattern emerged after the v2.0 refactor\"\n- **Cultural context**: \"The team prefers builder patterns for complex initialization\"\n- **Evolution insights**: \"Recent commits show movement toward async patterns\"\n\n#### 🎯 **Culturally-Aware Code Suggestions**\n- **Style consistency**: Suggest changes that match team's evolving patterns\n- **Cultural alignment**: Recommend refactoring that fits established team culture\n- **Evolution prediction**: Anticipate where code is heading based on recent patterns\n- **Risk assessment**: Flag changes that violate cultural norms\n\n#### 📈 **Architectural Intelligence**\n- **Pattern evolution tracking**: How architectural decisions change over time\n- **Cultural debt detection**: Areas where inconsistent patterns create confusion\n- **Team knowledge mapping**: Who understands what parts of the system culturally\n- **Change impact prediction**: Cultural ripple effects of architectural changes\n\n### Implementation Strategy\n\n#### Phase 1: Extend Binary Format (Weeks 1-2)\n- Extend `PackedSymbol` with temporal git metadata\n- Add cultural metadata storage structures\n- Implement efficient serialization/deserialization\n- **Dogfooding**: Analyze KotaDB's own symbol evolution patterns\n\n#### Phase 2: Cultural Analysis During Git Ingestion (Weeks 3-5)\n- Integrate git commit history with symbol extraction\n- Implement naming pattern detection algorithms\n- Build team collaboration analysis\n- Add evolutionary timeline construction\n- **Dogfooding**: Track KotaDB's 2,851 commits for cultural evolution validation\n\n#### Phase 3: Evolution-Aware Query Interface (Weeks 6-7)\n- Extend MCP server with cultural intelligence queries\n- Add temporal symbol search capabilities\n- Implement pattern evolution tracking\n- Build predictive analytics for change impact\n- **Dogfooding**: Test cultural queries on KotaDB's evolution patterns\n\n#### Phase 4: LLM-Optimized Cultural Intelligence (Weeks 8-9)\n- Create cultural summary formats for LLM consumption\n- Build narrative generation for code evolution\n- Implement cultural context injection for code suggestions\n- Add team pattern documentation generation\n- **Dogfooding**: Validate LLM cultural understanding improvements\n\n### Success Metrics\n\n#### Technical Metrics\n- **Performance**: Cultural analysis adds <5ms to indexing time per symbol\n- **Storage efficiency**: Cultural metadata adds <20% to binary storage size\n- **Query performance**: Cultural intelligence queries execute in <10ms\n- **Memory usage**: Cultural metadata fits within existing memory constraints\n\n#### Cultural Intelligence Metrics\n- **Pattern detection accuracy**: >90% accuracy in detecting naming conventions\n- **Evolution prediction**: >80% accuracy predicting symbol change likelihood\n- **Cultural consistency**: Identify >95% of cultural debt indicators\n- **Team insight quality**: Generate actionable insights for >75% of codebases\n\n### Dogfooding Opportunity: KotaDB's Cultural Evolution\n\nKotaDB's own development provides perfect validation data:\n- **2,851 commits** of evolutionary history\n- **Multi-author collaboration** patterns to analyze\n- **Architectural evolution** from simple storage to full intelligence platform\n- **Real cultural decisions** around error handling, async patterns, type safety\n\n**Validation scenarios:**\n```bash\n# Analyze KotaDB's own cultural evolution\ncargo run -- -d ./cultural-analysis analyze-evolution .\ncargo run -- -d ./cultural-analysis cultural-patterns --team-size 3\ncargo run -- -d ./cultural-analysis predict-changes --symbol FileStorage\ncargo run -- -d ./cultural-analysis cultural-debt --since \"2024-01-01\"\n```\n\n### API Design Preview\n\n```rust\n// New MCP server capabilities\npub enum CulturalQuery {\n    SymbolMaturity { symbol_name: String },\n    CulturalPatterns { since: Option<DateTime> },\n    EvolutionTimeline { symbol_id: DocumentId },\n    TeamCollaboration { author: Option<String> },\n    PredictChanges { symbols: Vec<String> },\n    CulturalDebt { severity: DebtLevel },\n    NamingEvolution { pattern_type: PatternType },\n    RefactoringCandidates { cultural_score: f32 },\n}\n```\n\n### Integration with Existing Systems\n\nThis feature builds seamlessly on existing KotaDB infrastructure:\n- **Binary storage**: Extend `PackedSymbol` format without breaking changes\n- **Git integration**: Enhance existing git ingestion with cultural analysis\n- **Index systems**: Add cultural metadata to existing B+ tree and trigram indices\n- **MCP server**: Add new query types without affecting existing functionality\n- **Type validation**: Use existing `Validated*` types for cultural metadata\n\n## Next Steps\n\n1. **Design review**: Validate cultural metadata schema and binary format extensions\n2. **Performance analysis**: Ensure cultural analysis doesn't impact core performance targets\n3. **Incremental implementation**: Start with basic temporal metadata, evolve to full cultural intelligence\n4. **Community feedback**: Share cultural analysis results from KotaDB's own evolution\n\nThis feature represents a fundamental evolution from \"code structure analysis\" to \"code culture understanding\" - enabling LLMs to not just read code, but understand the human decisions and team dynamics that shaped it.\n\n---\n\n**Related Issues**: This builds on our existing symbol tracking (#symbols) and git integration (#git-integration) to create a new category of codebase intelligence.\n\n**Target Audience**: AI assistants, code review tools, architectural analysis platforms, and developer experience tools that need cultural context for better code understanding and suggestions.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/637/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/637/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/633","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/633/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/633/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/633/events","html_url":"https://github.com/kotadb/kota-db/issues/633","id":3395583722,"node_id":"I_kwDOPFZ-b87KZH7q","number":633,"title":"POST v0.6.0: Comprehensive Technical Debt and Quality Improvements - Restore Full Test Coverage","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504068,"node_id":"LA_kwDOPFZ-b88AAAACEQVxxA","url":"https://api.github.com/repos/kotadb/kota-db/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":9066998984,"node_id":"LA_kwDOPFZ-b88AAAACHG9syA","url":"https://api.github.com/repos/kotadb/kota-db/labels/tests","name":"tests","color":"c2e0c6","default":false,"description":"Testing related"},{"id":9118359026,"node_id":"LA_kwDOPFZ-b88AAAACH38d8g","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-large","name":"effort-large","color":"f85149","default":false,"description":"Large effort - more than 3 days"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9136360593,"node_id":"LA_kwDOPFZ-b88AAAACIJHMkQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/integration","name":"integration","color":"1d76db","default":false,"description":"Integration issues between system components"},{"id":9182337439,"node_id":"LA_kwDOPFZ-b88AAAACI09Znw","url":"https://api.github.com/repos/kotadb/kota-db/labels/technical-debt","name":"technical-debt","color":"fbca04","default":false,"description":"Technical debt that needs to be addressed"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":{"url":"https://api.github.com/repos/kotadb/kota-db/milestones/5","html_url":"https://github.com/kotadb/kota-db/milestone/5","labels_url":"https://api.github.com/repos/kotadb/kota-db/milestones/5/labels","id":13683962,"node_id":"MI_kwDOPFZ-b84A0Mz6","number":5,"title":"Stabilization Sprint (Pre-Launch)","description":"Stabilize test/security/infra before new feature work: fix failing tests, security audit, CI stability. Short-lived milestone to unblock launch.","creator":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"open_issues":4,"closed_issues":1,"state":"open","created_at":"2025-09-13T16:13:49Z","updated_at":"2025-09-19T16:54:34Z","due_on":"2025-09-18T07:00:00Z","closed_at":null},"comments":0,"created_at":"2025-09-08T20:18:19Z","updated_at":"2025-09-13T16:13:56Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n\nFollowing the successful v0.6.0 release with 446 passing unit tests, we need systematic cleanup to address technical debt and quality gaps that were deferred during the release push. This issue covers critical test coverage restoration, CI pipeline stabilization, and integration testing improvements.\n\n**This is NOT an emergency - core functionality works correctly. This is about systematic quality improvement over the next 2 weeks.**\n\n## Critical Findings from PR #632 Code Review\n\n### 1. Disabled Tests Requiring Real Implementation Fixes (Anti-Mock Philosophy)\n- **test_query_sanitization.rs**: Completely disabled (renamed to .disabled) - security-critical testing\n- **Memory limits tests**: Marked with `#[ignore]` instead of proper fixes\n- **Git repository setup tests**: Failing across multiple integration test files\n- **IndexingService tests**: Failing due to output format mismatches (linked to #631)\n\n### 2. CI Pipeline Instability\n- Container Build failures in GitHub Actions\n- Supply Chain Security check failures\n- Railway deployment pipeline issues\n\n### 3. Integration Test Coverage Gaps\n- Codebase intelligence features lack comprehensive integration testing\n- Real-world scenario testing insufficient\n- Dogfooding validation incomplete for some edge cases\n\n## Action Plan\n\n### Phase 1: Test Infrastructure Restoration (Week 1)\n\n#### 1.1 Re-enable Disabled Tests with Real Implementations\n- [ ] **Restore test_query_sanitization.rs** (Priority: Critical)\n  - Rename from .disabled back to .rs\n  - Fix test failures using real components (NO mocks)\n  - Use failure injection patterns: `FlakyStorage`, `CorruptedStorage`\n  - Ensure input sanitization security tests pass\n  - Estimated effort: 1-2 days\n\n- [ ] **Fix Memory Limits Tests** (Priority: High)\n  - Remove `#[ignore]` annotations\n  - Implement proper memory pressure testing with real components\n  - Use `TempDir::new()` for isolated test environments\n  - Test actual memory exhaustion scenarios\n  - Estimated effort: 1 day\n\n- [ ] **Resolve Git Repository Setup Issues** (Priority: High)\n  - Address git setup failures across integration test files\n  - Ensure proper repository initialization in test environments\n  - Use real git repositories with `TempDir` isolation\n  - Link to resolved #509 for reference patterns\n  - Estimated effort: 1-2 days\n\n#### 1.2 IndexingService Output Format Alignment\n- [ ] **Fix IndexingService Test Failures** (Links to #631)\n  - Align test expectations with actual CLI output format\n  - Ensure backward compatibility testing\n  - Validate codebase intelligence output consistency\n  - Estimated effort: 0.5-1 day\n\n### Phase 2: CI Pipeline Stabilization (Week 1-2)\n\n#### 2.1 Container Build Reliability\n- [ ] **Investigate and Fix Container Build Failures**\n  - Analyze GitHub Actions container build logs\n  - Fix dependency resolution issues\n  - Ensure cross-platform build consistency\n  - Test multi-architecture support\n  - Estimated effort: 1-2 days\n\n#### 2.2 Supply Chain Security\n- [ ] **Resolve Supply Chain Security Check Failures**\n  - Update vulnerable dependencies\n  - Configure proper security scanning\n  - Document security exceptions if needed\n  - Estimated effort: 0.5-1 day\n\n#### 2.3 Deployment Pipeline\n- [ ] **Fix Railway Deployment Issues**\n  - Debug deployment configuration\n  - Test deployment process end-to-end\n  - Ensure production readiness\n  - Estimated effort: 1 day\n\n### Phase 3: Enhanced Integration Testing (Week 2)\n\n#### 3.1 Codebase Intelligence Integration Tests\n- [ ] **Comprehensive Dogfooding Test Suite**\n  - Create systematic dogfooding test scenarios\n  - Test on KotaDB's own codebase with realistic queries\n  - Validate symbol extraction >95% accuracy\n  - Ensure <10ms query latency targets\n  - Estimated effort: 2-3 days\n\n- [ ] **Real-World Integration Scenarios**\n  - Test complex codebase analysis workflows\n  - Validate concurrent access patterns\n  - Test incremental update behavior\n  - Cross-platform compatibility testing\n  - Estimated effort: 1-2 days\n\n#### 3.2 Performance Regression Testing\n- [ ] **Restore Performance Baselines**\n  - Re-establish performance benchmarks post-v0.6.0\n  - Ensure no regression from disabled tests\n  - Document performance characteristics\n  - Estimated effort: 0.5-1 day\n\n## Anti-Mock Testing Requirements\n\nAll test fixes MUST follow KotaDB's anti-mock philosophy:\n\n### ✅ Required Patterns\n- Use `TempDir::new()` for isolated test environments\n- Employ real storage/index implementations\n- Use failure injection: `FlakyStorage`, `DiskFullStorage`, `SlowStorage`, `CorruptedStorage`\n- Test with actual file I/O, network calls, and database operations\n- Use builder patterns: `create_test_storage()`, `create_test_document()`\n\n### ❌ Forbidden Patterns\n- NO mocks or stubs\n- NO fake implementations\n- NO bypassing real component behavior\n\n## Acceptance Criteria\n\n### Phase 1 Complete When:\n- [ ] All previously disabled tests are re-enabled and passing\n- [ ] No `#[ignore]` annotations remain on tests\n- [ ] Git repository setup works reliably in all test files\n- [ ] IndexingService tests align with actual output formats\n\n### Phase 2 Complete When:\n- [ ] GitHub Actions CI pipeline passes consistently (>95% success rate)\n- [ ] Container builds succeed across all supported platforms\n- [ ] Supply chain security checks pass\n- [ ] Railway deployment pipeline works end-to-end\n\n### Phase 3 Complete When:\n- [ ] Comprehensive dogfooding test suite covers major codebase intelligence features\n- [ ] Integration tests validate real-world usage patterns\n- [ ] Performance baselines are documented and regression tests exist\n- [ ] Test coverage reports show >90% integration coverage\n\n## Success Metrics\n\n- **Test Coverage**: Achieve >90% integration test coverage\n- **CI Reliability**: >95% success rate for GitHub Actions pipeline\n- **Performance**: Maintain <10ms query latency for codebase intelligence\n- **Quality Gate**: All tests pass with `just check` before merging any fixes\n- **Timeline**: Complete within 2 weeks of issue creation\n\n## Risk Mitigation\n\n- **Low Risk**: Core functionality already works correctly in v0.6.0\n- **Incremental Approach**: Fix one component at a time with validation\n- **Rollback Plan**: Each fix can be isolated if issues arise\n- **Communication**: Update this issue with progress every 2 days\n\n## Related Issues\n\n- Closes #631: IndexingService tests failing due to output format changes\n- Follow-up to #509: Git repository setup issues (resolved patterns to apply)\n- Part of ongoing technical debt reduction strategy\n\n---\n\n**Labels Applied**: `technical-debt`, `priority-high`, `tests`, `bug`, `integration`, `post-release`, `effort-large`\n\n🤖 Generated with [Claude Code](https://claude.ai/code)","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/633/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/633/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/631","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/631/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/631/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/631/events","html_url":"https://github.com/kotadb/kota-db/issues/631","id":3395488560,"node_id":"I_kwDOPFZ-b87KYwsw","number":631,"title":"Release blocker: IndexingService tests failing due to output format changes","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504068,"node_id":"LA_kwDOPFZ-b88AAAACEQVxxA","url":"https://api.github.com/repos/kotadb/kota-db/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":9066998377,"node_id":"LA_kwDOPFZ-b88AAAACHG9qaQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/production-blocker","name":"production-blocker","color":"b60205","default":false,"description":"Issues blocking production deployment"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9228371228,"node_id":"LA_kwDOPFZ-b88AAAACJg3FHA","url":"https://api.github.com/repos/kotadb/kota-db/labels/test-failures","name":"test-failures","color":"d93f0b","default":false,"description":"Test suite failures and race conditions"},{"id":9253151945,"node_id":"LA_kwDOPFZ-b88AAAACJ4fkyQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/launch-prep","name":"launch-prep","color":"d93f0b","default":false,"description":"Launch preparation tasks and cleanup"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":{"url":"https://api.github.com/repos/kotadb/kota-db/milestones/5","html_url":"https://github.com/kotadb/kota-db/milestone/5","labels_url":"https://api.github.com/repos/kotadb/kota-db/milestones/5/labels","id":13683962,"node_id":"MI_kwDOPFZ-b84A0Mz6","number":5,"title":"Stabilization Sprint (Pre-Launch)","description":"Stabilize test/security/infra before new feature work: fix failing tests, security audit, CI stability. Short-lived milestone to unblock launch.","creator":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"open_issues":4,"closed_issues":1,"state":"open","created_at":"2025-09-13T16:13:49Z","updated_at":"2025-09-19T16:54:34Z","due_on":"2025-09-18T07:00:00Z","closed_at":null},"comments":2,"created_at":"2025-09-08T19:52:26Z","updated_at":"2025-09-13T16:13:54Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Problem\n\nMultiple tests in `indexing_service_test.rs` are failing during the v0.6.0 release, blocking the release process.\n\n### Failing Tests\n- test_index_codebase_basic_functionality\n- test_index_codebase_memory_limits  \n- test_index_codebase_quiet_mode\n- test_index_codebase_with_symbol_extraction\n- test_index_codebase_without_symbol_extraction\n- test_index_git_repository_fallback\n- test_indexing_service_large_file_handling\n\n### Root Cause\nThe tests expect specific output format like `\"Stored 1 files from repository \"example-repo\"` but are receiving empty strings, suggesting recent changes to the IndexingService output format.\n\n### Error Example\n```\nassertion failed: `(left == right)`\n  left: `\"\"`,\n  right: `\"Stored 1 files from repository \"example-repo\"`\n```\n\n### Context\n- Discovered during v0.6.0 release process  \n- Similar to recently fixed CLI interface tests that required updating for new default context behavior\n- System functionality verified working through comprehensive API dogfooding\n\n### Next Steps\n1. Update tests to match current IndexingService output format\n2. Verify IndexingService functionality through integration testing\n3. Complete v0.6.0 release\n\n### Impact\n- **Severity**: Release blocker\n- **Priority**: High\n- **Component**: IndexingService, Testing\n\n### Related\n- Similar to recently fixed search-code CLI tests (commit aeffc0c6)\n- Part of broader output format standardization in recent releases\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/631/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/631/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/608","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/608/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/608/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/608/events","html_url":"https://github.com/kotadb/kota-db/issues/608","id":3392007169,"node_id":"I_kwDOPFZ-b87KLewB","number":608,"title":"Epic: Comprehensive Dogfooding & System Validation Framework","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998489,"node_id":"LA_kwDOPFZ-b88AAAACHG9q2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/mcp","name":"mcp","color":"0052cc","default":false,"description":"Model Context Protocol related"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9118359001,"node_id":"LA_kwDOPFZ-b88AAAACH38d2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/dogfooding","name":"dogfooding","color":"6f42c1","default":false,"description":"Self-analysis and validation features"},{"id":9118359024,"node_id":"LA_kwDOPFZ-b88AAAACH38d8A","url":"https://api.github.com/repos/kotadb/kota-db/labels/validation","name":"validation","color":"c2e0c6","default":false,"description":"Validation and testing of features"},{"id":9241936928,"node_id":"LA_kwDOPFZ-b88AAAACJtzEIA","url":"https://api.github.com/repos/kotadb/kota-db/labels/epic","name":"epic","color":"8B5CF6","default":false,"description":"Large multi-issue initiatives and feature collections"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-07T21:06:37Z","updated_at":"2025-09-07T21:06:37Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"# Epic: Comprehensive Dogfooding & System Validation Framework\n\n## Overview\nEstablish systematic dogfooding practices and comprehensive system validation to ensure KotaDB's reliability, performance, and real-world usability through continuous self-testing and validation protocols.\n\n## Objectives\n- Implement comprehensive dogfooding testing results framework\n- Establish architecture insights collection and analysis system\n- Resolve infrastructure debugging and observability gaps\n- Validate MCP server protocol compliance and performance\n- Create systematic testing session protocols for quality assurance\n\n## Scope of Work\n\n### 🔬 Dogfooding Infrastructure\n- [ ] Comprehensive testing results collection and analysis framework\n- [ ] Architecture insights extraction and documentation system\n- [ ] Real-world usage pattern analysis and optimization recommendations\n- [ ] Performance baseline establishment through self-analysis\n- [ ] Automated dogfooding validation pipeline integration\n\n### 🛠️ System Validation Components  \n- [ ] MCP server protocol validation and compliance testing\n- [ ] Infrastructure debugging capabilities and observability tooling\n- [ ] Systematic testing session protocols and documentation\n- [ ] Performance regression detection through dogfooding metrics\n- [ ] Quality assurance validation checkpoints\n\n### 📊 Validation Metrics\n- [ ] Dogfooding test coverage across all major features\n- [ ] MCP server reliability and protocol compliance scores\n- [ ] Infrastructure debugging success rate and mean resolution time\n- [ ] Performance benchmarks validated through real usage\n- [ ] Quality metrics derived from systematic testing sessions\n\n### 🎯 Deliverables\n- [ ] Comprehensive dogfooding testing framework and results dashboard\n- [ ] Architecture insights collection and analysis system\n- [ ] Enhanced infrastructure debugging and troubleshooting capabilities\n- [ ] MCP server validation suite with protocol compliance testing\n- [ ] Systematic testing session protocols and quality gates\n\n## Related Issues (Being Consolidated)\nThis epic consolidates and replaces the following issues:\n- #471: Dogfooding Comprehensive Testing Results\n- #514: Dogfooding Report - Architecture Insights  \n- #513: Cannot debug infrastructure issues\n- #540: MCP Server Protocol Validation\n- #543: MCP Server Testing Session\n\n## Implementation Strategy\n1. **Phase 1**: Infrastructure debugging and observability improvements\n2. **Phase 2**: Dogfooding testing framework development\n3. **Phase 3**: MCP server validation and protocol compliance testing\n4. **Phase 4**: Architecture insights collection and analysis\n5. **Phase 5**: Systematic testing session protocols and quality gates\n\n## Success Criteria\n- [ ] Comprehensive dogfooding results available for all major features\n- [ ] Architecture insights automatically collected and analyzed\n- [ ] Infrastructure issues can be debugged efficiently with proper tooling\n- [ ] MCP server protocol validation passes 100% compliance tests\n- [ ] Systematic testing sessions prevent regressions and catch issues early\n\n## Quality Gates\n- [ ] All dogfooding tests pass before major releases\n- [ ] Architecture insights inform development decisions\n- [ ] Infrastructure debugging resolves issues within defined SLAs\n- [ ] MCP server maintains protocol compliance across all operations\n- [ ] Testing sessions validate quality metrics meet project standards\n\n## Acceptance Criteria\n- [ ] All consolidated issues' requirements fulfilled\n- [ ] Dogfooding framework operational and generating insights\n- [ ] Infrastructure debugging capabilities restored and enhanced\n- [ ] MCP server validation integrated into CI/CD pipeline\n- [ ] Quality assurance process incorporates systematic testing protocols\n\n---\n*Epic created as part of KotaDB issue consolidation initiative. Replaces 5 individual issues with single tracked initiative.*","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/608/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/608/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/607","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/607/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/607/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/607/events","html_url":"https://github.com/kotadb/kota-db/issues/607","id":3392004116,"node_id":"I_kwDOPFZ-b87KLeAU","number":607,"title":"Epic: CI/CD Performance Optimization & Multi-Tier Architecture","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998567,"node_id":"LA_kwDOPFZ-b88AAAACHG9rJw","url":"https://api.github.com/repos/kotadb/kota-db/labels/performance","name":"performance","color":"fbca04","default":false,"description":"Performance related issues"},{"id":9117255494,"node_id":"LA_kwDOPFZ-b88AAAACH25HRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/ci/cd","name":"ci/cd","color":"ffd33d","default":false,"description":"Continuous Integration/Deployment issues"},{"id":9117255530,"node_id":"LA_kwDOPFZ-b88AAAACH25Hag","url":"https://api.github.com/repos/kotadb/kota-db/labels/infrastructure","name":"infrastructure","color":"6c757d","default":false,"description":"Infrastructure and environment issues"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9241936928,"node_id":"LA_kwDOPFZ-b88AAAACJtzEIA","url":"https://api.github.com/repos/kotadb/kota-db/labels/epic","name":"epic","color":"8B5CF6","default":false,"description":"Large multi-issue initiatives and feature collections"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-07T21:04:47Z","updated_at":"2025-09-07T21:04:47Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"# Epic: CI/CD Performance Optimization & Multi-Tier Architecture\n\n## Overview\nComprehensive initiative to optimize KotaDB's CI/CD pipeline for faster builds, efficient resource usage, and improved developer experience through advanced compilation strategies and architectural improvements.\n\n## Objectives\n- Implement single-compilation strategy to eliminate redundant builds\n- Deploy multi-tier CI/CD architecture for optimal resource utilization\n- Migrate to cargo-nextest archive system for faster test execution\n- Resolve integration test timeouts and CI instability issues\n- Achieve sub-5-minute full CI pipeline execution\n\n## Scope of Work\n\n### 🚀 Performance Optimizations\n- [ ] Single-compilation strategy implementation across all CI jobs\n- [ ] cargo-nextest archive migration for test execution speed\n- [ ] Multi-tier CI/CD architecture deployment\n- [ ] Integration test timeout resolution and optimization\n- [ ] Parallel job execution and dependency optimization\n\n### 🏗️ Architecture Components\n- [ ] Tier 1: Fast feedback (lint, format, unit tests) <2 minutes\n- [ ] Tier 2: Integration testing with proper timeout handling <5 minutes  \n- [ ] Tier 3: Full validation (E2E, performance, security) <10 minutes\n- [ ] Artifact caching and reuse between tiers\n- [ ] Smart job scheduling based on change detection\n\n### 📊 Performance Targets\n- [ ] Total CI pipeline time: <10 minutes (from current ~20+ minutes)\n- [ ] Fast feedback loop: <2 minutes for basic checks\n- [ ] Zero timeout failures in integration tests\n- [ ] 50% reduction in CI resource consumption\n- [ ] 90% reduction in compilation redundancy\n\n### 🎯 Deliverables\n- [ ] Optimized GitHub Actions workflows with multi-tier execution\n- [ ] cargo-nextest integration with archive-based test execution\n- [ ] Smart compilation caching and artifact reuse\n- [ ] Resolved integration test stability issues\n- [ ] CI/CD performance monitoring and alerting\n\n## Related Issues (Being Consolidated)\nThis epic consolidates and replaces the following issues:\n- #563: CI single-compilation optimization strategy\n- #567: cargo-nextest archive migration for faster testing\n- #568: Multi-Tier CI/CD Architecture implementation  \n- #253: Integration tests timing out in CI environment\n\n## Implementation Strategy\n1. **Phase 1**: Single-compilation strategy and caching optimization\n2. **Phase 2**: cargo-nextest archive system migration\n3. **Phase 3**: Multi-tier architecture deployment\n4. **Phase 4**: Integration test timeout resolution and stability\n5. **Phase 5**: Performance monitoring and continuous optimization\n\n## Success Metrics\n- [ ] CI pipeline execution time reduced by >50%\n- [ ] Zero integration test timeout failures over 2 weeks\n- [ ] Developer feedback time <2 minutes for basic checks\n- [ ] Resource usage efficiency improved by >40%\n- [ ] Build artifact reuse rate >80% across jobs\n\n## Acceptance Criteria\n- [ ] All consolidated issues' requirements fulfilled\n- [ ] Multi-tier CI/CD architecture fully operational\n- [ ] cargo-nextest archive system successfully integrated\n- [ ] Integration test timeouts completely resolved\n- [ ] Performance targets achieved and sustained\n\n---\n*Epic created as part of KotaDB issue consolidation initiative. Replaces 4 individual issues with single tracked initiative.*","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/607/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/607/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/606","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/606/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/606/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/606/events","html_url":"https://github.com/kotadb/kota-db/issues/606","id":3392001201,"node_id":"I_kwDOPFZ-b87KLdSx","number":606,"title":"Epic: Testing Infrastructure Overhaul & Pyramid Rebalancing","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998984,"node_id":"LA_kwDOPFZ-b88AAAACHG9syA","url":"https://api.github.com/repos/kotadb/kota-db/labels/tests","name":"tests","color":"c2e0c6","default":false,"description":"Testing related"},{"id":9117255530,"node_id":"LA_kwDOPFZ-b88AAAACH25Hag","url":"https://api.github.com/repos/kotadb/kota-db/labels/infrastructure","name":"infrastructure","color":"6c757d","default":false,"description":"Infrastructure and environment issues"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9241936928,"node_id":"LA_kwDOPFZ-b88AAAACJtzEIA","url":"https://api.github.com/repos/kotadb/kota-db/labels/epic","name":"epic","color":"8B5CF6","default":false,"description":"Large multi-issue initiatives and feature collections"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":{"url":"https://api.github.com/repos/kotadb/kota-db/milestones/5","html_url":"https://github.com/kotadb/kota-db/milestone/5","labels_url":"https://api.github.com/repos/kotadb/kota-db/milestones/5/labels","id":13683962,"node_id":"MI_kwDOPFZ-b84A0Mz6","number":5,"title":"Stabilization Sprint (Pre-Launch)","description":"Stabilize test/security/infra before new feature work: fix failing tests, security audit, CI stability. Short-lived milestone to unblock launch.","creator":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"open_issues":4,"closed_issues":1,"state":"open","created_at":"2025-09-13T16:13:49Z","updated_at":"2025-09-19T16:54:34Z","due_on":"2025-09-18T07:00:00Z","closed_at":null},"comments":0,"created_at":"2025-09-07T21:03:02Z","updated_at":"2025-09-13T16:13:58Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"# Epic: Testing Infrastructure Overhaul & Pyramid Rebalancing\n\n## Overview\nComprehensive initiative to redesign and optimize KotaDB's testing infrastructure for improved reliability, speed, and maintainability.\n\n## Objectives\n- Implement proper testing pyramid with balanced unit/integration/E2E tests\n- Achieve 3-5x faster test execution through cargo-nextest and optimization  \n- Establish multi-tier CI/CD architecture for efficient testing\n- Create robust E2E test layer for codebase intelligence features\n- Integrate service layer testing for comprehensive validation\n\n## Scope of Work\n\n### 🔧 Infrastructure Components\n- [ ] Testing pyramid compliance and rebalancing\n- [ ] Multi-tier CI/CD architecture implementation\n- [ ] cargo-nextest archive migration for speed optimization  \n- [ ] E2E test layer development for codebase intelligence\n- [ ] Service layer integration testing framework\n- [ ] Development freeze coordination for major changes\n\n### 📊 Success Metrics  \n- [ ] Test execution time reduced by 3-5x\n- [ ] Proper test pyramid ratios achieved (70% unit, 20% integration, 10% E2E)\n- [ ] All critical codebase intelligence workflows covered by E2E tests\n- [ ] CI pipeline optimized for single-compilation strategy\n- [ ] Zero flaky tests in core test suites\n\n### 🎯 Deliverables\n- [ ] Redesigned testing system architecture\n- [ ] Optimized CI/CD pipeline with multi-tier execution\n- [ ] Comprehensive E2E test coverage for key features\n- [ ] Service layer integration test framework\n- [ ] Documentation for new testing practices and standards\n\n## Related Issues (Being Consolidated)\nThis epic consolidates and replaces the following issues:\n- #551: Development Freeze for Testing Overhaul  \n- #548: Testing System Redesign\n- #554: Testing Pyramid Compliance\n- #562: Testing Pyramid Rebalancing Phase 3\n- #569: E2E Test Layer Implementation  \n- #571: Service Layer Integration Testing\n\n## Implementation Strategy\n1. **Phase 1**: Infrastructure setup (cargo-nextest, CI optimization)\n2. **Phase 2**: Test pyramid rebalancing and cleanup  \n3. **Phase 3**: E2E test layer development\n4. **Phase 4**: Service layer integration testing\n5. **Phase 5**: Documentation and developer onboarding\n\n## Acceptance Criteria\n- [ ] All consolidated issues' requirements fulfilled\n- [ ] Test execution performance targets achieved\n- [ ] CI/CD pipeline optimized and stable\n- [ ] E2E test coverage for all critical paths\n- [ ] Team able to run full test suite locally <2 minutes\n\n---\n*Epic created as part of KotaDB issue consolidation initiative. Replaces 6 individual issues with single tracked initiative.*","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/606/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/606/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/599","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/599/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/599/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/599/events","html_url":"https://github.com/kotadb/kota-db/issues/599","id":3391827060,"node_id":"I_kwDOPFZ-b87KKyx0","number":599,"title":"[Dogfogging] BenchmarkService validation reveals implementation gaps and ineffective tests","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504068,"node_id":"LA_kwDOPFZ-b88AAAACEQVxxA","url":"https://api.github.com/repos/kotadb/kota-db/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":9066998984,"node_id":"LA_kwDOPFZ-b88AAAACHG9syA","url":"https://api.github.com/repos/kotadb/kota-db/labels/tests","name":"tests","color":"c2e0c6","default":false,"description":"Testing related"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9118359001,"node_id":"LA_kwDOPFZ-b88AAAACH38d2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/dogfooding","name":"dogfooding","color":"6f42c1","default":false,"description":"Self-analysis and validation features"},{"id":9232903925,"node_id":"LA_kwDOPFZ-b88AAAACJlLu9Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/service-architecture","name":"service-architecture","color":"1d76db","default":false,"description":"Service layer architecture and design"},{"id":9232903957,"node_id":"LA_kwDOPFZ-b88AAAACJlLvFQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/pre-launch","name":"pre-launch","color":"d93f0b","default":false,"description":"Pre-launch validation and preparation"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-07T17:23:20Z","updated_at":"2025-09-07T17:23:20Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n\nComprehensive dogfooding validation of BenchmarkService completed as part of pre-launch service validation initiative (#581) reveals significant implementation gaps and ineffective testing infrastructure that undermines the reliability of performance benchmarking capabilities.\n\n**Context**: This validation was performed using the mandatory dogfooding protocol with fresh indexing of KotaDB's own codebase to validate real-world functionality.\n\n## ✅ WORKING CORRECTLY\n\n### Core Functionality\n- **Basic benchmark operations**: CLI `kotadb benchmark` command executes successfully\n- **Performance targets**: Achieving ~800 ops/sec with 1.2ms average latency, meeting <10ms targets specified in AGENT.md\n- **Output formats**: All formats work correctly (human-readable, JSON, CSV)\n- **Interface parity**: Available consistently across:\n  - CLI: `kotadb benchmark --operations 1000`\n  - HTTP API: `/api/benchmark` endpoint  \n  - MCP: `kotadb://benchmark_performance` tool\n\n### Specific Features\n- **Benchmark types**: `--benchmark-type` flag works for storage, index, query, search, and all\n- **Operation scaling**: Can handle different operation counts (tested 100-10,000 ops)\n- **Resource monitoring**: Basic memory and timing metrics collected\n\n## ❌ CRITICAL ISSUES FOUND\n\n### 1. Implementation Gaps - **HIGH PRIORITY**\n\nLarge portions of BenchmarkService contain TODO placeholders instead of actual implementations:\n\n**In `src/services/benchmark_service.rs`:**\n```rust\n// These methods return placeholder data instead of real analysis\npub async fn stress_test(&self) -> Result<StressTestReport> {\n    // TODO: Implement actual stress testing\n    Ok(StressTestReport {\n        max_throughput: 1000, // Placeholder value\n        // ...\n    })\n}\n\npub async fn regression_test(&self) -> Result<RegressionReport> {\n    // TODO: Compare against stored baselines\n    unimplemented!(\"Regression testing not yet implemented\")\n}\n\npub async fn capacity_planning(&self) -> Result<CapacityReport> {\n    // TODO: Implement capacity analysis\n    Ok(CapacityReport::default()) // Stub implementation\n}\n```\n\n**All `benchmark_*_operations()` methods** just call the same placeholder storage benchmark instead of testing their specific subsystems.\n\n### 2. Test Infrastructure Problems - **HIGH PRIORITY**\n\n**File: `tests/benchmark_command_test.rs`**\n- Contains only mock stubs that validate nothing meaningful\n- `run_benchmark_command()` helper returns static strings instead of running real benchmarks\n- Tests pass but provide zero confidence in actual functionality\n- No integration with actual BenchmarkService\n\n**Example of ineffective test:**\n```rust\n#[tokio::test]\nasync fn test_benchmark_command() {\n    let result = run_benchmark_command(\"1000\").await;\n    assert!(result.contains(\"operations\")); // Validates only static string\n}\n```\n\n### 3. Missing Advanced Features - **MEDIUM PRIORITY**\n\nFeatures advertised but not implemented:\n- **Stress testing**: No real concurrent load testing\n- **Regression analysis**: No baseline comparison capability  \n- **Capacity planning**: No analysis of system limits\n- **Warmup operations**: Not implemented despite being in interface\n- **Concurrent benchmarking**: Single-threaded execution only\n\n## 🔧 RECOMMENDATIONS\n\n### Immediate Actions (HIGH Priority)\n1. **Replace placeholder implementations** with real benchmark operations\n2. **Implement actual stress testing** with configurable concurrent load\n3. **Add regression testing** with baseline storage and comparison\n4. **Replace mock tests** with real integration tests using actual BenchmarkService\n\n### Medium Priority Actions  \n1. **Implement capacity planning** analysis of system limits\n2. **Add warmup operations** to eliminate JIT/caching effects from measurements\n3. **Add concurrent benchmarking** capabilities for realistic load testing\n\n### Testing Strategy Improvements\n1. **Real integration tests** that exercise actual BenchmarkService methods\n2. **Performance regression detection** in CI/CD pipeline\n3. **Dogfooding integration** as part of standard test suite\n\n## Impact Assessment\n\n**Current State**: BenchmarkService appears functional but is largely unimplemented, creating false confidence in performance validation capabilities.\n\n**Risk Level**: MEDIUM - While basic benchmarking works, advanced features needed for production performance validation are missing.\n\n**User Impact**: AI assistants and developers relying on advanced benchmarking features will encounter unimplemented functionality.\n\n## Related Issues\n\n- Part of #581 (BenchmarkService pre-launch validation)\n- Supports #575 (Broader service validation initiative) \n- Relates to production readiness goals for service architecture\n\n## Testing Evidence\n\n**Validation performed:**\n```bash\n# Fresh dogfooding setup\nrm -rf data/analysis && mkdir -p data/analysis\ncargo run --bin kotadb -- -d ./data/analysis index-codebase .\n\n# Core functionality testing\ncargo run --bin kotadb -- -d ./data/analysis benchmark --operations 1000\ntime cargo run --release --bin kotadb -- -d ./data/analysis benchmark --operations 5000\n\n# Output format validation  \ncargo run --bin kotadb -- -d ./data/analysis benchmark --operations 500 --format json\n```\n\n**Results:** Basic operations work, advanced features return placeholder data.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/599/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/599/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/598","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/598/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/598/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/598/events","html_url":"https://github.com/kotadb/kota-db/issues/598","id":3391794438,"node_id":"I_kwDOPFZ-b87KKq0G","number":598,"title":"Cloud Storage & GitHub Integration Architecture: Auto-Indexing with Supabase + Fly.io","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9117255530,"node_id":"LA_kwDOPFZ-b88AAAACH25Hag","url":"https://api.github.com/repos/kotadb/kota-db/labels/infrastructure","name":"infrastructure","color":"6c757d","default":false,"description":"Infrastructure and environment issues"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9120926036,"node_id":"LA_kwDOPFZ-b88AAAACH6ZJVA","url":"https://api.github.com/repos/kotadb/kota-db/labels/architecture","name":"architecture","color":"1d76db","default":false,"description":"Architectural design and structural issues"},{"id":9241044240,"node_id":"LA_kwDOPFZ-b88AAAACJs8lEA","url":"https://api.github.com/repos/kotadb/kota-db/labels/cloud-storage","name":"cloud-storage","color":"0052cc","default":false,"description":"Cloud storage backend and multi-tenant functionality"},{"id":9241044267,"node_id":"LA_kwDOPFZ-b88AAAACJs8lKw","url":"https://api.github.com/repos/kotadb/kota-db/labels/github-integration","name":"github-integration","color":"0366d6","default":false,"description":"GitHub API integration and webhook functionality"},{"id":9241936928,"node_id":"LA_kwDOPFZ-b88AAAACJtzEIA","url":"https://api.github.com/repos/kotadb/kota-db/labels/epic","name":"epic","color":"8B5CF6","default":false,"description":"Large multi-issue initiatives and feature collections"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":{"url":"https://api.github.com/repos/kotadb/kota-db/milestones/4","html_url":"https://github.com/kotadb/kota-db/milestone/4","labels_url":"https://api.github.com/repos/kotadb/kota-db/milestones/4/labels","id":13633840,"node_id":"MI_kwDOPFZ-b84A0Akw","number":4,"title":"v1.0.0","description":"Major architectural initiatives for v1.0.0","creator":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"open_issues":1,"closed_issues":0,"state":"open","created_at":"2025-09-07T21:13:21Z","updated_at":"2025-09-07T21:15:05Z","due_on":"2025-03-31T07:00:00Z","closed_at":null},"comments":1,"created_at":"2025-09-07T16:48:44Z","updated_at":"2025-09-07T21:15:06Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"# Cloud Storage & GitHub Integration Architecture: Auto-Indexing with Supabase + Fly.io\n\n## Overview\n\nThis issue outlines the comprehensive architecture for multi-tenant cloud storage with automatic GitHub repository indexing. This system will leverage KotaDB's existing components (git ingestion, Supabase integration, services layer) to provide zero-friction GitHub repository indexing with automatic updates via webhooks.\n\n**Key Goals:**\n- One-click repository setup with automatic indexing\n- Real-time incremental updates via GitHub webhooks  \n- Multi-tenant data isolation with row-level security\n- Scalable, cost-efficient serverless architecture\n- Granular token accounting for usage-based pricing\n- Superior developer experience with instant code intelligence\n\n---\n\n## Current Architecture Assessment\n\n### Already Implemented ✅\n1. **Git Ingestion Module** (`src/git/`)\n   - Complete repository cloning and processing\n   - File content extraction and symbol parsing\n   - Incremental updates via git diff detection\n   - Tree-sitter based AST parsing\n\n2. **Supabase Integration** (`src/supabase.rs`)\n   - Database connection management\n   - Row-level security foundation\n   - Basic CRUD operations for documents and metadata\n\n3. **Services Layer** (`src/services/`)\n   - Document and index management services\n   - Validation and sanitization infrastructure\n   - Modular service architecture with dependency injection\n\n4. **High-Performance Indexing**\n   - Primary B+ tree index for path-based lookups\n   - Trigram index for full-text search\n   - Vector index for semantic search\n   - Symbol extraction and relationship tracking\n\n### Missing Components 🚧\n- GitHub API integration and webhook handling\n- Multi-tenant repository management\n- Incremental indexing orchestration\n- Token accounting and usage tracking\n- Production deployment infrastructure\n\n---\n\n## Proposed Architecture\n\n### System Overview\n```\n┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐\n│   GitHub API    │───▶│   Fly.io Worker  │───▶│   Supabase DB   │\n│                 │    │                  │    │                 │\n│ • Webhooks      │    │ • Webhook Handler│    │ • Multi-tenant  │\n│ • Repository    │    │ • Git Ingestion  │    │ • Documents     │\n│ • File Content  │    │ • Index Update   │    │ • Symbols       │\n│ • Commit Data   │    │ • Token Tracking │    │ • Jobs Queue    │\n└─────────────────┘    └──────────────────┘    └─────────────────┘\n         │                       │                       │\n         │              ┌──────────────────┐             │\n         └─────────────▶│   Client API     │◀────────────┘\n                        │                  │\n                        │ • Authentication │\n                        │ • Query Interface│\n                        │ • Usage Tracking │\n                        └──────────────────┘\n```\n\n### Data Flow Architecture\n1. **Repository Registration**: User connects GitHub repo → System creates tenant record\n2. **Initial Indexing**: Full clone and index → Background job processes all files  \n3. **Webhook Updates**: GitHub pushes changes → Incremental processing → Index updates\n4. **Query Processing**: Client queries → Multi-tenant filtering → Results with usage tracking\n\n---\n\n## Supabase Database Schema\n\n### Enhanced Multi-Tenant Schema\n```sql\n-- Repositories table (tenant isolation)\nCREATE TABLE repositories (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    user_id UUID NOT NULL REFERENCES auth.users(id),\n    github_repo_id BIGINT UNIQUE NOT NULL,\n    owner TEXT NOT NULL,\n    name TEXT NOT NULL,\n    full_name TEXT NOT NULL, -- \"owner/repo\"\n    clone_url TEXT NOT NULL,\n    default_branch TEXT NOT NULL DEFAULT 'main',\n    webhook_secret TEXT,\n    last_indexed_at TIMESTAMPTZ,\n    indexing_status TEXT DEFAULT 'pending', -- pending, indexing, completed, failed\n    created_at TIMESTAMPTZ DEFAULT NOW(),\n    updated_at TIMESTAMPTZ DEFAULT NOW(),\n    \n    CONSTRAINT repositories_user_repo_unique UNIQUE(user_id, github_repo_id)\n);\n\n-- Enhanced documents table with repository context\nCREATE TABLE documents (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    repository_id UUID NOT NULL REFERENCES repositories(id) ON DELETE CASCADE,\n    user_id UUID NOT NULL REFERENCES auth.users(id),\n    path TEXT NOT NULL,\n    content TEXT NOT NULL,\n    language TEXT,\n    file_hash TEXT NOT NULL, -- SHA256 for change detection\n    size_bytes INTEGER NOT NULL,\n    line_count INTEGER,\n    commit_sha TEXT NOT NULL,\n    last_modified TIMESTAMPTZ NOT NULL,\n    indexed_at TIMESTAMPTZ DEFAULT NOW(),\n    \n    CONSTRAINT documents_repo_path_unique UNIQUE(repository_id, path)\n);\n\n-- Symbols table for code intelligence\nCREATE TABLE symbols (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    repository_id UUID NOT NULL REFERENCES repositories(id) ON DELETE CASCADE,\n    user_id UUID NOT NULL REFERENCES auth.users(id),\n    document_id UUID NOT NULL REFERENCES documents(id) ON DELETE CASCADE,\n    name TEXT NOT NULL,\n    kind TEXT NOT NULL, -- function, class, variable, etc.\n    signature TEXT,\n    line_number INTEGER NOT NULL,\n    column_number INTEGER NOT NULL,\n    definition_path TEXT NOT NULL,\n    scope TEXT, -- global, local, class, etc.\n    language TEXT NOT NULL,\n    created_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Symbol relationships (calls, imports, etc.)\nCREATE TABLE symbol_relationships (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    repository_id UUID NOT NULL REFERENCES repositories(id) ON DELETE CASCADE,\n    user_id UUID NOT NULL REFERENCES auth.users(id),\n    source_symbol_id UUID NOT NULL REFERENCES symbols(id) ON DELETE CASCADE,\n    target_symbol_id UUID NOT NULL REFERENCES symbols(id) ON DELETE CASCADE,\n    relationship_type TEXT NOT NULL, -- calls, imports, inherits, etc.\n    source_file TEXT NOT NULL,\n    source_line INTEGER NOT NULL,\n    target_file TEXT NOT NULL,\n    target_line INTEGER NOT NULL,\n    created_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Indexing jobs for background processing\nCREATE TABLE indexing_jobs (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    repository_id UUID NOT NULL REFERENCES repositories(id) ON DELETE CASCADE,\n    user_id UUID NOT NULL REFERENCES auth.users(id),\n    job_type TEXT NOT NULL, -- 'full_index', 'incremental_update', 'webhook_update'\n    status TEXT NOT NULL DEFAULT 'pending', -- pending, running, completed, failed\n    payload JSONB NOT NULL, -- commit info, file changes, etc.\n    progress JSONB DEFAULT '{}', -- {\"files_processed\": 0, \"total_files\": 0}\n    error_message TEXT,\n    started_at TIMESTAMPTZ,\n    completed_at TIMESTAMPTZ,\n    created_at TIMESTAMPTZ DEFAULT NOW(),\n    \n    INDEX idx_indexing_jobs_status ON indexing_jobs(status),\n    INDEX idx_indexing_jobs_repo_status ON indexing_jobs(repository_id, status)\n);\n\n-- Token usage tracking for billing\nCREATE TABLE token_usage (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    user_id UUID NOT NULL REFERENCES auth.users(id),\n    repository_id UUID REFERENCES repositories(id) ON DELETE SET NULL,\n    operation_type TEXT NOT NULL, -- 'query', 'index', 'webhook'\n    tokens_consumed INTEGER NOT NULL,\n    operation_details JSONB, -- query text, files indexed, etc.\n    created_at TIMESTAMPTZ DEFAULT NOW(),\n    \n    INDEX idx_token_usage_user_date ON token_usage(user_id, created_at),\n    INDEX idx_token_usage_repo_date ON token_usage(repository_id, created_at)\n);\n\n-- Row-level security policies\nALTER TABLE repositories ENABLE ROW LEVEL SECURITY;\nALTER TABLE documents ENABLE ROW LEVEL SECURITY;\nALTER TABLE symbols ENABLE ROW LEVEL SECURITY;\nALTER TABLE symbol_relationships ENABLE ROW LEVEL SECURITY;\nALTER TABLE indexing_jobs ENABLE ROW LEVEL SECURITY;\nALTER TABLE token_usage ENABLE ROW LEVEL SECURITY;\n\n-- RLS Policies\nCREATE POLICY repositories_isolation ON repositories\n    FOR ALL USING (auth.uid() = user_id);\n\nCREATE POLICY documents_isolation ON documents\n    FOR ALL USING (auth.uid() = user_id);\n\nCREATE POLICY symbols_isolation ON symbols\n    FOR ALL USING (auth.uid() = user_id);\n\n-- Indexes for performance\nCREATE INDEX idx_documents_repo_path ON documents(repository_id, path);\nCREATE INDEX idx_documents_hash ON documents(file_hash);\nCREATE INDEX idx_symbols_repo_name ON symbols(repository_id, name);\nCREATE INDEX idx_symbols_document ON symbols(document_id);\nCREATE INDEX idx_repositories_github_id ON repositories(github_repo_id);\n```\n\n---\n\n## GitHub Integration Workflow\n\n### Phase 1: Repository Registration (One-Click Setup)\n\n**Frontend Flow:**\n```typescript\n// 1. OAuth GitHub authentication\nconst githubAuth = await authenticateGitHub();\n\n// 2. Repository selection UI\nconst selectedRepos = await showRepositorySelector(githubAuth);\n\n// 3. One-click registration\nfor (const repo of selectedRepos) {\n    await registerRepository({\n        github_repo_id: repo.id,\n        owner: repo.owner.login,\n        name: repo.name,\n        full_name: repo.full_name,\n        clone_url: repo.clone_url,\n        default_branch: repo.default_branch\n    });\n}\n```\n\n**Backend Implementation:**\n```rust\n// src/services/github_service.rs\npub struct GitHubService {\n    client: GitHubClient,\n    webhook_service: WebhookService,\n}\n\nimpl GitHubService {\n    pub async fn register_repository(&self, user_id: Uuid, repo_data: GitHubRepoData) -> Result<Repository> {\n        // 1. Create repository record\n        let repository = self.supabase\n            .insert_repository(user_id, repo_data)\n            .await?;\n            \n        // 2. Setup GitHub webhook\n        let webhook_url = format!(\"{}/webhooks/github/{}\", self.base_url, repository.id);\n        let webhook_secret = generate_secure_secret();\n        \n        self.client.create_webhook(&repo_data.full_name, WebhookConfig {\n            url: webhook_url,\n            secret: webhook_secret.clone(),\n            events: vec![\"push\", \"pull_request\"],\n        }).await?;\n        \n        // 3. Update repository with webhook secret\n        self.supabase\n            .update_repository_webhook_secret(repository.id, webhook_secret)\n            .await?;\n            \n        // 4. Queue initial indexing job\n        self.queue_indexing_job(repository.id, IndexingJobType::FullIndex, serde_json::json!({\n            \"branch\": repo_data.default_branch,\n            \"commit_sha\": null // Will fetch latest\n        })).await?;\n        \n        Ok(repository)\n    }\n}\n```\n\n### Phase 2: Initial Full Indexing\n\n**Leveraging Existing Git Ingestion:**\n```rust\n// src/services/indexing_service.rs\npub struct IndexingService {\n    git_service: GitService, // Existing git ingestion\n    document_service: DocumentService,\n    symbol_service: SymbolService,\n}\n\nimpl IndexingService {\n    pub async fn process_full_index(&self, job: IndexingJob) -> Result<()> {\n        let repo = self.get_repository(job.repository_id).await?;\n        \n        // 1. Clone repository using existing git service\n        let temp_dir = self.git_service\n            .clone_repository(&repo.clone_url, &repo.default_branch)\n            .await?;\n            \n        // 2. Process all files using existing infrastructure\n        let files = self.git_service.discover_files(&temp_dir).await?;\n        \n        let mut progress = IndexingProgress::new(files.len());\n        self.update_job_progress(job.id, &progress).await?;\n        \n        for file_path in files {\n            // 3. Extract content and symbols (existing functionality)\n            let file_content = self.git_service.read_file(&file_path).await?;\n            let symbols = self.git_service.extract_symbols(&file_path, &file_content).await?;\n            \n            // 4. Store in multi-tenant database\n            let document = self.document_service.create_document(CreateDocumentRequest {\n                repository_id: job.repository_id,\n                user_id: job.user_id,\n                path: file_path.to_string(),\n                content: file_content,\n                language: detect_language(&file_path),\n                file_hash: calculate_file_hash(&file_content),\n                commit_sha: job.payload[\"commit_sha\"].as_str().unwrap().to_string(),\n            }).await?;\n            \n            // 5. Store symbols and relationships\n            for symbol in symbols {\n                self.symbol_service.create_symbol(CreateSymbolRequest {\n                    repository_id: job.repository_id,\n                    user_id: job.user_id,\n                    document_id: document.id,\n                    name: symbol.name,\n                    kind: symbol.kind,\n                    signature: symbol.signature,\n                    line_number: symbol.line_number,\n                    column_number: symbol.column_number,\n                    definition_path: file_path.to_string(),\n                    language: symbol.language,\n                }).await?;\n            }\n            \n            progress.increment();\n            self.update_job_progress(job.id, &progress).await?;\n        }\n        \n        // 6. Mark repository as indexed\n        self.update_repository_status(job.repository_id, IndexingStatus::Completed).await?;\n        self.complete_job(job.id).await?;\n        \n        cleanup_temp_directory(temp_dir);\n        Ok(())\n    }\n}\n```\n\n### Phase 3: Webhook-Driven Incremental Updates\n\n**Webhook Handler:**\n```rust\n// src/handlers/webhook_handler.rs\n#[derive(Deserialize)]\npub struct GitHubPushEvent {\n    pub repository: GitHubRepository,\n    pub commits: Vec<GitHubCommit>,\n    pub head_commit: GitHubCommit,\n}\n\npub async fn handle_github_webhook(\n    payload: GitHubPushEvent,\n    signature: String,\n    repository_id: Uuid,\n) -> Result<()> {\n    // 1. Verify webhook signature\n    verify_github_signature(&payload, &signature, &webhook_secret)?;\n    \n    // 2. Queue incremental indexing job\n    let job_payload = serde_json::json!({\n        \"commits\": payload.commits,\n        \"head_commit\": payload.head_commit,\n        \"files_changed\": extract_changed_files(&payload.commits),\n    });\n    \n    queue_indexing_job(\n        repository_id,\n        IndexingJobType::WebhookUpdate,\n        job_payload,\n    ).await?;\n    \n    Ok(())\n}\n```\n\n---\n\n## Incremental Indexing Strategy\n\n### Smart Change Detection\n```rust\npub struct FileChangeAnalyzer {\n    git_service: GitService,\n}\n\n#[derive(Debug)]\npub struct FileChange {\n    pub path: String,\n    pub change_type: ChangeType,\n    pub old_hash: Option<String>,\n    pub new_hash: Option<String>,\n    pub old_content: Option<String>,\n    pub new_content: Option<String>,\n}\n\n#[derive(Debug)]\npub enum ChangeType {\n    Added,\n    Modified,\n    Deleted,\n    Renamed { from: String, to: String },\n}\n\nimpl FileChangeAnalyzer {\n    pub async fn analyze_commit_changes(&self, commits: Vec<GitHubCommit>) -> Result<Vec<FileChange>> {\n        let mut file_changes = HashMap::new();\n        \n        for commit in commits {\n            for file in commit.added {\n                file_changes.insert(file.clone(), FileChange {\n                    path: file,\n                    change_type: ChangeType::Added,\n                    old_hash: None,\n                    new_hash: Some(commit.id.clone()),\n                    old_content: None,\n                    new_content: None, // Will be fetched\n                });\n            }\n            \n            for file in commit.modified {\n                // Check if this is actually a rename\n                if let Some(renamed_from) = self.detect_rename(&file, &commit).await? {\n                    file_changes.insert(file.clone(), FileChange {\n                        path: file,\n                        change_type: ChangeType::Renamed { \n                            from: renamed_from, \n                            to: file \n                        },\n                        old_hash: commit.parents.first().map(|p| p.id.clone()),\n                        new_hash: Some(commit.id.clone()),\n                        old_content: None,\n                        new_content: None,\n                    });\n                } else {\n                    file_changes.insert(file.clone(), FileChange {\n                        path: file,\n                        change_type: ChangeType::Modified,\n                        old_hash: commit.parents.first().map(|p| p.id.clone()),\n                        new_hash: Some(commit.id.clone()),\n                        old_content: None,\n                        new_content: None,\n                    });\n                }\n            }\n            \n            for file in commit.removed {\n                file_changes.insert(file.clone(), FileChange {\n                    path: file,\n                    change_type: ChangeType::Deleted,\n                    old_hash: commit.parents.first().map(|p| p.id.clone()),\n                    new_hash: None,\n                    old_content: None,\n                    new_content: None,\n                });\n            }\n        }\n        \n        Ok(file_changes.into_values().collect())\n    }\n}\n```\n\n### Incremental Processing Implementation\n```rust\nimpl IndexingService {\n    pub async fn process_incremental_update(&self, job: IndexingJob) -> Result<()> {\n        let commits: Vec<GitHubCommit> = serde_json::from_value(job.payload[\"commits\"].clone())?;\n        let file_changes = self.change_analyzer.analyze_commit_changes(commits).await?;\n        \n        let mut progress = IndexingProgress::new(file_changes.len());\n        self.update_job_progress(job.id, &progress).await?;\n        \n        for change in file_changes {\n            match change.change_type {\n                ChangeType::Added | ChangeType::Modified => {\n                    // Fetch new content from GitHub API\n                    let content = self.github_client\n                        .get_file_content(&job.repository.full_name, &change.path)\n                        .await?;\n                        \n                    // Extract symbols using existing infrastructure\n                    let symbols = self.git_service\n                        .extract_symbols(&change.path, &content)\n                        .await?;\n                    \n                    // Upsert document\n                    self.document_service.upsert_document(UpsertDocumentRequest {\n                        repository_id: job.repository_id,\n                        user_id: job.user_id,\n                        path: change.path.clone(),\n                        content,\n                        file_hash: change.new_hash.unwrap(),\n                        commit_sha: job.payload[\"head_commit\"][\"id\"].as_str().unwrap().to_string(),\n                    }).await?;\n                    \n                    // Update symbols - delete old, insert new\n                    self.symbol_service.delete_symbols_for_file(\n                        job.repository_id, \n                        &change.path\n                    ).await?;\n                    \n                    for symbol in symbols {\n                        self.symbol_service.create_symbol(/* ... */).await?;\n                    }\n                }\n                \n                ChangeType::Deleted => {\n                    // Remove document and all associated symbols/relationships\n                    self.document_service.delete_document_by_path(\n                        job.repository_id,\n                        &change.path\n                    ).await?;\n                }\n                \n                ChangeType::Renamed { from, to } => {\n                    // Update document path and associated symbols\n                    self.document_service.rename_document(\n                        job.repository_id,\n                        &from,\n                        &to\n                    ).await?;\n                }\n            }\n            \n            progress.increment();\n            self.update_job_progress(job.id, &progress).await?;\n        }\n        \n        self.complete_job(job.id).await?;\n        Ok(())\n    }\n}\n```\n\n---\n\n## Multi-Tenant Storage & Security\n\n### Row-Level Security Implementation\n```sql\n-- Comprehensive RLS policies for all table operations\nCREATE POLICY repositories_select ON repositories\n    FOR SELECT USING (auth.uid() = user_id);\n\nCREATE POLICY repositories_insert ON repositories  \n    FOR INSERT WITH CHECK (auth.uid() = user_id);\n\nCREATE POLICY repositories_update ON repositories\n    FOR UPDATE USING (auth.uid() = user_id) \n    WITH CHECK (auth.uid() = user_id);\n\nCREATE POLICY repositories_delete ON repositories\n    FOR DELETE USING (auth.uid() = user_id);\n\n-- Similar policies for documents, symbols, etc. with repository-based isolation\nCREATE POLICY documents_tenant_isolation ON documents\n    FOR ALL USING (\n        auth.uid() = user_id AND \n        repository_id IN (\n            SELECT id FROM repositories WHERE user_id = auth.uid()\n        )\n    );\n```\n\n### API Scoping and Authentication\n```rust\n// src/auth/tenant_context.rs\n#[derive(Debug, Clone)]\npub struct TenantContext {\n    pub user_id: Uuid,\n    pub accessible_repositories: Vec<Uuid>,\n}\n\nimpl TenantContext {\n    pub async fn from_jwt_token(token: &str, supabase: &SupabaseClient) -> Result<Self> {\n        let claims = verify_jwt_token(token)?;\n        let user_id = Uuid::parse_str(&claims.sub)?;\n        \n        // Fetch accessible repositories for this user\n        let repositories = supabase\n            .from(\"repositories\")\n            .select(\"id\")\n            .eq(\"user_id\", user_id)\n            .execute()\n            .await?;\n            \n        Ok(TenantContext {\n            user_id,\n            accessible_repositories: repositories.into_iter()\n                .map(|r| r[\"id\"].as_str().unwrap().parse().unwrap())\n                .collect(),\n        })\n    }\n    \n    pub fn can_access_repository(&self, repo_id: Uuid) -> bool {\n        self.accessible_repositories.contains(&repo_id)\n    }\n}\n\n// Middleware for automatic tenant context injection\npub async fn tenant_middleware(\n    req: Request<Body>,\n    next: Next<Body>,\n) -> Result<Response<Body>, StatusCode> {\n    let auth_header = req.headers()\n        .get(\"Authorization\")\n        .and_then(|h| h.to_str().ok())\n        .ok_or(StatusCode::UNAUTHORIZED)?;\n        \n    let token = auth_header.strip_prefix(\"Bearer \")\n        .ok_or(StatusCode::UNAUTHORIZED)?;\n        \n    let tenant_context = TenantContext::from_jwt_token(token, &supabase)\n        .await\n        .map_err(|_| StatusCode::UNAUTHORIZED)?;\n        \n    // Inject tenant context into request extensions\n    req.extensions_mut().insert(tenant_context);\n    \n    Ok(next.run(req).await)\n}\n```\n\n---\n\n## Token Accounting & Usage Tracking\n\n### Granular Usage Tracking\n```rust\n// src/services/token_service.rs\npub struct TokenService {\n    supabase: SupabaseClient,\n}\n\n#[derive(Debug)]\npub struct TokenUsage {\n    pub operation_type: OperationType,\n    pub tokens_consumed: u32,\n    pub operation_details: serde_json::Value,\n}\n\n#[derive(Debug)]\npub enum OperationType {\n    Query { query_type: String, result_count: usize },\n    Index { files_processed: usize, symbols_extracted: usize },\n    Webhook { files_updated: usize },\n    ApiRequest { endpoint: String },\n}\n\nimpl TokenService {\n    pub async fn track_usage(&self, \n        user_id: Uuid,\n        repository_id: Option<Uuid>,\n        usage: TokenUsage,\n    ) -> Result<()> {\n        self.supabase\n            .from(\"token_usage\")\n            .insert(&json!({\n                \"user_id\": user_id,\n                \"repository_id\": repository_id,\n                \"operation_type\": usage.operation_type.to_string(),\n                \"tokens_consumed\": usage.tokens_consumed,\n                \"operation_details\": usage.operation_details,\n                \"created_at\": chrono::Utc::now()\n            }))\n            .execute()\n            .await?;\n            \n        Ok(())\n    }\n    \n    pub async fn get_usage_summary(&self, \n        user_id: Uuid, \n        period: TimePeriod\n    ) -> Result<UsageSummary> {\n        let (start_date, end_date) = period.to_date_range();\n        \n        let usage_data = self.supabase\n            .from(\"token_usage\")\n            .select(\"operation_type, SUM(tokens_consumed) as total_tokens\")\n            .eq(\"user_id\", user_id)\n            .gte(\"created_at\", start_date)\n            .lte(\"created_at\", end_date)\n            .group_by(\"operation_type\")\n            .execute()\n            .await?;\n            \n        Ok(UsageSummary::from(usage_data))\n    }\n}\n\n// Usage tracking middleware\npub async fn usage_tracking_middleware(\n    req: Request<Body>,\n    next: Next<Body>,\n) -> Result<Response<Body>, StatusCode> {\n    let start_time = Instant::now();\n    let tenant_context = req.extensions().get::<TenantContext>()\n        .ok_or(StatusCode::UNAUTHORIZED)?;\n        \n    let response = next.run(req).await;\n    let duration = start_time.elapsed();\n    \n    // Calculate tokens based on operation complexity\n    let tokens = calculate_operation_tokens(&req, &response, duration);\n    \n    // Track usage asynchronously\n    tokio::spawn(async move {\n        let token_service = TokenService::new(); // Get from DI container\n        let _ = token_service.track_usage(\n            tenant_context.user_id,\n            extract_repository_id(&req),\n            TokenUsage {\n                operation_type: OperationType::ApiRequest {\n                    endpoint: req.uri().path().to_string(),\n                },\n                tokens_consumed: tokens,\n                operation_details: json!({\n                    \"duration_ms\": duration.as_millis(),\n                    \"status_code\": response.status().as_u16(),\n                }),\n            }\n        ).await;\n    });\n    \n    Ok(response)\n}\n```\n\n---\n\n## API Endpoints & Client Integration\n\n### Repository Management API\n```rust\n// src/handlers/repository_handler.rs\n\n// GET /api/repositories - List user's repositories\npub async fn list_repositories(\n    tenant: TenantContext,\n    query: Query<ListRepositoriesQuery>,\n) -> Result<Json<Vec<Repository>>, AppError> {\n    let repositories = repository_service\n        .list_repositories(tenant.user_id, query.into_inner())\n        .await?;\n    \n    // Track usage\n    token_service.track_usage(tenant.user_id, None, TokenUsage {\n        operation_type: OperationType::ApiRequest { \n            endpoint: \"list_repositories\".to_string() \n        },\n        tokens_consumed: 1,\n        operation_details: json!({ \"count\": repositories.len() }),\n    }).await?;\n    \n    Ok(Json(repositories))\n}\n\n// POST /api/repositories - Register new repository  \npub async fn register_repository(\n    tenant: TenantContext,\n    Json(payload): Json<RegisterRepositoryRequest>,\n) -> Result<Json<Repository>, AppError> {\n    let repository = github_service\n        .register_repository(tenant.user_id, payload)\n        .await?;\n        \n    token_service.track_usage(tenant.user_id, Some(repository.id), TokenUsage {\n        operation_type: OperationType::Index { \n            files_processed: 0, // Initial registration\n            symbols_extracted: 0,\n        },\n        tokens_consumed: 10, // Higher cost for setup\n        operation_details: json!({ \"repository\": repository.full_name }),\n    }).await?;\n    \n    Ok(Json(repository))\n}\n\n// GET /api/repositories/{id}/status - Get indexing status\npub async fn get_indexing_status(\n    tenant: TenantContext,\n    Path(repository_id): Path<Uuid>,\n) -> Result<Json<IndexingStatus>, AppError> {\n    ensure_repository_access(&tenant, repository_id)?;\n    \n    let status = indexing_service\n        .get_indexing_status(repository_id)\n        .await?;\n        \n    Ok(Json(status))\n}\n```\n\n### Code Intelligence API\n```rust\n// GET /api/repositories/{id}/search/code - Full-text code search\npub async fn search_code(\n    tenant: TenantContext,\n    Path(repository_id): Path<Uuid>,\n    Query(params): Query<CodeSearchParams>,\n) -> Result<Json<SearchResults>, AppError> {\n    ensure_repository_access(&tenant, repository_id)?;\n    \n    let results = search_service\n        .search_code(repository_id, &params.query, &params)\n        .await?;\n        \n    token_service.track_usage(tenant.user_id, Some(repository_id), TokenUsage {\n        operation_type: OperationType::Query { \n            query_type: \"code_search\".to_string(),\n            result_count: results.matches.len(),\n        },\n        tokens_consumed: calculate_search_tokens(&params.query, results.matches.len()),\n        operation_details: json!({\n            \"query\": params.query,\n            \"result_count\": results.matches.len(),\n        }),\n    }).await?;\n    \n    Ok(Json(results))\n}\n\n// GET /api/repositories/{id}/symbols/{symbol_id}/callers - Find function callers\npub async fn find_callers(\n    tenant: TenantContext,\n    Path((repository_id, symbol_id)): Path<(Uuid, Uuid)>,\n) -> Result<Json<Vec<SymbolReference>>, AppError> {\n    ensure_repository_access(&tenant, repository_id)?;\n    \n    let callers = symbol_service\n        .find_callers(repository_id, symbol_id)\n        .await?;\n        \n    token_service.track_usage(tenant.user_id, Some(repository_id), TokenUsage {\n        operation_type: OperationType::Query { \n            query_type: \"find_callers\".to_string(),\n            result_count: callers.len(),\n        },\n        tokens_consumed: 2, // More expensive operation\n        operation_details: json!({ \"symbol_id\": symbol_id }),\n    }).await?;\n    \n    Ok(Json(callers))\n}\n```\n\n---\n\n## Fly.io Deployment Architecture\n\n### Application Structure\n```toml\n# fly.toml\n[build]\n  builder = \"rust\"\n\n[env]\n  PORT = \"8080\"\n  RUST_LOG = \"info\"\n  \n[processes]\n  web = \"kotadb-server\"\n  worker = \"kotadb-worker\"\n\n[[services]]\n  internal_port = 8080\n  protocol = \"tcp\"\n\n[[services.ports]]\n  handlers = [\"http\"]\n  port = \"80\"\n\n[[services.ports]]\n  handlers = [\"tls\", \"http\"]\n  port = \"443\"\n\n[resources]\n  memory = \"512MB\"\n  cpu_kind = \"shared\"\n  cpus = 1\n\n# Scale configuration\n[scaling]\n  min_machines = 1\n  max_machines = 10\n```\n\n### Worker Process Implementation\n```rust\n// src/bin/kotadb_worker.rs\n#[tokio::main]\nasync fn main() -> Result<()> {\n    tracing_subscriber::init();\n    \n    let supabase = SupabaseClient::new(&env::var(\"SUPABASE_URL\")?, &env::var(\"SUPABASE_KEY\")?);\n    let services = ServiceContainer::new(supabase).await?;\n    \n    let worker = JobWorker::new(services);\n    worker.start().await?;\n    \n    Ok(())\n}\n\npub struct JobWorker {\n    indexing_service: IndexingService,\n    job_queue: JobQueue,\n}\n\nimpl JobWorker {\n    pub async fn start(&self) -> Result<()> {\n        info!(\"Starting job worker...\");\n        \n        loop {\n            // Poll for pending jobs\n            let jobs = self.job_queue.fetch_pending_jobs(10).await?;\n            \n            if jobs.is_empty() {\n                tokio::time::sleep(Duration::from_secs(5)).await;\n                continue;\n            }\n            \n            // Process jobs concurrently\n            let futures = jobs.into_iter().map(|job| {\n                let service = self.indexing_service.clone();\n                tokio::spawn(async move {\n                    service.process_job(job).await\n                })\n            });\n            \n            // Wait for all jobs to complete\n            let results = futures::future::join_all(futures).await;\n            \n            // Log results and errors\n            for result in results {\n                match result {\n                    Ok(Ok(_)) => info!(\"Job completed successfully\"),\n                    Ok(Err(e)) => error!(\"Job failed: {}\", e),\n                    Err(e) => error!(\"Job panicked: {}\", e),\n                }\n            }\n        }\n    }\n}\n```\n\n---\n\n## Performance Considerations & Optimization\n\n### Database Optimization\n```sql\n-- Comprehensive indexing strategy\nCREATE INDEX CONCURRENTLY idx_documents_repo_hash ON documents(repository_id, file_hash);\nCREATE INDEX CONCURRENTLY idx_documents_content_gin ON documents USING gin(to_tsvector('english', content));\nCREATE INDEX CONCURRENTLY idx_symbols_repo_name_kind ON symbols(repository_id, name, kind);\nCREATE INDEX CONCURRENTLY idx_symbol_relationships_source ON symbol_relationships(source_symbol_id);\nCREATE INDEX CONCURRENTLY idx_symbol_relationships_target ON symbol_relationships(target_symbol_id);\nCREATE INDEX CONCURRENTLY idx_indexing_jobs_created ON indexing_jobs(created_at) WHERE status = 'pending';\n\n-- Partitioning for large tables (future consideration)\nCREATE TABLE token_usage_2024 PARTITION OF token_usage \nFOR VALUES FROM ('2024-01-01') TO ('2025-01-01');\n```\n\n### Caching Strategy\n```rust\n// src/cache/repository_cache.rs\npub struct RepositoryCache {\n    redis: Redis,\n    ttl: Duration,\n}\n\nimpl RepositoryCache {\n    pub async fn get_search_results(&self, \n        cache_key: &str\n    ) -> Result<Option<SearchResults>> {\n        let cached = self.redis.get(cache_key).await?;\n        if let Some(data) = cached {\n            return Ok(Some(serde_json::from_str(&data)?));\n        }\n        Ok(None)\n    }\n    \n    pub async fn cache_search_results(&self, \n        cache_key: &str, \n        results: &SearchResults\n    ) -> Result<()> {\n        let serialized = serde_json::to_string(results)?;\n        self.redis\n            .setex(cache_key, self.ttl.as_secs(), serialized)\n            .await?;\n        Ok(())\n    }\n}\n\n// Cache keys based on repository state\nfn generate_search_cache_key(repo_id: Uuid, query: &str, last_indexed: DateTime<Utc>) -> String {\n    format!(\"search:{}:{}:{}\", repo_id, \n            sha256(query), \n            last_indexed.timestamp())\n}\n```\n\n### Connection Pool Configuration\n```rust\n// src/config/database.rs\npub fn create_connection_pool(database_url: &str) -> Result<PgPool> {\n    PgPoolOptions::new()\n        .max_connections(20)\n        .min_connections(5)\n        .acquire_timeout(Duration::from_secs(30))\n        .idle_timeout(Duration::from_secs(600))\n        .max_lifetime(Duration::from_secs(1800))\n        .connect_lazy(database_url)\n        .context(\"Failed to create database connection pool\")\n}\n```\n\n---\n\n## Implementation Roadmap\n\n### Phase 1: Foundation (Weeks 1-2)\n**GitHub API Integration**\n- [ ] GitHub OAuth integration for repository access\n- [ ] Repository discovery and selection UI\n- [ ] Basic webhook endpoint setup and signature verification\n- [ ] Enhanced Supabase schema deployment with migration scripts\n\n**Multi-Tenant Infrastructure** \n- [ ] Row-level security implementation and testing\n- [ ] Tenant context middleware with JWT validation\n- [ ] Repository registration service with error handling\n- [ ] Basic usage tracking infrastructure\n\n**Deliverables:**\n- Users can connect GitHub accounts and register repositories\n- Proper data isolation between tenants\n- Webhook endpoints ready for GitHub integration\n- Foundation for usage tracking\n\n### Phase 2: Core Indexing (Weeks 3-4)\n**Full Repository Indexing**\n- [ ] Integration with existing git ingestion module\n- [ ] Background job processing system with Redis/database queue\n- [ ] Symbol extraction and relationship mapping at scale\n- [ ] Progress tracking and status updates for long-running jobs\n\n**Incremental Update System**\n- [ ] Webhook event processing for push events\n- [ ] Smart change detection (added/modified/deleted/renamed files)\n- [ ] Incremental symbol and relationship updates\n- [ ] Conflict resolution for concurrent updates\n\n**Deliverables:**\n- Complete repository indexing from GitHub\n- Real-time updates via webhooks\n- Scalable background processing\n- Comprehensive symbol and relationship data\n\n### Phase 3: Production & Optimization (Weeks 5-6)\n**Performance & Scaling**\n- [ ] Database query optimization and comprehensive indexing\n- [ ] Redis caching layer for frequent queries\n- [ ] Connection pooling and resource management\n- [ ] Load testing and performance tuning\n\n**Monitoring & Operations**\n- [ ] Comprehensive logging with structured data\n- [ ] Metrics collection and alerting\n- [ ] Error tracking and recovery mechanisms\n- [ ] Health checks and monitoring dashboards\n\n**API & Client Experience**\n- [ ] Complete REST API with OpenAPI documentation\n- [ ] Rate limiting and quota management\n- [ ] Client SDKs (TypeScript/Python) with usage examples\n- [ ] Comprehensive integration testing\n\n**Deliverables:**\n- Production-ready cloud deployment\n- Sub-10ms query performance\n- Complete developer experience\n- Monitoring and operational excellence\n\n---\n\n## Benefits & Competitive Advantages\n\n### Developer Experience Benefits\n- **Zero Setup Friction**: One-click repository indexing with immediate code intelligence\n- **Real-Time Updates**: Changes reflected instantly via webhook integration\n- **Multi-Repository Support**: Unified search across entire development portfolio\n- **Native GitHub Integration**: Seamless workflow with existing development tools\n\n### Technical Benefits\n- **Scalable Architecture**: Serverless design handles traffic spikes efficiently\n- **Cost Optimization**: Usage-based pricing with granular token tracking\n- **High Performance**: Sub-10ms query latency with optimized indexing\n- **Data Security**: Multi-tenant isolation with row-level security\n\n### Business Benefits\n- **Rapid Time-to-Value**: Immediate code intelligence without infrastructure setup\n- **Predictable Costs**: Token-based pricing aligned with actual usage\n- **Enterprise Ready**: Secure multi-tenant architecture with audit trails\n- **API-First Design**: Easy integration with existing development workflows\n\n---\n\n## Success Metrics & Validation\n\n### Performance Targets\n- **Repository Indexing**: Complete indexing of 10,000+ file repositories within 5 minutes\n- **Query Latency**: <10ms for code search, <5ms for symbol lookup\n- **Webhook Processing**: <30 seconds from GitHub push to index update\n- **Uptime**: 99.9% availability with automated failover\n\n### User Experience Metrics\n- **Setup Time**: <2 minutes from GitHub connection to searchable repository\n- **Query Success Rate**: >99% for well-formed queries\n- **Update Accuracy**: >95% of changes reflected correctly in incremental updates\n- **Cost Efficiency**: <$10/month for typical developer usage patterns\n\n### Technical Validation\n- **Load Testing**: 1,000+ concurrent users, 10,000+ repositories indexed\n- **Data Integrity**: Zero data loss during incremental updates\n- **Security Compliance**: SOC 2 Type II audit readiness\n- **API Reliability**: <0.1% error rate under normal load\n\n---\n\nThis architecture represents a major evolution of KotaDB from a local tool to a comprehensive cloud platform, positioning it as the definitive solution for AI-powered code intelligence.\n\n🔬 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/598/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/598/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/591","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/591/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/591/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/591/events","html_url":"https://github.com/kotadb/kota-db/issues/591","id":3389162142,"node_id":"I_kwDOPFZ-b87KAoKe","number":591,"title":"Vision: Search Orchestration Intelligence - Eliminate AI Assistant Tool Juggling","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9120926036,"node_id":"LA_kwDOPFZ-b88AAAACH6ZJVA","url":"https://api.github.com/repos/kotadb/kota-db/labels/architecture","name":"architecture","color":"1d76db","default":false,"description":"Architectural design and structural issues"},{"id":9169161132,"node_id":"LA_kwDOPFZ-b88AAAACIoZLrA","url":"https://api.github.com/repos/kotadb/kota-db/labels/vision","name":"vision","color":"8B5CF6","default":false,"description":"Vision and long-term direction issues"},{"id":9175575816,"node_id":"LA_kwDOPFZ-b88AAAACIugtCA","url":"https://api.github.com/repos/kotadb/kota-db/labels/agent-experience","name":"agent-experience","color":"6f42c1","default":false,"description":"Issues affecting agent/LLM interaction patterns and workflows"},{"id":9183060638,"node_id":"LA_kwDOPFZ-b88AAAACI1ping","url":"https://api.github.com/repos/kotadb/kota-db/labels/codebase-intelligence","name":"codebase-intelligence","color":"6f42c1","default":false,"description":"Codebase intelligence platform features and direction"},{"id":9187707818,"node_id":"LA_kwDOPFZ-b88AAAACI6FLqg","url":"https://api.github.com/repos/kotadb/kota-db/labels/meta","name":"meta","color":"8B5CF6","default":false,"description":"Meta issues for strategic planning and architecture"},{"id":9233848980,"node_id":"LA_kwDOPFZ-b88AAAACJmFalA","url":"https://api.github.com/repos/kotadb/kota-db/labels/ai-assistant","name":"ai-assistant","color":"6f42c1","default":false,"description":"AI assistant integration and optimization features"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-06T01:31:49Z","updated_at":"2025-09-06T01:31:49Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Vision: Search Orchestration Intelligence\n\n### The Problem\nClaude Code currently juggles multiple search tools (ripgrep, grep, find, glob) and the AI has to manually decide which one to use for each query. This creates friction and cognitive overhead.\n\n### The Solution\nMake KotaDB the single search entry point that automatically routes queries to the best underlying tool, then enhances the results with relationship intelligence.\n\n### How it works:\n- Query \"async fn parse\" → KotaDB uses ripgrep for speed, then adds \"who calls these functions?\"\n- Query \"**/*.toml\" → KotaDB uses fd for file finding, then adds \"which files depend on these configs?\"\n- Query \"FileStorage\" → KotaDB hits symbol index directly, then shows all usage patterns\n\n### The benefit\nClaude Code only talks to KotaDB. KotaDB handles tool selection and makes results smarter with relationship context. AI gets faster, more relevant results without tool-juggling complexity.\n\n## Technical Architecture\n\nThis transforms KotaDB from \"yet another search tool\" into \"search orchestration intelligence\" - leveraging proven tools like ripgrep while adding unique semantic understanding that no other tool provides.\n\n### Implementation Approach\n1. **Tool Adapters**: Create adapters for ripgrep, fd, and other best-in-class tools\n2. **Query Classification**: Intelligent routing based on query patterns and intent\n3. **Result Enhancement**: Add relationship context to all search results  \n4. **Unified API**: Single search interface for all Claude Code interactions\n\n### Success Metrics\n- Eliminate manual tool selection decisions for AI assistants\n- Sub-3ms query routing with relationship-enhanced results\n- Maintain compatibility with existing KotaDB functionality\n- Reduce Claude Code search complexity by 70%\n\n## Priority and Timeline\nThis represents a significant architectural evolution that aligns with KotaDB's mission of AI-assistant optimization. Should be prioritized after current stability work is complete.\n\n## Related Work\n- Current codebase intelligence features provide the foundation\n- Existing relationship engine enables the \"enhancement\" capability\n- MCP integration provides the interface layer for Claude Code\n\n## Implementation Considerations\n\n### Query Pattern Recognition\nNeed to develop smart pattern matching for:\n- **File patterns** (`**/*.rs`, `src/**`) → Use fd/find\n- **Content patterns** (`async fn`, `struct User`) → Use ripgrep  \n- **Symbol patterns** (`FileStorage`, `parse_config`) → Use symbol index\n- **Relationship queries** (`who calls X`, `what depends on Y`) → Use graph traversal\n\n### Tool Integration Strategy\n- **Preserve tool strengths**: Don't reinvent ripgrep's speed or fd's file handling\n- **Add semantic layer**: Enhance results with KotaDB's unique relationship data\n- **Unified interface**: Hide tool complexity behind single KotaDB API\n- **Performance targets**: Maintain sub-3ms routing + tool execution time\n\n### API Design Principles\n- **Query intent detection**: Automatic classification without explicit tool selection\n- **Result enrichment**: Always add relationship context where relevant\n- **Backward compatibility**: Existing KotaDB functionality must remain unchanged\n- **Error handling**: Graceful fallbacks when tool adapters fail\n\nThis vision positions KotaDB as the intelligence layer that makes existing tools smarter rather than replacing them.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/591/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/591/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/575","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/575/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/575/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/575/events","html_url":"https://github.com/kotadb/kota-db/issues/575","id":3388607770,"node_id":"I_kwDOPFZ-b87J-g0a","number":575,"title":"[Pre-Launch] Comprehensive Service Validation Initiative","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9118359001,"node_id":"LA_kwDOPFZ-b88AAAACH38d2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/dogfooding","name":"dogfooding","color":"6f42c1","default":false,"description":"Self-analysis and validation features"},{"id":9118359024,"node_id":"LA_kwDOPFZ-b88AAAACH38d8A","url":"https://api.github.com/repos/kotadb/kota-db/labels/validation","name":"validation","color":"c2e0c6","default":false,"description":"Validation and testing of features"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9174838498,"node_id":"LA_kwDOPFZ-b88AAAACItzs4g","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-critical","name":"priority-critical","color":"b60205","default":false,"description":"Critical priority - immediate attention required"},{"id":9187707818,"node_id":"LA_kwDOPFZ-b88AAAACI6FLqg","url":"https://api.github.com/repos/kotadb/kota-db/labels/meta","name":"meta","color":"8B5CF6","default":false,"description":"Meta issues for strategic planning and architecture"},{"id":9232903925,"node_id":"LA_kwDOPFZ-b88AAAACJlLu9Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/service-architecture","name":"service-architecture","color":"1d76db","default":false,"description":"Service layer architecture and design"},{"id":9232903957,"node_id":"LA_kwDOPFZ-b88AAAACJlLvFQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/pre-launch","name":"pre-launch","color":"d93f0b","default":false,"description":"Pre-launch validation and preparation"},{"id":9241966124,"node_id":"LA_kwDOPFZ-b88AAAACJt02LA","url":"https://api.github.com/repos/kotadb/kota-db/labels/quality-assurance","name":"quality-assurance","color":"0e8a16","default":false,"description":"Quality assurance and validation processes"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":{"url":"https://api.github.com/repos/kotadb/kota-db/milestones/3","html_url":"https://github.com/kotadb/kota-db/milestone/3","labels_url":"https://api.github.com/repos/kotadb/kota-db/milestones/3/labels","id":13633839,"node_id":"MI_kwDOPFZ-b84A0Akv","number":3,"title":"v0.6.1","description":"High priority fixes and improvements for v0.6.1","creator":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"open_issues":3,"closed_issues":0,"state":"open","created_at":"2025-09-07T21:13:21Z","updated_at":"2025-09-13T16:14:08Z","due_on":"2025-01-15T08:00:00Z","closed_at":null},"comments":2,"created_at":"2025-09-05T19:51:40Z","updated_at":"2025-09-07T21:14:09Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Overview\n\nWith launch approaching, we need systematic validation of each service in the services layer to ensure core functionality works properly. Despite 98%+ test pass rates, there's a disconnect between test coverage and actual functional coverage.\n\n## Approach\n\n1. **Systematic Dogfooding**: Test each service against KotaDB's own codebase following AGENT.md dogfooding protocol\n2. **Test Infrastructure Audit**: Review and improve tests to reflect real user workflows rather than implementation details\n3. **Interface Parity Verification**: Ensure services work identically across CLI, MCP, and HTTP interfaces\n\n## Service Validation Issues\n\n- [ ] #576 SearchService comprehensive validation\n- [ ] #577 IndexingService comprehensive validation  \n- [ ] #578 StatsService comprehensive validation\n- [ ] #579 AnalysisService comprehensive validation\n- [ ] #580 ValidationService comprehensive validation\n- [ ] #581 BenchmarkService comprehensive validation\n\n## Success Criteria\n\n- All services pass dogfooding tests on KotaDB codebase\n- Performance meets sub-10ms query latency targets\n- Tests reflect actual user workflows and catch integration issues\n- Interface parity verified across CLI/MCP/HTTP\n\n## Timeline\n\n5 days to launch - prioritize SearchService and IndexingService as most critical.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/575/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/575/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/573","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/573/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/573/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/573/events","html_url":"https://github.com/kotadb/kota-db/issues/573","id":3388500257,"node_id":"I_kwDOPFZ-b87J-Gkh","number":573,"title":"[MEDIUM PRIORITY] Implement Automated Dogfooding Tests in CI Pipeline","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998984,"node_id":"LA_kwDOPFZ-b88AAAACHG9syA","url":"https://api.github.com/repos/kotadb/kota-db/labels/tests","name":"tests","color":"c2e0c6","default":false,"description":"Testing related"},{"id":9117255494,"node_id":"LA_kwDOPFZ-b88AAAACH25HRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/ci/cd","name":"ci/cd","color":"ffd33d","default":false,"description":"Continuous Integration/Deployment issues"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9118359001,"node_id":"LA_kwDOPFZ-b88AAAACH38d2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/dogfooding","name":"dogfooding","color":"6f42c1","default":false,"description":"Self-analysis and validation features"},{"id":9118359024,"node_id":"LA_kwDOPFZ-b88AAAACH38d8A","url":"https://api.github.com/repos/kotadb/kota-db/labels/validation","name":"validation","color":"c2e0c6","default":false,"description":"Validation and testing of features"},{"id":9124823970,"node_id":"LA_kwDOPFZ-b88AAAACH-HDog","url":"https://api.github.com/repos/kotadb/kota-db/labels/blocked","name":"blocked","color":"d73a49","default":false,"description":"Blocked by external factors or other issues"},{"id":9136360593,"node_id":"LA_kwDOPFZ-b88AAAACIJHMkQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/integration","name":"integration","color":"1d76db","default":false,"description":"Integration issues between system components"},{"id":9195014214,"node_id":"LA_kwDOPFZ-b88AAAACJBDIRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/automation","name":"automation","color":"0e8a16","default":false,"description":"Automated processes and triggers"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2025-09-05T19:03:29Z","updated_at":"2025-09-05T19:04:01Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n\nImplement automated dogfooding tests in CI pipeline to catch integration issues that manual dogfooding currently reveals.\n\n## Problem Description\n\n**Current Situation:**\n- Manual dogfooding on KotaDB's own codebase catches all major integration bugs\n- Issues #570, #571, #572 were all discovered through manual dogfooding\n- Critical regressions go undetected by unit/integration tests alone\n- Manual process is time-consuming and inconsistent\n\n**Proven Track Record:**\nManual dogfooding has caught every major integration bug:\n- Issue #191: Search disconnection after git ingestion  \n- Issue #196: Trigram index architectural limitation\n- Issue #184: Multiple UX and functionality gaps\n- Issue #179: Symbol extraction edge cases\n- Issue #203: Performance degradation under realistic load\n- Issue #157: Memory usage issues with large codebases\n\n## Impact\n\n- **Prevent Regressions**: Automatically catch integration issues before release\n- **CI/CD Reliability**: Build confidence through comprehensive end-to-end testing\n- **Development Velocity**: Reduce time spent on manual validation\n- **Quality Assurance**: Maintain 99% reliability through automated validation\n\n## Acceptance Criteria\n\n### 1. Automated Dogfooding Test Suite\n- CI job that indexes KotaDB's own codebase from scratch\n- Validates all core operations work correctly\n- Compares results against known baselines and expectations\n- Fails CI if dogfooding reveals integration problems\n\n### 2. Comprehensive Operation Testing\n- **Index KotaDB codebase**: `index-codebase . --symbols`\n- **Validate extraction**: Check symbol count ~31,857, file coverage >85%\n- **Test search operations**: Content search, symbol search, wildcard queries\n- **Test analysis features**: find-callers, analyze-impact, relationship queries\n- **Performance validation**: Ensure <10ms query latency targets\n\n### 3. Baseline Validation System\n- Store expected metrics (symbol counts, file counts, performance benchmarks)\n- Compare actual results against baselines\n- Flag significant deviations as CI failures\n- Update baselines when legitimate changes occur\n\n### 4. Integration with Existing CI\n- Add dogfooding stage to GitHub Actions workflow\n- Run after successful unit/integration tests\n- Generate detailed reports on dogfooding results\n- Archive dogfooding artifacts for debugging\n\n## Technical Implementation\n\n**New CI workflow:**\n- `.github/workflows/dogfooding.yml` or extend existing workflow\n- Use clean environment for each test run\n- Index KotaDB repository in temporary directory\n- Run comprehensive validation commands\n- Compare against stored baselines\n\n**Test structure:**\n```bash\n# Setup\nrm -rf /tmp/dogfooding-test && mkdir -p /tmp/dogfooding-test\n\n# Index\ncargo run --release --bin kotadb -- -d /tmp/dogfooding-test index-codebase . --symbols\n\n# Validate core metrics  \ncargo run --release --bin kotadb -- -d /tmp/dogfooding-test stats --symbols\n# Expect: ~31,857 symbols, ~2,847 files with symbols, ~85% coverage\n\n# Test search functionality\ncargo run --release --bin kotadb -- -d /tmp/dogfooding-test search-code \"async fn\"\ncargo run --release --bin kotadb -- -d /tmp/dogfooding-test search-symbols \"FileStorage\"\n\n# Test analysis features\ncargo run --release --bin kotadb -- -d /tmp/dogfooding-test find-callers FileStorage\ncargo run --release --bin kotadb -- -d /tmp/dogfooding-test analyze-impact Config\n\n# Performance validation\ntime cargo run --release --bin kotadb -- -d /tmp/dogfooding-test search-code \"rust\"\n# Expect: <10ms response time\n```\n\n**Baseline management:**\n- Store expected results in `tests/dogfooding/baselines.json`\n- Update baselines when legitimate codebase changes occur\n- Version baselines with Git for traceability\n\n## Dependencies\n\n- **Depends on**: Issues #570, #571, #572 being resolved first\n- **Enables**: Confident automated releases and deployments\n\n## Priority Justification\n\nThis is **MEDIUM PRIORITY** because:\n- Prevents future regressions but doesn't fix current issues\n- Depends on other issues being resolved first\n- High impact on long-term development velocity\n- Essential for production-ready CI/CD pipeline\n\n**Should be implemented after Issues #570, #571, #572 are resolved.**\n\n## Implementation Timeline\n\n1. **Phase 1**: Basic dogfooding CI job\n2. **Phase 2**: Baseline validation system  \n3. **Phase 3**: Performance and quality metrics\n4. **Phase 4**: Integration with release process\n\n🤖 Generated with [Claude Code](https://claude.ai/code)","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/573/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/573/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/572","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/572/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/572/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/572/events","html_url":"https://github.com/kotadb/kota-db/issues/572","id":3388498606,"node_id":"I_kwDOPFZ-b87J-GKu","number":572,"title":"[MEDIUM PRIORITY] Fix Configuration Loading and Error Handling Issues","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504068,"node_id":"LA_kwDOPFZ-b88AAAACEQVxxA","url":"https://api.github.com/repos/kotadb/kota-db/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":9066998489,"node_id":"LA_kwDOPFZ-b88AAAACHG9q2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/mcp","name":"mcp","color":"0052cc","default":false,"description":"Model Context Protocol related"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9175575880,"node_id":"LA_kwDOPFZ-b88AAAACIugtSA","url":"https://api.github.com/repos/kotadb/kota-db/labels/usability","name":"usability","color":"84b6eb","default":false,"description":"User experience and interface usability issues"},{"id":9176514187,"node_id":"LA_kwDOPFZ-b88AAAACIvZ-iw","url":"https://api.github.com/repos/kotadb/kota-db/labels/cli-ux","name":"cli-ux","color":"0366d6","default":false,"description":"CLI user experience and interface improvements"},{"id":9188127861,"node_id":"LA_kwDOPFZ-b88AAAACI6e0dQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/configuration","name":"configuration","color":"0366d6","default":false,"description":"Configuration files and settings"},{"id":9232698836,"node_id":"LA_kwDOPFZ-b88AAAACJk_N1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/error-handling","name":"error-handling","color":"d73a49","default":false,"description":"Error handling and user experience"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2025-09-05T19:02:44Z","updated_at":"2025-09-05T19:03:49Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n\nMultiple user experience and configuration issues discovered during dogfooting that affect deployment reliability and user experience.\n\n## Problem Description\n\n**Configuration Issues:**\n- MCP server ignores `kotadb-mcp-dev.toml` config file\n- Starts on port 3000 instead of configured port 9876\n- No indication that config file is being ignored\n\n**Error Handling Issues:**\n- CLI commands show Rust panic stack traces instead of user-friendly errors\n- Technical error messages confuse end users\n- No graceful degradation for common error scenarios\n\n**Search Quality Issues:**\n- Search returns false positives with very low scores (0.1, 0.2)\n- No score thresholding to filter irrelevant results\n- Results not ranked by relevance effectively\n\n## Impact\n\n- **Deployment Problems**: Cannot reliably configure MCP server\n- **Poor User Experience**: Technical errors confuse non-technical users\n- **Search Usability**: Low-quality results reduce search effectiveness\n- **Production Readiness**: Issues prevent smooth production deployment\n\n## Acceptance Criteria\n\n### 1. Configuration Loading Fix\n- MCP server correctly loads and uses `kotadb-mcp-dev.toml`\n- Server starts on configured port (9876)\n- Log configuration loading success/failure clearly\n- Add configuration validation and helpful error messages\n\n### 2. Error Handling Improvements\n- Replace panic stack traces with user-friendly error messages\n- Add context-specific error messages for common scenarios\n- Implement graceful error handling throughout CLI commands\n- Add `--verbose` flag for detailed error output when needed\n\n### 3. Search Quality Improvements\n- Implement score thresholding (e.g., minimum score 0.5)\n- Improve result ranking algorithm\n- Add search quality metrics and validation\n- Filter out clearly irrelevant results\n\n### 4. General UX Polish\n- Consistent error message formatting across all commands\n- Helpful suggestions for common user mistakes\n- Clear progress indicators for long-running operations\n- Standardize output formatting\n\n## Technical Implementation\n\n**Files to modify:**\n- `src/bin/mcp_server.rs` - Fix configuration loading\n- `src/cli/` - Improve error handling throughout CLI\n- `src/services/search_service.rs` - Add score thresholding\n- Error handling utilities for consistent messaging\n\n**Configuration fix:**\n- Debug why TOML config is not being loaded properly\n- Ensure config path resolution works correctly\n- Add configuration validation and clear error messages\n\n**Error handling patterns:**\n- Use `anyhow::Context` for user-friendly error messages\n- Create error message formatting utilities\n- Add specific error types for common scenarios\n\n## Priority Justification\n\nThis is **MEDIUM PRIORITY** because:\n- Affects user experience but doesn't break core functionality\n- Important for production deployment reliability\n- Can be worked on in parallel with other issues\n- Quality-of-life improvements that enhance adoption\n\n**Can be worked on in parallel with Issues #570 and #571.**\n\n## Related Issues\n\n- Can work independently of Issues #570, #571\n- Enables better testing and validation of other fixes\n\n🤖 Generated with [Claude Code](https://claude.ai/code)","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/572/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/572/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/561","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/561/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/561/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/561/events","html_url":"https://github.com/kotadb/kota-db/issues/561","id":3386076786,"node_id":"I_kwDOPFZ-b87J025y","number":561,"title":"CRITICAL: Comprehensive Testing Suite Analysis - Security Vulnerabilities & Test Failures","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998377,"node_id":"LA_kwDOPFZ-b88AAAACHG9qaQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/production-blocker","name":"production-blocker","color":"b60205","default":false,"description":"Issues blocking production deployment"},{"id":9066998984,"node_id":"LA_kwDOPFZ-b88AAAACHG9syA","url":"https://api.github.com/repos/kotadb/kota-db/labels/tests","name":"tests","color":"c2e0c6","default":false,"description":"Testing related"},{"id":9067343356,"node_id":"LA_kwDOPFZ-b88AAAACHHSt_A","url":"https://api.github.com/repos/kotadb/kota-db/labels/dependencies","name":"dependencies","color":"0366d6","default":false,"description":"Pull requests that update a dependency file"},{"id":9113577132,"node_id":"LA_kwDOPFZ-b88AAAACHzYmrA","url":"https://api.github.com/repos/kotadb/kota-db/labels/security","name":"security","color":"d73a4a","default":false,"description":"Security vulnerabilities and concerns"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9157095354,"node_id":"LA_kwDOPFZ-b88AAAACIc4vug","url":"https://api.github.com/repos/kotadb/kota-db/labels/testing-needed","name":"testing-needed","color":"fbca04","default":false,"description":"Feature implemented but needs testing"},{"id":9174838498,"node_id":"LA_kwDOPFZ-b88AAAACItzs4g","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-critical","name":"priority-critical","color":"b60205","default":false,"description":"Critical priority - immediate attention required"},{"id":9228371211,"node_id":"LA_kwDOPFZ-b88AAAACJg3FCw","url":"https://api.github.com/repos/kotadb/kota-db/labels/security-vulnerability","name":"security-vulnerability","color":"d73a4a","default":false,"description":"Security vulnerabilities requiring immediate attention"},{"id":9228371228,"node_id":"LA_kwDOPFZ-b88AAAACJg3FHA","url":"https://api.github.com/repos/kotadb/kota-db/labels/test-failures","name":"test-failures","color":"d93f0b","default":false,"description":"Test suite failures and race conditions"},{"id":9228371247,"node_id":"LA_kwDOPFZ-b88AAAACJg3FLw","url":"https://api.github.com/repos/kotadb/kota-db/labels/dependency-maintenance","name":"dependency-maintenance","color":"fbca04","default":false,"description":"Dependency updates and maintenance"},{"id":9241966174,"node_id":"LA_kwDOPFZ-b88AAAACJt02Xg","url":"https://api.github.com/repos/kotadb/kota-db/labels/vulnerability","name":"vulnerability","color":"d73a4a","default":false,"description":"Security vulnerabilities requiring attention"},{"id":9253151945,"node_id":"LA_kwDOPFZ-b88AAAACJ4fkyQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/launch-prep","name":"launch-prep","color":"d93f0b","default":false,"description":"Launch preparation tasks and cleanup"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":{"url":"https://api.github.com/repos/kotadb/kota-db/milestones/5","html_url":"https://github.com/kotadb/kota-db/milestone/5","labels_url":"https://api.github.com/repos/kotadb/kota-db/milestones/5/labels","id":13683962,"node_id":"MI_kwDOPFZ-b84A0Mz6","number":5,"title":"Stabilization Sprint (Pre-Launch)","description":"Stabilize test/security/infra before new feature work: fix failing tests, security audit, CI stability. Short-lived milestone to unblock launch.","creator":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"open_issues":4,"closed_issues":1,"state":"open","created_at":"2025-09-13T16:13:49Z","updated_at":"2025-09-19T16:54:34Z","due_on":"2025-09-18T07:00:00Z","closed_at":null},"comments":4,"created_at":"2025-09-05T02:36:43Z","updated_at":"2025-09-13T16:13:53Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Overview\n\nThis issue documents critical findings from a comprehensive testing suite analysis that revealed **2 critical security vulnerabilities** and **3 failing integration tests** that require immediate attention, along with medium-priority maintenance items.\n\n**Overall Test Status: 99.2% Success Rate**\n- ✅ 479/482 integration tests passed  \n- ✅ 378/378 unit tests passed\n- ✅ 5/5 performance tests passed\n- ❌ **3 critical test failures requiring immediate attention**\n- 🔒 **2 critical security vulnerabilities found**\n\n## 🚨 CRITICAL IMMEDIATE ACTIONS\n\n### 1. Security Vulnerabilities (CRITICAL)\n\n#### SQLx Binary Protocol Vulnerability (RUSTSEC-2024-0363)\n- **Current Version**: SQLx 0.7.4 \n- **Required Action**: Update to SQLx >= 0.8.1\n- **Risk**: Binary protocol misinterpretation vulnerability\n- **Impact**: Database communication security risk\n- **Timeline**: **IMMEDIATE - within 24 hours**\n\n#### RSA Cryptographic Vulnerability (RUSTSEC-2023-0071)  \n- **Current Version**: RSA 0.9.8\n- **Risk**: Known cryptographic vulnerability\n- **Action**: Monitor for RSA crate updates or evaluate alternative crypto backends\n- **Timeline**: **HIGH PRIORITY - within 1 week**\n\n### 2. Failing Integration Tests (CRITICAL)\n\nThree integration tests are failing due to race conditions in concurrent execution scenarios:\n\n#### Test 1: `test_edge_cases` \n- **Location**: `code_analysis_integration_test.rs:476`\n- **Issue**: Race condition in concurrent test execution\n- **Impact**: Potential data integrity issues under concurrent load\n\n#### Test 2: `test_concurrent_api_requests`\n- **Location**: `codebase_intelligence_api_test`  \n- **Issue**: Concurrent API request handling failure\n- **Impact**: API reliability under concurrent usage\n\n#### Test 3: `test_deprecated_endpoints_have_headers`\n- **Issue**: Header validation failure in deprecated endpoints\n- **Impact**: API compatibility and deprecation handling\n\n**Root Cause**: Test isolation issues causing race conditions between concurrent test executions\n**Timeline**: **IMMEDIATE - within 48 hours**\n\n## 📋 MEDIUM PRIORITY ACTIONS\n\n### 3. Dependency Maintenance\n\nReplace unmaintained dependencies identified in cargo audit:\n- `instant 0.1.13` - No longer maintained\n- `net2 0.2.39` - Deprecated  \n- `paste 1.0.15` - Consider alternatives\n\n### 4. Test Infrastructure Improvements\n\n- **Automated Performance Regression Detection**: Set up CI checks for performance SLA violations\n- **Test Isolation Enhancement**: Improve concurrent test isolation to prevent race conditions\n- **Concurrency Testing**: Strengthen concurrent execution test patterns\n\n## ✅ CONFIRMED WORKING SYSTEMS\n\n- **Performance SLAs**: All targets maintained (sub-10ms query latency)\n- **Code Quality**: All clippy and formatting checks passed\n- **Core Functionality**: 99.2% test success rate demonstrates robust core systems\n- **Unit Tests**: 100% success rate (378/378)\n- **Performance Tests**: 100% success rate (5/5)\n\n## 📊 Testing Metrics Summary\n\n```\nIntegration Tests: 479/482 passed (99.4%)\nUnit Tests:        378/378 passed (100%)  \nPerformance Tests: 5/5 passed (100%)\nSecurity Audit:    2 critical vulnerabilities found\nCode Quality:      ✅ All checks passed\nOverall Success:   99.2%\n```\n\n## 🎯 Success Criteria\n\n**Critical Issues (Week 1)**:\n- [ ] SQLx updated to >= 0.8.1 \n- [ ] All 3 integration test failures resolved\n- [ ] RSA vulnerability assessment completed\n\n**Medium Priority (Week 2-3)**:\n- [ ] Unmaintained dependencies replaced\n- [ ] Performance regression detection implemented\n- [ ] Test isolation improvements deployed\n- [ ] Concurrent testing patterns strengthened\n\n## 🔍 Investigation Notes\n\nThe testing analysis demonstrates that while KotaDB maintains excellent overall reliability (99.2% success rate), the identified security vulnerabilities and race condition test failures represent critical risks that could impact production deployment readiness.\n\nThe high success rate combined with these specific critical issues suggests targeted fixes rather than systemic problems, making resolution achievable within the proposed timelines.\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/561/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/561/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/559","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/559/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/559/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/559/events","html_url":"https://github.com/kotadb/kota-db/issues/559","id":3386042812,"node_id":"I_kwDOPFZ-b87J0um8","number":559,"title":"Strategic Initiative: Third-Party Agent Testing Framework for Authentic KotaDB Validation","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9118359026,"node_id":"LA_kwDOPFZ-b88AAAACH38d8g","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-large","name":"effort-large","color":"f85149","default":false,"description":"Large effort - more than 3 days"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9120926036,"node_id":"LA_kwDOPFZ-b88AAAACH6ZJVA","url":"https://api.github.com/repos/kotadb/kota-db/labels/architecture","name":"architecture","color":"1d76db","default":false,"description":"Architectural design and structural issues"},{"id":9175575880,"node_id":"LA_kwDOPFZ-b88AAAACIugtSA","url":"https://api.github.com/repos/kotadb/kota-db/labels/usability","name":"usability","color":"84b6eb","default":false,"description":"User experience and interface usability issues"},{"id":9187707818,"node_id":"LA_kwDOPFZ-b88AAAACI6FLqg","url":"https://api.github.com/repos/kotadb/kota-db/labels/meta","name":"meta","color":"8B5CF6","default":false,"description":"Meta issues for strategic planning and architecture"},{"id":9228298524,"node_id":"LA_kwDOPFZ-b88AAAACJgypHA","url":"https://api.github.com/repos/kotadb/kota-db/labels/strategic-initiative","name":"strategic-initiative","color":"8B5CF6","default":false,"description":"Major strategic initiative for product direction"},{"id":9228298538,"node_id":"LA_kwDOPFZ-b88AAAACJgypKg","url":"https://api.github.com/repos/kotadb/kota-db/labels/user-research","name":"user-research","color":"0075ca","default":false,"description":"User research and external validation"},{"id":9228298547,"node_id":"LA_kwDOPFZ-b88AAAACJgypMw","url":"https://api.github.com/repos/kotadb/kota-db/labels/agent-validation","name":"agent-validation","color":"6f42c1","default":false,"description":"Third-party agent testing and validation"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2025-09-05T02:12:48Z","updated_at":"2025-09-05T02:13:14Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Problem Statement\n\nKotaDB is designed as a codebase intelligence platform specifically for AI coding assistants, yet our current testing methodology has a fundamental blindspot: **we only test with internal knowledge of the system**. Our team inherently knows KotaDB's capabilities, limitations, and expected outputs, making it impossible to validate the authentic user experience of AI agents encountering KotaDB for the first time.\n\n### Core Testing Limitation\n\nCurrent validation approaches suffer from **insider knowledge contamination**:\n- We know which queries should work and which shouldn't\n- We understand the expected output format and can recognize correct vs incorrect results\n- We design test scenarios around known capabilities rather than authentic discovery patterns\n- We can't simulate the genuine confusion, trial-and-error, and learning process that external agents experience\n\n### Target User Disconnect\n\nOur primary users are LLM coding assistants, but we have no systematic way to observe:\n- How agents naturally discover KotaDB's features\n- What assumptions they make about query syntax and capabilities  \n- Which friction points prevent successful adoption\n- How they adapt their workflow to KotaDB's strengths and limitations\n- Whether our documentation and interfaces match agent mental models\n\n## Proposed Solution: External Agent Testing Repository\n\nCreate a separate internal repository (`kotadb-user-testing`) that serves as an **isolated testing environment** where third-party agents can interact with KotaDB without any access to implementation knowledge, documentation, or expected outcomes.\n\n### Key Design Principles\n\n#### 1. Zero Internal Knowledge Access\n- Separate repository with no connection to main KotaDB development\n- Third-party agents receive only:\n  - KotaDB binary/installation instructions\n  - Minimal getting-started documentation\n  - Target repositories to analyze\n- **No access to**: Implementation details, test suites, expected outputs, internal documentation\n\n#### 2. Post-Training Data Strategy (Critical)\n\n**Problem with Traditional OSS Testing**: Using well-known repositories (React, Django, Linux kernel) creates **training data contamination**. LLMs can fabricate plausible responses about these codebases from memorized patterns rather than relying on KotaDB's actual analysis.\n\n**Solution - Post-Training Cutoff Validation**:\n- Use exclusively repositories created **after January 2024** (post-training cutoff for most LLMs)\n- Ensures agents must rely entirely on KotaDB's intelligence rather than training data\n- Creates authentic \"blind testing\" conditions where fabricated responses are impossible\n\n#### 3. Authentic Task Scenarios\n\nDesign scenarios that mirror real AI assistant workflows:\n\n**Code Discovery Challenge**:\n- Agent receives unfamiliar post-2024 repository\n- Task: \"Help a developer understand this codebase's authentication system\"\n- Success metric: Can the agent accurately map auth flows using only KotaDB?\n\n**Impact Analysis Challenge**:\n- Agent given a specific function/class in post-2024 codebase\n- Task: \"Analyze the impact of modifying this component\"\n- Success metric: Does the agent find all dependencies and potential breakage points?\n\n**Refactoring Support Challenge**:\n- Agent tasked with suggesting safe refactoring opportunities\n- Must use KotaDB to identify unused code, circular dependencies, high-coupling areas\n- Success metric: Suggestions are accurate and actionable\n\n**Multi-Language Navigation**:\n- Repository with multiple programming languages (Rust + TypeScript + Python)\n- Task: \"Trace a feature from frontend to backend to database\"\n- Success metric: Agent successfully follows cross-language boundaries\n\n## Repository Selection Criteria\n\n### Complexity Requirements\n- **Medium-Large Scale**: 10,000+ lines of code across multiple files/modules\n- **Real Production Patterns**: Not toy examples or tutorials\n- **Multiple Contributors**: Evidence of collaborative development\n- **Active Development**: Regular commits through 2024\n- **Documentation Present**: READMEs and comments for context verification\n\n### Language Diversity\n- **Primary Target**: Rust codebases (KotaDB's strength)\n- **Secondary Targets**: TypeScript/JavaScript, Python, Go\n- **Cross-Language**: Repositories mixing multiple languages\n- **Modern Patterns**: Use of recent language features and frameworks\n\n### Domain Variety\n- Web application backends\n- CLI tools and utilities  \n- Data processing pipelines\n- API servers and microservices\n- Developer tooling\n- **Avoid**: Cryptocurrency, blockchain, or highly specialized domains\n\n### Recency Validation\n- Created **after January 1, 2024**\n- Majority of development in 2024\n- Uses post-2024 dependencies and patterns\n- Not forks of pre-training repositories\n\n## Testing Execution Framework\n\n### Phase 1: Environment Setup\n1. **Repository Curation**: Identify 10-15 qualifying post-2024 repositories\n2. **Clean Environment**: Set up kotadb-user-testing repository with minimal context\n3. **Binary Distribution**: Provide latest KotaDB release without source access\n4. **Task Design**: Create specific challenges per repository\n\n### Phase 2: Agent Instruction Design\n**Minimal Context Approach**:\n```\nYou are testing a codebase intelligence tool called KotaDB. Your task is to help analyze the provided repository using only KotaDB's capabilities. You have no prior knowledge of this tool or the target codebase.\n\nRepository: [post-2024-repo-name]\nTask: [specific scenario]\nSuccess Criteria: [measurable outcomes]\n\nAvailable: KotaDB binary, basic installation docs, target repository\nForbidden: Internet search, external tools, assumption-based responses\n```\n\n### Phase 3: Observation and Data Collection\n- **Interaction Logging**: Full session transcripts of agent-KotaDB interactions\n- **Query Pattern Analysis**: What commands agents try, succeed/fail patterns\n- **Friction Point Identification**: Where agents get stuck or confused\n- **Feature Discovery Mapping**: How agents find and learn KotaDB capabilities\n- **Error Recovery Patterns**: How agents handle failures and adapt approaches\n\n### Phase 4: Feedback Analysis\n- **Usability Gaps**: Features that should exist but don't\n- **Documentation Blind Spots**: Unclear or missing usage guidance  \n- **UX Friction**: Interface design issues blocking adoption\n- **Performance Perception**: Whether speed meets agent expectations\n- **Feature Discoverability**: Hidden capabilities agents can't find\n\n## Expected Benefits\n\n### Authentic Friction Discovery\nUnlike internal testing, external agents will encounter **genuine usability issues**:\n- Confusing command syntax that we've internalized\n- Missing error messages that would help orientation\n- Assumptions about user knowledge that don't hold\n- Interface patterns that work for us but not for discovery-based usage\n\n### Genuine Usage Pattern Observation\nSee how agents **actually** interact with KotaDB:\n- Query formulation strategies when uncertain about syntax\n- Trial-and-error patterns for feature discovery\n- Workflow adaptation as they learn the system\n- Integration approaches with their existing knowledge\n\n### Production Readiness Validation\nValidate that KotaDB delivers on its core promise:\n- Can agents successfully understand unfamiliar codebases using only KotaDB?\n- Do the extracted symbols and relationships provide actionable intelligence?\n- Is the performance adequate for interactive AI assistant workflows?\n- Are the query interfaces intuitive enough for agents to master quickly?\n\n### Training Data Contamination Elimination\nBy using post-2024 repositories, we ensure:\n- Agents cannot fabricate plausible answers from training data\n- All responses must be grounded in KotaDB's actual analysis\n- We observe genuine reliance on our intelligence vs. hallucination patterns\n- Testing validates real capability rather than memorization overlap\n\n## Implementation Phases\n\n### Phase 1: Infrastructure (Weeks 1-2)\n- [ ] Create kotadb-user-testing repository (internal)\n- [ ] Set up isolated testing environment\n- [ ] Curate initial set of 5 post-2024 repositories across different domains\n- [ ] Design binary distribution mechanism\n- [ ] Create minimal documentation package\n\n### Phase 2: Test Scenario Development (Weeks 3-4)\n- [ ] Design 3-5 core scenarios per repository type\n- [ ] Create measurable success criteria for each scenario\n- [ ] Develop agent instruction templates\n- [ ] Set up session logging and data collection infrastructure\n- [ ] Create feedback analysis framework\n\n### Phase 3: Initial Agent Testing (Weeks 5-8)\n- [ ] Recruit 2-3 third-party agents for initial validation\n- [ ] Execute testing scenarios across repository types\n- [ ] Collect detailed interaction logs and feedback\n- [ ] Analyze friction points and usability gaps\n- [ ] Document initial findings and recommendations\n\n### Phase 4: Iteration and Expansion (Weeks 9-12)\n- [ ] Implement high-impact usability improvements\n- [ ] Expand repository coverage to 10-15 codebases\n- [ ] Test additional agent types and approaches\n- [ ] Develop standardized agent onboarding process\n- [ ] Create systematic feedback integration workflow\n\n## Success Metrics\n\n### Quantitative Measures\n- **Task Completion Rate**: % of scenarios successfully completed by external agents\n- **Time to Productivity**: How quickly agents become effective with KotaDB\n- **Query Success Ratio**: % of agent queries that return useful results\n- **Feature Discovery Rate**: % of KotaDB capabilities agents find independently\n- **Error Recovery Success**: % of failed queries followed by successful adaptation\n\n### Qualitative Measures\n- **Friction Point Severity**: Impact assessment of identified usability issues\n- **Documentation Gap Analysis**: Critical missing guidance identified by agents\n- **Workflow Integration Success**: How well KotaDB fits agent mental models\n- **Confidence in Results**: Agent trust in KotaDB's intelligence accuracy\n- **Adoption Likelihood**: Would agents choose KotaDB for real projects?\n\n## Strategic Impact\n\n### Product Development Alignment\nThis initiative directly addresses KotaDB's core mission: **enabling AI assistants to understand and work with codebases effectively**. External validation ensures our development efforts target real agent needs rather than internal assumptions.\n\n### Market Validation\nDemonstrates KotaDB's value proposition in authentic conditions:\n- Proves capability to provide actionable intelligence on unfamiliar codebases\n- Validates performance and usability for interactive AI workflows\n- Identifies competitive advantages and differentiation opportunities\n\n### Risk Mitigation\nIdentifies and addresses usability issues before wider adoption:\n- Prevents poor first impressions that could limit agent adoption\n- Ensures documentation and interfaces match agent expectations\n- Validates that KotaDB delivers on its intelligence promises\n\n### Innovation Direction\nExternal agent feedback provides strategic guidance:\n- Which features provide the most value in practice?\n- What capabilities are missing for complete codebase understanding?\n- How should KotaDB evolve to better serve AI assistant workflows?\n\n## Next Steps\n\n1. **Immediate Action**: Create kotadb-user-testing repository and begin post-2024 repository curation\n2. **Resource Allocation**: Assign team member to lead this initiative (estimated 25% time commitment)\n3. **Timeline Commitment**: 12-week initial pilot with option to expand based on results\n4. **Success Gateway**: Define specific criteria for continuing vs. pivoting based on Phase 3 results\n\nThis initiative represents a novel approach to AI-first product validation and positions KotaDB for successful adoption by its primary audience: AI coding assistants working with unfamiliar codebases.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/559/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/559/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/558","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/558/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/558/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/558/events","html_url":"https://github.com/kotadb/kota-db/issues/558","id":3386036918,"node_id":"I_kwDOPFZ-b87J0tK2","number":558,"title":"CLI UX Improvements: Argument parsing, performance reporting, and stats output","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9118359037,"node_id":"LA_kwDOPFZ-b88AAAACH38d_Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-medium","name":"effort-medium","color":"fbca04","default":false,"description":"Medium effort (1-3 days)"},{"id":9137694578,"node_id":"LA_kwDOPFZ-b88AAAACIKYncg","url":"https://api.github.com/repos/kotadb/kota-db/labels/cli","name":"cli","color":"0366d6","default":false,"description":"Command-line interface issues"},{"id":9175575880,"node_id":"LA_kwDOPFZ-b88AAAACIugtSA","url":"https://api.github.com/repos/kotadb/kota-db/labels/usability","name":"usability","color":"84b6eb","default":false,"description":"User experience and interface usability issues"},{"id":9176514187,"node_id":"LA_kwDOPFZ-b88AAAACIvZ-iw","url":"https://api.github.com/repos/kotadb/kota-db/labels/cli-ux","name":"cli-ux","color":"0366d6","default":false,"description":"CLI user experience and interface improvements"},{"id":9183021826,"node_id":"LA_kwDOPFZ-b88AAAACI1nLAg","url":"https://api.github.com/repos/kotadb/kota-db/labels/reporting","name":"reporting","color":"84b6eb","default":false,"description":"Command output and reporting functionality"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-09-05T02:08:27Z","updated_at":"2025-09-05T02:08:27Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n\nDuring CLI testing, discovered three UX improvements needed for the command-line interface. All core functionality works correctly, but the user experience could be enhanced in these areas:\n\n1. **CLI argument parsing inconsistency**\n2. **Performance reporting for complex queries** \n3. **Silent stats command output**\n\n## Issue 1: CLI Argument Parsing Inconsistency\n\n**Problem**: Documentation and help text suggest `--symbols` flag exists, but command fails with \"unexpected argument\"\n\n**Current behavior**:\n```bash\ncargo run --bin kotadb -- -d ./data/analysis index-codebase . --symbols\n# Error: unexpected argument '--symbols' found\n```\n\n**Expected behavior**: Either accept `--symbols` flag or update documentation to reflect actual interface\n\n**Impact**: Minor UX confusion - functionality works (symbols extracted by default), but interface doesn't match documentation\n\n**Workaround**: Use command without `--symbols` flag - symbol extraction happens automatically\n\n## Issue 2: Complex Query Performance Reporting\n\n**Problem**: Long-running queries (like `find-callers`) complete successfully but don't provide performance feedback\n\n**Current behavior**:\n```bash\ncargo run --bin kotadb -- -d ./data/analysis find-callers \"FileStorage\"\n# Takes 3,680ms but no timing feedback provided\n# Results appear with no indication of processing time\n```\n\n**Context**: \n- Simple queries (like `analyze-impact \"Database\"`) complete in ~1ms\n- Complex relationship traversals across 31K symbols take longer\n- Performance varies significantly by query complexity\n\n**Expected behavior**: Show query timing for operations >1000ms to help users understand processing status\n\n**Impact**: Users may think complex queries are hanging when they're processing normally\n\n## Issue 3: Stats Command Silent Output  \n\n**Problem**: Stats commands execute without visible output, making it impossible to verify database status\n\n**Current behavior**:\n```bash\ncargo run --bin kotadb -- -d ./data/analysis stats\ncargo run --bin kotadb -- -d ./data/analysis stats --symbols\n# Both commands succeed but produce no console output\n```\n\n**Expected behavior**: Display database statistics, document counts, symbol counts, index status\n\n**Impact**: Cannot verify successful indexing or troubleshoot database issues via CLI\n\n**Workaround**: File system inspection shows proper database creation in expected directories\n\n## Reproduction Steps\n\n1. Index a codebase: `cargo run --bin kotadb -- -d ./data/analysis index-codebase .`\n2. Try stats commands: `cargo run --bin kotadb -- -d ./data/analysis stats`\n3. Run complex query: `cargo run --bin kotadb -- -d ./data/analysis find-callers \"FileStorage\"`\n4. Observe: No stats output, no performance feedback for long queries\n\n## Current Status\n\n- **Core functionality**: ✅ Working correctly\n- **Data integrity**: ✅ Database created and populated properly  \n- **Query results**: ✅ Accurate results returned\n- **User experience**: ❌ Silent operations, confusing interface\n\n## Proposed Solutions\n\n1. **Argument parsing**: Align CLI arguments with help text or update documentation\n2. **Performance reporting**: Add optional timing output for queries >1000ms\n3. **Stats output**: Implement proper console reporting for database statistics\n\n## Priority\n\n**Medium priority** - functionality works but UX improvements would enhance developer experience during dogfooding and production usage.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/558/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/558/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/547","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/547/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/547/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/547/events","html_url":"https://github.com/kotadb/kota-db/issues/547","id":3381547924,"node_id":"I_kwDOPFZ-b87JjlOU","number":547,"title":"[CRITICAL] Interface Parity Problem: CLI vs MCP Tool Inconsistency","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998489,"node_id":"LA_kwDOPFZ-b88AAAACHG9q2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/mcp","name":"mcp","color":"0052cc","default":false,"description":"Model Context Protocol related"},{"id":9113577095,"node_id":"LA_kwDOPFZ-b88AAAACHzYmhw","url":"https://api.github.com/repos/kotadb/kota-db/labels/critical","name":"critical","color":"d73a4a","default":false,"description":"Critical issues requiring immediate attention"},{"id":9113577148,"node_id":"LA_kwDOPFZ-b88AAAACHzYmvA","url":"https://api.github.com/repos/kotadb/kota-db/labels/api","name":"api","color":"fbca04","default":false,"description":"API design and functionality issues"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9120926036,"node_id":"LA_kwDOPFZ-b88AAAACH6ZJVA","url":"https://api.github.com/repos/kotadb/kota-db/labels/architecture","name":"architecture","color":"1d76db","default":false,"description":"Architectural design and structural issues"},{"id":9137694578,"node_id":"LA_kwDOPFZ-b88AAAACIKYncg","url":"https://api.github.com/repos/kotadb/kota-db/labels/cli","name":"cli","color":"0366d6","default":false,"description":"Command-line interface issues"},{"id":9174838498,"node_id":"LA_kwDOPFZ-b88AAAACItzs4g","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-critical","name":"priority-critical","color":"b60205","default":false,"description":"Critical priority - immediate attention required"},{"id":9182337456,"node_id":"LA_kwDOPFZ-b88AAAACI09ZsA","url":"https://api.github.com/repos/kotadb/kota-db/labels/refactoring","name":"refactoring","color":"fef2c0","default":false,"description":"Code restructuring without feature changes"},{"id":9220288546,"node_id":"LA_kwDOPFZ-b88AAAACJZJwIg","url":"https://api.github.com/repos/kotadb/kota-db/labels/interface-parity","name":"interface-parity","color":"fbca04","default":false,"description":"Interface parity across CLI/API/MCP"},{"id":9241966134,"node_id":"LA_kwDOPFZ-b88AAAACJt02Ng","url":"https://api.github.com/repos/kotadb/kota-db/labels/interface-consistency","name":"interface-consistency","color":"fbca04","default":false,"description":"Consistency across different interfaces (CLI/API/MCP)"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":{"url":"https://api.github.com/repos/kotadb/kota-db/milestones/3","html_url":"https://github.com/kotadb/kota-db/milestone/3","labels_url":"https://api.github.com/repos/kotadb/kota-db/milestones/3/labels","id":13633839,"node_id":"MI_kwDOPFZ-b84A0Akv","number":3,"title":"v0.6.1","description":"High priority fixes and improvements for v0.6.1","creator":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"open_issues":3,"closed_issues":0,"state":"open","created_at":"2025-09-07T21:13:21Z","updated_at":"2025-09-13T16:14:08Z","due_on":"2025-01-15T08:00:00Z","closed_at":null},"comments":2,"created_at":"2025-09-03T22:56:15Z","updated_at":"2025-09-07T21:14:21Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Problem Statement\n\nKotaDB suffers from a fundamental **interface parity problem** where the CLI and MCP Server expose different subsets of functionality, creating user confusion and maintenance burden. This architectural issue affects user experience and violates interface consistency principles.\n\n## Current State Analysis\n\n### Interface Comparison\n- **CLI Commands**: 11 total commands\n- **MCP Tools**: 9 total tools  \n- **Exact Parity**: Only 3 tools have identical functionality between interfaces\n\n### Missing from MCP (6 CLI commands not available via MCP):\n1. `search-code` - Full-text code search\n2. `search-symbols` - Symbol pattern search\n3. `stats` - Database statistics and metrics\n4. `benchmark` - Performance benchmarking\n5. `validate` - Database validation\n6. `index-codebase` - Codebase ingestion and indexing\n\n### Missing from CLI (6 MCP tools not available via CLI):\n1. `find-callees` - Find what a function calls\n2. `call-chain` - Analyze call chains\n3. `circular-dependencies` - Detect circular dependencies\n4. `unused-symbols` - Find unused symbols\n5. `hot-paths` - Find frequently used code paths\n6. `relationship-query` - Advanced relationship queries\n\n## Root Cause Analysis\n\n### Architectural Issues\n1. **Fragmented Development**: MCP tools implemented separately from CLI commands without shared abstraction\n2. **No Unified Service Layer**: Each interface reimplements functionality instead of calling shared services\n3. **Unused Feature Flags**: `enable_search_tools` flag exists but isn't properly wired up\n4. **Duplicate Implementations**: Same functionality coded twice with different interfaces\n\n### Code Evidence\n```rust\n// CLI: Direct implementation in main.rs\nCommands::SearchCode { query, .. } => {\n    // Direct trigram search implementation\n}\n\n// MCP: Separate implementation in mcp/tools/\nasync fn handle_search_code_tool() -> Result<..> {\n    // Different implementation path\n}\n```\n\n## Impact Assessment\n\n### User Experience Issues\n- **Capability Confusion**: Users can't achieve same functionality through different interfaces\n- **Agent Confusion**: AI agents (like Claude Code) get confused about capability differences\n- **Workflow Disruption**: Users must switch interfaces to access different features\n- **Documentation Complexity**: Two different capability sets to document and maintain\n\n### Development Issues  \n- **Maintenance Burden**: Duplicate implementations require double maintenance\n- **Bug Propagation**: Fixes must be applied in multiple places\n- **Feature Drift**: Interfaces diverge over time without coordination\n- **Testing Complexity**: Need separate test suites for each interface\n\n### Discovery Context\nThis issue was discovered through **systematic dogfooding** - testing KotaDB on its own codebase revealed the inconsistency when trying to access search functionality through different interfaces. This validates the importance of comprehensive self-testing.\n\n## Proposed Solution: Unified Service Architecture\n\n### Phase 1: Service Layer Abstraction\n```rust\n// Shared service layer\npub struct SearchService {\n    trigram_index: Arc<TrigramIndex>,\n    symbol_index: Arc<SymbolIndex>,\n}\n\nimpl SearchService {\n    pub async fn search_code(&self, query: &str) -> Result<Vec<SearchResult>> {\n        // Single implementation\n    }\n    \n    pub async fn search_symbols(&self, pattern: &str) -> Result<Vec<SymbolResult>> {\n        // Single implementation  \n    }\n}\n\n// Both interfaces use same service\n// CLI: Commands::SearchCode => search_service.search_code(query)\n// MCP: search_code_tool => search_service.search_code(query)\n```\n\n### Phase 2: Interface Unification\n- **SearchService**: Handle all search operations\n- **RelationshipService**: Manage dependency and call graphs  \n- **IndexService**: Control indexing and statistics\n- **ValidationService**: Database validation and benchmarking\n\n### Phase 3: Automatic Parity Enforcement\n- Code generation to ensure interface consistency\n- Shared test suite validating both interfaces\n- CI checks preventing parity drift\n\n## Success Criteria\n\n### Immediate (Phase 1)\n- [x] Document interface inconsistencies (this issue)\n- [ ] Create unified service abstractions\n- [ ] Refactor one command/tool pair to use shared service\n- [ ] Validate approach with comprehensive testing\n\n### Medium Term (Phase 2)\n- [ ] All CLI commands available via MCP\n- [ ] All MCP tools available via CLI  \n- [ ] Single service implementation for each feature\n- [ ] Consistent behavior between interfaces\n\n### Long Term (Phase 3)\n- [ ] Automated parity enforcement in CI\n- [ ] HTTP API reuses same service layer\n- [ ] Zero interface drift maintenance\n- [ ] Simplified documentation and testing\n\n## Priority Justification\n\n**CRITICAL** priority because:\n1. **User Experience**: Fundamental usability problem affecting all users\n2. **Maintenance Burden**: Technical debt compounds over time  \n3. **Architecture Foundation**: Must be fixed before adding new features\n4. **Agent Integration**: AI agents require consistent, predictable interfaces\n5. **Product Maturity**: Interface consistency is essential for v1.0.0 readiness\n\n## Related Issues\n- Performance benchmarking needs unified access (#benchmark)\n- Search functionality discoverability (#search)  \n- MCP server stability improvements (#mcp)\n- Developer experience improvements (#developer-experience)\n\n## Implementation Plan\n1. **Document Current State** ✅ (this issue)\n2. **Design Service Architecture** - Create detailed technical design\n3. **Proof of Concept** - Refactor one command/tool pair\n4. **Incremental Migration** - Move remaining functionality to services\n5. **Validation & Testing** - Ensure parity and performance\n6. **Documentation Update** - Single source of truth for capabilities\n\n---\n\n**Note**: This issue was discovered through systematic dogfooding validation, demonstrating the critical importance of comprehensive self-testing in maintaining product quality.\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/547/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/547/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/545","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/545/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/545/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/545/events","html_url":"https://github.com/kotadb/kota-db/issues/545","id":3381481245,"node_id":"I_kwDOPFZ-b87JjU8d","number":545,"title":"perf(indexing): CLI indexing operation times out on moderate codebases","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504068,"node_id":"LA_kwDOPFZ-b88AAAACEQVxxA","url":"https://api.github.com/repos/kotadb/kota-db/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":9066998567,"node_id":"LA_kwDOPFZ-b88AAAACHG9rJw","url":"https://api.github.com/repos/kotadb/kota-db/labels/performance","name":"performance","color":"fbca04","default":false,"description":"Performance related issues"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9118359001,"node_id":"LA_kwDOPFZ-b88AAAACH38d2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/dogfooding","name":"dogfooding","color":"6f42c1","default":false,"description":"Self-analysis and validation features"},{"id":9118359007,"node_id":"LA_kwDOPFZ-b88AAAACH38d3w","url":"https://api.github.com/repos/kotadb/kota-db/labels/index","name":"index","color":"0366d6","default":false,"description":"Index system related issues"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9137694578,"node_id":"LA_kwDOPFZ-b88AAAACIKYncg","url":"https://api.github.com/repos/kotadb/kota-db/labels/cli","name":"cli","color":"0366d6","default":false,"description":"Command-line interface issues"},{"id":9241966162,"node_id":"LA_kwDOPFZ-b88AAAACJt02Ug","url":"https://api.github.com/repos/kotadb/kota-db/labels/indexing","name":"indexing","color":"0366d6","default":false,"description":"Codebase indexing and parsing functionality"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":{"url":"https://api.github.com/repos/kotadb/kota-db/milestones/3","html_url":"https://github.com/kotadb/kota-db/milestone/3","labels_url":"https://api.github.com/repos/kotadb/kota-db/milestones/3/labels","id":13633839,"node_id":"MI_kwDOPFZ-b84A0Akv","number":3,"title":"v0.6.1","description":"High priority fixes and improvements for v0.6.1","creator":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"open_issues":3,"closed_issues":0,"state":"open","created_at":"2025-09-07T21:13:21Z","updated_at":"2025-09-13T16:14:08Z","due_on":"2025-01-15T08:00:00Z","closed_at":null},"comments":1,"created_at":"2025-09-03T22:27:44Z","updated_at":"2025-09-07T21:14:39Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## 🐌 Performance Regression in CLI Indexing\n\n### Problem  \nCLI indexing operation consistently times out after 2+ minutes when indexing KotaDB's own codebase.\n\n### Command That Fails\n```bash\ncargo run --bin kotadb -- -d ./data index-codebase .\n```\n\n### Observed Behavior\n- **Timeout**: Process runs for 2+ minutes then times out\n- **Partial Data**: Creates `symbols.kota` file (1.9MB) but indexing never completes\n- **No Completion Signal**: Process doesn't finish normally or report completion\n- **Consistent Reproduction**: 100% reproduction rate on KotaDB codebase\n\n### Expected Behavior\n- **Fast Completion**: Indexing should complete in <30 seconds for moderate codebases\n- **Progress Reporting**: Should show indexing progress and completion status\n- **Full Data**: Should create complete index with all files processed\n\n### Impact\n- **Severity**: HIGH - Blocks dogfooding and real usage\n- **Scope**: Anyone trying to index moderate to large codebases\n- **Discovery**: Found during MCP server dogfooding session\n- **Downstream Effect**: Prevents MCP server functional testing due to no indexed data\n\n### Environment\n- **Codebase Size**: KotaDB (~200 source files, mixed Rust/config/docs)\n- **System**: macOS (Darwin 23.4.0)\n- **Build**: Debug mode (`cargo run`)\n\n### Investigation Needed\n1. **Performance Profiling**: Identify bottleneck in indexing pipeline\n2. **Memory Usage**: Check for memory leaks or excessive allocation\n3. **Infinite Loops**: Verify no loops in file processing\n4. **Concurrency Issues**: Check for deadlocks in async operations\n5. **Regression Testing**: Compare against known-good indexing performance\n\n### Potential Root Causes\n- Infinite loop in symbol extraction\n- Memory exhaustion causing slowdown\n- Deadlock in async file processing\n- Performance regression from recent changes\n- Issues with concurrent indexing operations\n\n### Workaround\nCurrently no known workaround - indexing is blocked entirely.\n\n### Files to Investigate  \n- `src/bin/kotadb.rs` - CLI indexing command\n- `src/file_storage.rs` - Storage operations during indexing\n- `src/primary_index.rs` - Index building during ingestion\n- `src/trigram_index.rs` - Trigram indexing performance\n- Symbol extraction code paths\n\n### Success Criteria\n- Indexing completes in <30 seconds on KotaDB codebase\n- No timeouts or hanging processes\n- Complete symbol and content indexing\n- Progress reporting during operation\n- Memory usage remains reasonable (<1GB)","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/545/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/545/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/534","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/534/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/534/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/534/events","html_url":"https://github.com/kotadb/kota-db/issues/534","id":3381014613,"node_id":"I_kwDOPFZ-b87JhjBV","number":534,"title":"[Dogfooding] MCP Server compilation error in services_tools.rs","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504068,"node_id":"LA_kwDOPFZ-b88AAAACEQVxxA","url":"https://api.github.com/repos/kotadb/kota-db/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":9066998489,"node_id":"LA_kwDOPFZ-b88AAAACHG9q2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/mcp","name":"mcp","color":"0052cc","default":false,"description":"Model Context Protocol related"},{"id":9118359001,"node_id":"LA_kwDOPFZ-b88AAAACH38d2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/dogfooding","name":"dogfooding","color":"6f42c1","default":false,"description":"Self-analysis and validation features"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9187622996,"node_id":"LA_kwDOPFZ-b88AAAACI6AAVA","url":"https://api.github.com/repos/kotadb/kota-db/labels/crashes","name":"crashes","color":"d73a4a","default":false,"description":"Issues causing application crashes or panics"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2025-09-03T19:28:13Z","updated_at":"2025-09-03T22:18:20Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Problem Found During MCP Dogfooding\n\n**Test scenario:** Starting MCP server for dogfooding session using `cargo run --bin mcp_server --features=\"mcp-server\" -- --config kotadb-mcp-dev.toml`\n\n**Expected behavior:** MCP server should compile and start successfully\n\n**Actual behavior:** Compilation fails with type mismatch errors in incremental_update method call\n\n**Reproduction steps:** \n1. Run `cargo run --bin mcp_server --features=\"mcp-server\" -- --config kotadb-mcp-dev.toml`\n2. Observe compilation errors\n\n**Error details:**\n```\nerror[E0308]: mismatched types\n   --> src/mcp/services_tools.rs:436:55\n    |\n436 |             match indexing_service.incremental_update(&PathBuf::from(repo_path)).await {\n    |                                    ------------------ ^^^^^^^^^^^^^^^^^^^^^^^^^ expected `IncrementalUpdateOptions`, found `&PathBuf`\n\nerror[E0308]: `if` and `else` have incompatible types\n   --> src/mcp/services_tools.rs:436:13\n    |\n419 |            let result = if force_full_reindex {\n    |                         ^^^^^^^ expected `IndexResult`, found `Value`\n```\n\n**Impact:** MCP server cannot start, blocking all MCP-based dogfooding validation\n\n**Fix required:** \n1. Fix incremental_update method call to use proper IncrementalUpdateOptions struct\n2. Fix return type mismatch between IndexResult and Value in conditional logic","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/534/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/534/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/530","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/530/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/530/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/530/events","html_url":"https://github.com/kotadb/kota-db/issues/530","id":3380788376,"node_id":"I_kwDOPFZ-b87JgryY","number":530,"title":"[Strategic Initiative] KotaDB Value Demonstration Framework - Fair Testing Protocol","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9118359026,"node_id":"LA_kwDOPFZ-b88AAAACH38d8g","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-large","name":"effort-large","color":"f85149","default":false,"description":"Large effort - more than 3 days"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9187707818,"node_id":"LA_kwDOPFZ-b88AAAACI6FLqg","url":"https://api.github.com/repos/kotadb/kota-db/labels/meta","name":"meta","color":"8B5CF6","default":false,"description":"Meta issues for strategic planning and architecture"},{"id":9220190270,"node_id":"LA_kwDOPFZ-b88AAAACJZDwPg","url":"https://api.github.com/repos/kotadb/kota-db/labels/strategic","name":"strategic","color":"8B5CF6","default":false,"description":"Strategic initiatives and planning"},{"id":9220190308,"node_id":"LA_kwDOPFZ-b88AAAACJZDwZA","url":"https://api.github.com/repos/kotadb/kota-db/labels/value-demonstration","name":"value-demonstration","color":"0e8a16","default":false,"description":"Value demonstration and competitive analysis"},{"id":9220190392,"node_id":"LA_kwDOPFZ-b88AAAACJZDwuA","url":"https://api.github.com/repos/kotadb/kota-db/labels/benchmarking","name":"benchmarking","color":"0052cc","default":false,"description":"Performance benchmarking and comparative testing"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2025-09-03T18:09:47Z","updated_at":"2025-09-03T21:54:16Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Problem Statement\n\nKotaDB's core value proposition - dramatically improving codebase analysis speed and efficiency for AI assistants - needs robust demonstration through **fair, unbiased testing**. Current success shows **3 minutes vs 10 minutes** with fewer tokens and similar quality conclusions, but this advantage may be skewed by Claude's pre-existing knowledge of popular codebases.\n\n### Current Challenge\n- Claude has extensive pre-existing knowledge of popular repositories (VS Code, React, Linux kernel, etc.)\n- This creates **unfair advantages** where Claude can provide detailed analysis without actually needing to examine code\n- Need controlled testing environment that demonstrates **genuine KotaDB value** rather than knowledge recall\n\n### Proven Success Metrics\n- **70% time reduction**: 3 minutes vs 10 minutes for complex analysis\n- **Significant token savings**: Reduced API costs through efficient information retrieval\n- **Consistent quality**: Similar or better analysis depth and accuracy\n- **Reduced subagent usage**: More direct, focused analysis paths\n\n## Repository Selection Criteria\n\nTo ensure fair testing, target repositories that are likely **outside Claude's training data**:\n\n### Primary Criteria\n1. **Recent Development**: Post-2023 projects (likely outside training cutoff)\n2. **Domain-Specific**: Specialized applications vs general-purpose tools\n3. **Enterprise/Internal**: Private or enterprise-focused repositories\n4. **Niche Technology**: Custom frameworks, proprietary tech stacks\n5. **Limited Public Visibility**: Lower GitHub stars, minimal documentation\n\n### Target Repository Categories\n\n#### 🏭 Industry-Specific Applications\n- **Supply Chain Management**: Inventory tracking, logistics optimization\n- **Healthcare/Biotech**: Clinical trial management, lab information systems\n- **Manufacturing**: Production planning, quality control systems  \n- **Financial Services**: Risk management tools, compliance platforms\n\n#### 🚀 Recent Startups & Emerging Companies\n- **Y Combinator 2024 cohort**: Recently launched applications\n- **Series A/B startups**: Internal tooling and specialized platforms\n- **Vertical SaaS**: Industry-specific software solutions\n- **B2B Internal Tools**: Enterprise workflow automation\n\n#### 🔧 Specialized Technology Stacks\n- **Custom Frameworks**: Company-specific development frameworks\n- **Legacy Modernization**: Modernized mainframe applications\n- **IoT/Edge Computing**: Device management and data processing\n- **Blockchain/DeFi**: Smart contract platforms and DeFi protocols\n\n#### 🏢 Enterprise Internal Repositories\n- **Internal Developer Tools**: Build systems, deployment pipelines\n- **Business Process Automation**: Workflow engines, approval systems\n- **Data Processing Pipelines**: ETL systems, analytics platforms\n- **Integration Platforms**: API gateways, middleware solutions\n\n## Testing Protocol\n\n### Standardized Benchmark Queries\nDevelop consistent analysis tasks that test KotaDB's core capabilities:\n\n1. **Architecture Analysis**\n   - \"Analyze the overall system architecture and identify key components\"\n   - \"Map data flow through the application\"\n   - \"Identify potential scalability bottlenecks\"\n\n2. **Dependency Impact Analysis**\n   - \"Find all code that would be affected by changing [specific function/class]\"\n   - \"Trace the execution path from API endpoint to database\"\n   - \"Identify circular dependencies and tight coupling\"\n\n3. **Code Quality Assessment**\n   - \"Find potential security vulnerabilities in authentication code\"\n   - \"Identify performance optimization opportunities\"\n   - \"Locate error handling gaps and improvement areas\"\n\n4. **Feature Understanding**\n   - \"Explain how [specific feature] works end-to-end\"\n   - \"Find all configuration options and their effects\"\n   - \"Identify extension points and customization opportunities\"\n\n### Controlled Comparison Framework\n\n#### Test Environment Setup\n- **Control Group**: Claude analyzing codebase without KotaDB\n- **Test Group**: Claude analyzing same codebase with KotaDB integration\n- **Blind Testing**: Evaluators unaware of which analysis used KotaDB\n\n#### Measurement Metrics\n- **Time Efficiency**: Total analysis time from start to completion\n- **Token Usage**: API costs and computational overhead\n- **Quality Score**: Analysis depth, accuracy, and completeness\n- **Subagent Usage**: Number of context switches and tool invocations\n- **Consistency**: Reliability across multiple runs\n\n### Quality Assessment Criteria\n\n#### Analysis Completeness (40%)\n- Identifies all major system components\n- Maps critical data flows and dependencies\n- Covers security, performance, and maintainability aspects\n\n#### Technical Accuracy (30%)\n- Correctly identifies code patterns and architectures\n- Accurate assessment of potential issues and risks\n- Valid recommendations for improvements\n\n#### Efficiency & Focus (30%)\n- Direct path to conclusions without excessive exploration\n- Relevant findings without information overload\n- Practical, actionable insights\n\n## Success Metrics & KPIs\n\n### Primary Success Indicators\n- **Time Reduction**: Target 50-70% faster analysis\n- **Cost Efficiency**: 40-60% token/API cost savings  \n- **Quality Maintenance**: Equal or superior analysis quality\n- **Consistency**: <10% variance across multiple runs\n\n### Secondary Benefits\n- **Reduced Context Switching**: Fewer tool invocations and subagent usage\n- **Deeper Insights**: Access to relationships not visible without indexing\n- **Scalability**: Consistent performance on large, complex codebases\n- **Reproducibility**: Consistent results across different analysis sessions\n\n## Implementation Roadmap\n\n### Phase 1: Repository Identification & Vetting (Week 1-2)\n- [ ] Compile candidate repository list across target categories\n- [ ] Verify repositories meet selection criteria (recent, specialized, limited visibility)\n- [ ] Establish baseline complexity metrics (lines of code, file count, dependency depth)\n- [ ] Ensure legal compliance for analysis (public repositories, appropriate licensing)\n\n### Phase 2: Testing Infrastructure Development (Week 3-4)\n- [ ] Create standardized benchmark query sets\n- [ ] Build automated comparison framework\n- [ ] Develop metrics collection and analysis system\n- [ ] Establish quality assessment rubrics and scoring\n\n### Phase 3: Pilot Testing & Refinement (Week 5-6)\n- [ ] Run initial tests on 5-10 candidate repositories\n- [ ] Refine testing protocol based on initial results\n- [ ] Adjust metrics and quality criteria\n- [ ] Validate statistical significance of performance differences\n\n### Phase 4: Comprehensive Validation (Week 7-8)\n- [ ] Execute full testing protocol across 20+ repositories\n- [ ] Collect comprehensive performance and quality data\n- [ ] Statistical analysis and confidence interval calculation\n- [ ] Document findings and create demonstration materials\n\n### Phase 5: Results & Documentation (Week 9-10)\n- [ ] Create executive summary and technical reports\n- [ ] Develop sales demonstration materials\n- [ ] Build automated demo environment for prospects\n- [ ] Establish ongoing monitoring for continued validation\n\n## Expected Outcomes\n\n### Competitive Advantage Validation\n- **Quantified Value Proposition**: Concrete metrics showing KotaDB's efficiency gains\n- **Fair Comparison**: Results that aren't skewed by pre-existing knowledge\n- **Enterprise Confidence**: Proof that benefits scale to unknown, complex codebases\n\n### Sales & Marketing Assets\n- **Demo Environment**: Standardized demonstration for prospects\n- **Case Studies**: Real-world examples across different domains\n- **ROI Calculator**: Tools for prospects to estimate their own benefits\n- **Competitive Analysis**: Clear differentiation from alternative solutions\n\n### Product Development Insights\n- **Feature Validation**: Confirmation of which capabilities provide most value\n- **Performance Optimization**: Areas where further speed improvements needed\n- **User Experience**: Insights into optimal workflow patterns\n- **Market Fit**: Understanding of target customer segments and use cases\n\n## Resource Requirements\n\n### Technical Resources\n- **Development Time**: ~40 hours for infrastructure development\n- **Testing Environment**: Dedicated testing infrastructure and automation\n- **API Credits**: Budget for extensive Claude API usage during testing\n- **Analysis Tools**: Statistical analysis and visualization tools\n\n### Research & Analysis\n- **Repository Research**: Time to identify and vet candidate repositories\n- **Domain Expertise**: Understanding of different industry contexts\n- **Statistical Analysis**: Proper experimental design and result analysis\n- **Documentation**: Comprehensive reporting and material creation\n\n## Risk Mitigation\n\n### Potential Challenges\n- **Repository Access**: Some interesting repositories may be private\n- **Complexity Variation**: Different codebases may have varying complexity levels\n- **Evaluation Subjectivity**: Quality assessment may have subjective elements\n- **Selection Bias**: Risk of unconsciously selecting repositories that favor KotaDB\n\n### Mitigation Strategies\n- **Diverse Repository Pool**: Large sample size across multiple categories\n- **Blind Evaluation**: Third-party assessment of analysis quality\n- **Statistical Rigor**: Proper experimental design with confidence intervals\n- **Peer Review**: External validation of methodology and results\n\n## Next Steps\n\n1. **Immediate Actions** (This Week)\n   - Begin repository identification and initial vetting\n   - Create detailed project timeline and resource allocation\n   - Establish success criteria and measurement frameworks\n\n2. **Short-term Goals** (Next 2 Weeks)\n   - Complete repository candidate list (50+ options)\n   - Begin testing infrastructure development\n   - Finalize benchmark query specifications\n\n3. **Medium-term Objectives** (Next Month)\n   - Complete pilot testing phase\n   - Refine and validate testing protocol\n   - Begin comprehensive validation testing\n\nThis initiative is **critical for KotaDB's market positioning** and will provide the foundation for compelling, data-driven demonstrations of our core value proposition to enterprise customers.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/530/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/530/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/512","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/512/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/512/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/512/events","html_url":"https://github.com/kotadb/kota-db/issues/512","id":3377540547,"node_id":"I_kwDOPFZ-b87JUS3D","number":512,"title":"kotadb-api-server exits immediately with code 0 on Fly.io deployment","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504068,"node_id":"LA_kwDOPFZ-b88AAAACEQVxxA","url":"https://api.github.com/repos/kotadb/kota-db/labels/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"},{"id":9066998377,"node_id":"LA_kwDOPFZ-b88AAAACHG9qaQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/production-blocker","name":"production-blocker","color":"b60205","default":false,"description":"Issues blocking production deployment"},{"id":9067343361,"node_id":"LA_kwDOPFZ-b88AAAACHHSuAQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/docker","name":"docker","color":"21ceff","default":false,"description":"Pull requests that update docker code"},{"id":9117255530,"node_id":"LA_kwDOPFZ-b88AAAACH25Hag","url":"https://api.github.com/repos/kotadb/kota-db/labels/infrastructure","name":"infrastructure","color":"6c757d","default":false,"description":"Infrastructure and environment issues"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9253151945,"node_id":"LA_kwDOPFZ-b88AAAACJ4fkyQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/launch-prep","name":"launch-prep","color":"d93f0b","default":false,"description":"Launch preparation tasks and cleanup"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":{"url":"https://api.github.com/repos/kotadb/kota-db/milestones/6","html_url":"https://github.com/kotadb/kota-db/milestone/6","labels_url":"https://api.github.com/repos/kotadb/kota-db/milestones/6/labels","id":13683963,"node_id":"MI_kwDOPFZ-b84A0Mz7","number":6,"title":"Launch Readiness (Pre-Launch)","description":"Track launch-blocking API, infra, and deployment tasks (HTTP API endpoints, Fly.io boot, CI/CD auto-deploy, server cleanup).","creator":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"open_issues":2,"closed_issues":3,"state":"open","created_at":"2025-09-13T16:14:03Z","updated_at":"2025-09-22T22:14:48Z","due_on":"2025-09-20T07:00:00Z","closed_at":null},"comments":6,"created_at":"2025-09-02T21:28:06Z","updated_at":"2025-09-13T16:14:09Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Problem\n\nThe kotadb-api-server binary exits immediately with exit code 0 when deployed to Fly.io, despite working perfectly when run locally. No application logs are produced despite setting `RUST_LOG=debug`.\n\n## Current Behavior\n\n- ✅ **Local development**: Server starts successfully and responds to health checks\n- ❌ **Fly.io deployment**: Binary exits immediately with code 0\n- ❌ **No logging output**: Despite `RUST_LOG=debug` being set\n- ❌ **Health endpoint unreachable**: https://kotadb-api-staging.fly.dev/health returns connection errors\n\n## What We've Tried\n\n### 1. Logging Configuration Fixes\n- Fixed logging initialization to respect `RUST_LOG` environment variable\n- Added explicit tracing subscriber initialization\n- Verified logging works locally with debug output\n\n### 2. Docker Build Improvements\n- Modified `Dockerfile.production` to ensure proper binary building\n- Removed stub binary after dependency build phase\n- Verified binary exists in final container layer\n- Used multi-stage build with explicit binary copying\n\n### 3. Deployment Troubleshooting  \n- Used `--local-only` flag to avoid Docker build caching issues\n- Added debugging output to `docker-entrypoint.sh`\n- Tested with fresh deployments to eliminate cached artifacts\n\n### 4. Local Verification\n- ✅ Server works perfectly locally with Supabase connection\n- ✅ `curl http://localhost:8081/health` returns successful JSON response\n- ✅ All API endpoints functional during local testing\n\n## Evidence of the Problem\n\n### Local Success\n```bash\n$ cargo run --bin kotadb-api-server\n2024-XX-XX INFO kotadb_api_server: Starting KotaDB API Server\n2024-XX-XX INFO kotadb_api_server: Server running on http://0.0.0.0:8081\n\n$ curl http://localhost:8081/health\n{\"status\":\"healthy\",\"version\":\"0.4.0\"}\n```\n\n### Fly.io Failure\n```bash\n$ fly logs\n2024-XX-XX [info] Starting init (commit: 633b8d9...)  \n2024-XX-XX [info] Preparing to run: `/app/docker-entrypoint.sh` as root\n2024-XX-XX [info] 2024/XX/XX XX:XX:XX listening on [fdaa:x:x:x::x]:22 (DNS: [fdaa::3]:53)\n# Binary exits here with code 0 - no application logs despite RUST_LOG=debug\n```\n\n### Binary Size Issue Observed\n- Expected binary size: ~11MB (based on local builds)\n- Observed in container: 379KB (indicating potential build issue)\n- Binary exists at correct path but may be malformed\n\n## Environment Details\n\n### Deployment Configuration\n- **Platform**: Fly.io\n- **Dockerfile**: `Dockerfile.production` (multi-stage build)\n- **Deployment command**: `fly deploy --local-only`\n- **Base image**: `debian:bookworm-slim`\n\n### Environment Variables Set\n```\nDATABASE_URL=postgresql://...  # Supabase connection (verified working locally)\nPORT=8081\nRUST_LOG=debug\nKOTADB_DATA_DIR=/tmp/kotadb-data\n```\n\n### Dependencies\n- **Database**: Supabase PostgreSQL (connection tested and working locally)\n- **Rust version**: Latest stable\n- **Build target**: x86_64-unknown-linux-gnu\n\n## What Success Looks Like\n\n- [x] Server starts and stays running on Fly.io\n- [x] Health endpoint accessible at https://kotadb-api-staging.fly.dev/health\n- [x] Proper logging output showing server initialization messages\n- [x] API endpoints available and responding correctly\n- [x] Stable deployment without immediate exits\n\n## Technical Investigation Needed\n\n1. **Binary integrity verification**: Check if the binary is built correctly in the Docker container\n2. **Runtime dependencies**: Verify all shared libraries are available in the deployment environment  \n3. **Startup sequence debugging**: Add more detailed logging to identify where the process fails\n4. **Environment variable validation**: Ensure all required environment variables are properly set\n5. **Database connectivity**: Verify database connection doesn't cause silent failures\n\n## Related Issues\n\n- Related to #510: Migration from Railway to Fly.io\n- This is blocking production deployment of the API server\n\n## Priority\n\nThis is a **high-priority production blocker** as it prevents the API server from being deployed and accessible to users.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/512/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/512/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/492","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/492/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/492/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/492/events","html_url":"https://github.com/kotadb/kota-db/issues/492","id":3370365303,"node_id":"I_kwDOPFZ-b87I47F3","number":492,"title":"Wire up MCP relationship tools with BinaryRelationshipEngine","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9066998489,"node_id":"LA_kwDOPFZ-b88AAAACHG9q2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/mcp","name":"mcp","color":"0052cc","default":false,"description":"Model Context Protocol related"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9118359037,"node_id":"LA_kwDOPFZ-b88AAAACH38d_Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-medium","name":"effort-medium","color":"fbca04","default":false,"description":"Medium effort (1-3 days)"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-08-31T14:47:49Z","updated_at":"2025-08-31T14:47:49Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Problem\nThe MCP (Model Context Protocol) server currently doesn't expose relationship analysis tools, limiting its capability for codebase intelligence queries. The new BinaryRelationshipEngine provides high-performance relationship queries but isn't integrated with the MCP server.\n\n## Current State\n- Document CRUD tools are available in MCP server\n- BinaryRelationshipEngine exists but not exposed via MCP\n- Web applications and AI assistants can't access relationship analysis\n\n## Proposed Solution\n\n### New MCP Tools\n1. **kotadb_find_callers** - Find all functions/methods that call a given symbol\n2. **kotadb_analyze_impact** - Analyze the impact of changing a symbol\n3. **kotadb_search_symbols** - Search for symbols with wildcard patterns\n4. **kotadb_get_dependencies** - Get dependency graph for a symbol\n5. **kotadb_codebase_stats** - Get comprehensive codebase statistics\n\n### Implementation Strategy\n```rust\n// Example tool registration:\n#[derive(Debug, Serialize, Deserialize)]\nstruct FindCallersRequest {\n    symbol: String,\n    repository_path: Option<String>,\n}\n\nasync fn handle_find_callers(params: serde_json::Value) -> Result<serde_json::Value> {\n    // Use BinaryRelationshipEngine with spawn_blocking\n}\n```\n\n## Dependencies\n- **Depends on**: #490 (BinaryRelationshipEngine thread safety)\n- **Can work in parallel with**: #491 (HTTP API endpoints)\n\n## Configuration Updates\nUpdate \\`kotadb-mcp-dev.toml\\`:\n```toml\n[relationship_engine]\nenabled = true\n# Other configuration options\n```\n\n## Test Plan\n- [ ] MCP client can discover new relationship tools\n- [ ] Each tool returns correct JSON responses\n- [ ] Error handling works properly\n- [ ] Performance acceptable for AI assistant usage\n- [ ] Integration tests with Claude Code\n- [ ] Backward compatibility with existing document tools\n\n## Acceptance Criteria\n- All relationship tools available via MCP protocol\n- Tools use BinaryRelationshipEngine for performance\n- Proper error handling and responses\n- Configuration options work correctly\n- Full integration test coverage\n- No breaking changes to existing MCP functionality\n\n## Effort  \nMedium - estimated 2 days","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/492/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/492/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/481","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/481/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/481/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/481/events","html_url":"https://github.com/kotadb/kota-db/issues/481","id":3369378553,"node_id":"I_kwDOPFZ-b87I1KL5","number":481,"title":"Set up CI/CD deployment infrastructure with auto-deploy to staging/production","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9067343361,"node_id":"LA_kwDOPFZ-b88AAAACHHSuAQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/docker","name":"docker","color":"21ceff","default":false,"description":"Pull requests that update docker code"},{"id":9067343725,"node_id":"LA_kwDOPFZ-b88AAAACHHSvbQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/github_actions","name":"github_actions","color":"000000","default":false,"description":"Pull requests that update GitHub Actions code"},{"id":9117255494,"node_id":"LA_kwDOPFZ-b88AAAACH25HRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/ci/cd","name":"ci/cd","color":"ffd33d","default":false,"description":"Continuous Integration/Deployment issues"},{"id":9117255530,"node_id":"LA_kwDOPFZ-b88AAAACH25Hag","url":"https://api.github.com/repos/kotadb/kota-db/labels/infrastructure","name":"infrastructure","color":"6c757d","default":false,"description":"Infrastructure and environment issues"},{"id":9118359026,"node_id":"LA_kwDOPFZ-b88AAAACH38d8g","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-large","name":"effort-large","color":"f85149","default":false,"description":"Large effort - more than 3 days"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9124823878,"node_id":"LA_kwDOPFZ-b88AAAACH-HDRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/feature","name":"feature","color":"0075ca","default":false,"description":"Major new feature implementation"},{"id":9167968495,"node_id":"LA_kwDOPFZ-b88AAAACInQY7w","url":"https://api.github.com/repos/kotadb/kota-db/labels/production-readiness","name":"production-readiness","color":"d93f0b","default":false,"description":"Production deployment readiness items"},{"id":9253151945,"node_id":"LA_kwDOPFZ-b88AAAACJ4fkyQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/launch-prep","name":"launch-prep","color":"d93f0b","default":false,"description":"Launch preparation tasks and cleanup"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":{"url":"https://api.github.com/repos/kotadb/kota-db/milestones/6","html_url":"https://github.com/kotadb/kota-db/milestone/6","labels_url":"https://api.github.com/repos/kotadb/kota-db/milestones/6/labels","id":13683963,"node_id":"MI_kwDOPFZ-b84A0Mz7","number":6,"title":"Launch Readiness (Pre-Launch)","description":"Track launch-blocking API, infra, and deployment tasks (HTTP API endpoints, Fly.io boot, CI/CD auto-deploy, server cleanup).","creator":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"open_issues":2,"closed_issues":3,"state":"open","created_at":"2025-09-13T16:14:03Z","updated_at":"2025-09-22T22:14:48Z","due_on":"2025-09-20T07:00:00Z","closed_at":null},"comments":0,"created_at":"2025-08-30T18:37:07Z","updated_at":"2025-09-13T16:14:10Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Overview\n\nSet up comprehensive CI/CD deployment infrastructure with automatic deployment to staging and production environments. This is critical for:\n- Rapid iteration and deployment of API changes\n- Testing changes before production release\n- Supporting the web app integration at app.kotadb.io\n- Enabling continuous delivery for both KotaDB API service and MCP server\n\n## Deployment Pipeline Architecture\n\n### Deployment Triggers\n- **Staging Environment**: Auto-deploy on pushes to `develop` branch\n  - URL: `staging.api.kotadb.io` \n  - MCP Server: `staging.mcp.kotadb.io`\n- **Production Environment**: Auto-deploy on pushes to `main` branch\n  - URL: `api.kotadb.io`\n  - MCP Server: `mcp.kotadb.io`\n\n### Services to Deploy\n1. **KotaDB API Service** (main binary from Dockerfile.prod)\n2. **MCP Server** (from Dockerfile.mcp)\n3. **Static Documentation** (extend existing docs-deploy.yml)\n\n## Cloud Infrastructure Requirements\n\n### Container Orchestration Options\n**Recommended: Google Cloud Run** (serverless, cost-effective)\n- Auto-scaling based on traffic\n- Pay-per-request pricing\n- Built-in SSL/TLS termination\n- Easy rollback mechanisms\n\n**Alternative: AWS ECS Fargate**\n- Similar serverless container model\n- Integrates well with ALB for load balancing\n\n### Storage & Persistence\n```yaml\n# Persistent storage for database files\nvolumes:\n  - name: kotadb-data\n    type: persistent-disk\n    size: 100GB\n    mount: /data\n```\n\n### Load Balancing & SSL\n- **SSL/TLS**: Automatic certificate management (Cloud Run handles this)\n- **Load Balancing**: Built-in with container orchestration\n- **CDN**: CloudFront/CloudFlare for static assets\n\n## CI/CD Pipeline Implementation\n\n### GitHub Actions Workflow Structure\n\n```yaml\nname: Deploy\n\non:\n  push:\n    branches: [main, develop]\n\nenv:\n  PROJECT_ID: kotadb-prod\n  SERVICE_NAME: kotadb-api\n  REGION: us-central1\n\njobs:\n  build-and-deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      \n      - name: Set up Cloud SDK\n        uses: google-github-actions/setup-gcloud@v1\n        with:\n          project_id: ${{ secrets.GCP_PROJECT_ID }}\n          service_account_key: ${{ secrets.GCP_SA_KEY }}\n      \n      - name: Configure Docker for GCR\n        run: gcloud auth configure-docker\n      \n      - name: Determine environment\n        id: env\n        run: |\n          if [[ ${{ github.ref }} == 'refs/heads/main' ]]; then\n            echo \"environment=production\" >> $GITHUB_OUTPUT\n            echo \"url=api.kotadb.io\" >> $GITHUB_OUTPUT\n            echo \"service=kotadb-api-prod\" >> $GITHUB_OUTPUT\n          else\n            echo \"environment=staging\" >> $GITHUB_OUTPUT\n            echo \"url=staging.api.kotadb.io\" >> $GITHUB_OUTPUT\n            echo \"service=kotadb-api-staging\" >> $GITHUB_OUTPUT\n          fi\n      \n      - name: Build and push API service\n        run: |\n          docker build -f Dockerfile.prod -t gcr.io/$PROJECT_ID/${{ steps.env.outputs.service }}:${{ github.sha }} .\n          docker push gcr.io/$PROJECT_ID/${{ steps.env.outputs.service }}:${{ github.sha }}\n      \n      - name: Build and push MCP server\n        run: |\n          docker build -f Dockerfile.mcp -t gcr.io/$PROJECT_ID/kotadb-mcp-${{ steps.env.outputs.environment }}:${{ github.sha }} .\n          docker push gcr.io/$PROJECT_ID/kotadb-mcp-${{ steps.env.outputs.environment }}:${{ github.sha }}\n      \n      - name: Deploy to Cloud Run\n        run: |\n          gcloud run deploy ${{ steps.env.outputs.service }} \\\n            --image gcr.io/$PROJECT_ID/${{ steps.env.outputs.service }}:${{ github.sha }} \\\n            --platform managed \\\n            --region $REGION \\\n            --allow-unauthenticated \\\n            --set-env-vars ENVIRONMENT=${{ steps.env.outputs.environment }} \\\n            --memory 2Gi \\\n            --cpu 2 \\\n            --min-instances 0 \\\n            --max-instances 10\n      \n      - name: Health check\n        run: |\n          sleep 30\n          curl -f https://${{ steps.env.outputs.url }}/health || exit 1\n```\n\n### Pipeline Steps Detail\n\n1. **Quality Gates** (extend existing ci.yml)\n   ```bash\n   just fmt          # Code formatting\n   just clippy       # Linting (zero warnings)\n   just test         # All tests must pass\n   just check        # Combined quality checks\n   ```\n\n2. **Security Scanning**\n   ```bash\n   cargo audit       # Dependency vulnerabilities\n   cargo deny check  # License compliance\n   ```\n\n3. **Docker Image Build**\n   - Multi-stage builds using existing Dockerfiles\n   - Layer caching for faster builds\n   - Image vulnerability scanning\n   - Push to container registry (GCR/ECR)\n\n4. **Deployment**\n   - Environment-specific configuration\n   - Health checks before traffic routing\n   - Automatic rollback on failure\n   - Gradual traffic shifting (canary deployments)\n\n5. **Post-deployment Verification**\n   - Health endpoint checks\n   - Integration tests against deployed service\n   - Performance regression tests\n   - Notify team of deployment status\n\n## Monitoring and Observability\n\n### Metrics Collection (Prometheus-compatible)\n```yaml\n# Expose metrics endpoint\nendpoints:\n  - path: /metrics\n    port: 8080\n    \n# Key metrics to track\nmetrics:\n  - http_requests_total\n  - http_request_duration_seconds\n  - kotadb_query_duration_seconds\n  - kotadb_storage_operations_total\n  - kotadb_active_connections\n```\n\n### Log Aggregation\n- **Google Cloud**: Cloud Logging with structured JSON logs\n- **AWS**: CloudWatch with log groups per environment\n- **Retention**: 30 days for staging, 90 days for production\n\n### Uptime Monitoring\n```yaml\n# Health check endpoints\nendpoints:\n  - url: https://api.kotadb.io/health\n    interval: 1m\n    timeout: 10s\n  - url: https://mcp.kotadb.io/health  \n    interval: 1m\n    timeout: 10s\n\n# Alerting\nalerts:\n  - name: API Down\n    condition: success_rate < 99%\n    duration: 5m\n  - name: High Latency\n    condition: p95_latency > 1s\n    duration: 2m\n```\n\n### Performance Tracking\n- Request/response times\n- Query performance metrics\n- Resource utilization (CPU, memory, disk I/O)\n- Database operation latencies\n\n## Security Implementation\n\n### Secrets Management\n```yaml\n# GitHub Secrets needed\nsecrets:\n  - GCP_PROJECT_ID\n  - GCP_SA_KEY (service account with Cloud Run admin)\n  - DOCKER_REGISTRY_TOKEN\n  - SLACK_WEBHOOK_URL (for notifications)\n  - API_ENCRYPTION_KEY\n  - MCP_AUTH_TOKEN\n```\n\n### Network Security\n- **HTTPS Enforcement**: Automatic redirect HTTP → HTTPS\n- **Rate Limiting**: 1000 requests/minute per IP\n- **CORS**: Configured for app.kotadb.io origin\n- **Request Size Limits**: 10MB max payload\n\n### Container Security\n- **Non-root user**: Run containers as non-privileged user\n- **Read-only filesystem**: Except for /data mount\n- **Security scanning**: Integrate with Snyk/Trivy\n- **Minimal base images**: Use Alpine/distroless images\n\n## Infrastructure as Code\n\n### Terraform Example (GCP)\n```hcl\n# terraform/main.tf\nresource \"google_cloud_run_service\" \"kotadb_api\" {\n  name     = \"kotadb-api-${var.environment}\"\n  location = var.region\n\n  template {\n    spec {\n      containers {\n        image = var.container_image\n        \n        resources {\n          limits = {\n            cpu    = \"2000m\"\n            memory = \"2Gi\"\n          }\n        }\n\n        env {\n          name  = \"ENVIRONMENT\"\n          value = var.environment\n        }\n\n        env {\n          name = \"DATABASE_PATH\"\n          value = \"/data\"\n        }\n\n        volume_mounts {\n          name       = \"data\"\n          mount_path = \"/data\"\n        }\n      }\n\n      volumes {\n        name = \"data\"\n        gcs {\n          bucket    = google_storage_bucket.kotadb_data.name\n          read_only = false\n        }\n      }\n    }\n  }\n\n  traffic {\n    percent         = 100\n    latest_revision = true\n  }\n}\n\nresource \"google_cloud_run_domain_mapping\" \"api\" {\n  location = var.region\n  name     = var.domain\n\n  spec {\n    route_name = google_cloud_run_service.kotadb_api.name\n  }\n}\n```\n\n## Integration with Existing Workflows\n\n### Extend Current GitHub Actions\n1. **ci.yml**: Add deployment conditions after quality gates pass\n2. **release.yml**: Trigger production deployment on tag creation\n3. **quality-gates.yml**: Add deployment-readiness checks\n4. **production-gate.yml**: Add deployment verification steps\n\n### Docker Integration\n- **Dockerfile.prod**: API service (already exists)\n- **Dockerfile.mcp**: MCP server (already exists)  \n- **Dockerfile.dev**: Development environment (already exists)\n\n### Development Workflow\n```bash\n# Local development\njust dev                    # Start with auto-reload\n\n# Pre-deployment testing\njust check                  # All quality checks\ndocker build -f Dockerfile.prod -t kotadb:test .\ndocker run -p 8080:8080 kotadb:test\n\n# Deploy to staging\ngit push origin develop     # Triggers staging deployment\n\n# Deploy to production  \ngit push origin main        # Triggers production deployment\n```\n\n## Rollback and Recovery\n\n### Automatic Rollback Triggers\n- Health check failures (>5 minutes)\n- Error rate >5% \n- Response time >2s p95\n\n### Manual Rollback Process\n```bash\n# Rollback to previous version\ngcloud run services update kotadb-api-prod \\\n  --image gcr.io/kotadb-prod/kotadb-api:PREVIOUS_SHA \\\n  --region us-central1\n\n# Database rollback (if needed)\n# Restore from hourly backups in persistent storage\n```\n\n### Recovery Procedures\n1. **Service Down**: Auto-restart containers, scale up replicas\n2. **Database Corruption**: Restore from backups, replay WAL\n3. **Network Issues**: Health checks with exponential backoff\n4. **Deployment Failure**: Automatic rollback to last known good state\n\n## Implementation Tasks\n\n### Phase 1: Infrastructure Setup (3 days)\n- [ ] Set up cloud accounts and projects (GCP/AWS)\n- [ ] Configure container registries\n- [ ] Create service accounts and IAM roles\n- [ ] Set up persistent storage for databases\n- [ ] Configure DNS and SSL certificates\n\n### Phase 2: CI/CD Pipeline (3 days)  \n- [ ] Extend existing GitHub Actions with deployment steps\n- [ ] Add Docker image building and pushing\n- [ ] Implement environment-specific deployment logic\n- [ ] Add health checks and rollback mechanisms\n- [ ] Configure secrets and environment variables\n\n### Phase 3: Monitoring & Security (2 days)\n- [ ] Set up metrics collection and dashboards\n- [ ] Configure log aggregation and alerting\n- [ ] Implement rate limiting and security headers\n- [ ] Add uptime monitoring and notifications\n- [ ] Security scanning integration\n\n### Phase 4: Testing & Documentation (1 day)\n- [ ] End-to-end deployment testing\n- [ ] Load testing on staging environment\n- [ ] Document deployment procedures\n- [ ] Create runbook for common operations\n- [ ] Team training on new deployment process\n\n## Success Criteria\n\n- [ ] **Staging deployments**: Automatic on `develop` branch pushes (<5 min)\n- [ ] **Production deployments**: Automatic on `main` branch pushes (<5 min)\n- [ ] **Zero-downtime deployments**: Health checks prevent bad deployments\n- [ ] **99.9% uptime**: Monitoring and alerting in place\n- [ ] **Sub-100ms API response times**: Performance monitoring active\n- [ ] **Automatic rollbacks**: Failed deployments rollback within 2 minutes\n- [ ] **Security compliance**: All endpoints HTTPS, rate limiting active\n- [ ] **Cost optimization**: Pay-per-use pricing, auto-scaling enabled\n\n## Related Issues & References\n\n- Existing workflows: `.github/workflows/ci.yml`, `.github/workflows/release.yml`\n- Docker configuration: `Dockerfile.prod`, `Dockerfile.mcp` \n- Quality gates: `justfile` commands (`just check`, `just test`)\n- Web app integration: app.kotadb.io needs reliable API endpoints\n\n## Next Steps\n\n1. **Cloud Platform Selection**: Recommend Google Cloud Run for cost and simplicity\n2. **Environment Setup**: Create staging and production projects\n3. **GitHub Actions Extension**: Modify existing workflows for deployment\n4. **Security Configuration**: Set up secrets and access controls\n5. **Monitoring Integration**: Add observability and alerting\n\nThis infrastructure will enable rapid iteration, reliable deployments, and production-ready hosting for both the KotaDB API and MCP server components.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/481/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/481/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/477","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/477/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/477/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/477/events","html_url":"https://github.com/kotadb/kota-db/issues/477","id":3369265248,"node_id":"I_kwDOPFZ-b87I0uhg","number":477,"title":"Enhancement: Multi-Language Intelligence Pack - Cross-Language Analysis & Filtering","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9118359037,"node_id":"LA_kwDOPFZ-b88AAAACH38d_Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-medium","name":"effort-medium","color":"fbca04","default":false,"description":"Medium effort (1-3 days)"},{"id":9124823937,"node_id":"LA_kwDOPFZ-b88AAAACH-HDgQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/killer-feature","name":"killer-feature","color":"d73a4a","default":false,"description":"Unique features that differentiate KotaDB"},{"id":9183060638,"node_id":"LA_kwDOPFZ-b88AAAACI1ping","url":"https://api.github.com/repos/kotadb/kota-db/labels/codebase-intelligence","name":"codebase-intelligence","color":"6f42c1","default":false,"description":"Codebase intelligence platform features and direction"},{"id":9197456729,"node_id":"LA_kwDOPFZ-b88AAAACJDYNWQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/multi-language","name":"multi-language","color":"0052cc","default":false,"description":"Multi-language support and cross-language analysis"},{"id":9197456752,"node_id":"LA_kwDOPFZ-b88AAAACJDYNcA","url":"https://api.github.com/repos/kotadb/kota-db/labels/intelligence-pack","name":"intelligence-pack","color":"6f42c1","default":false,"description":"Intelligence pack command enhancements"},{"id":9197456788,"node_id":"LA_kwDOPFZ-b88AAAACJDYNlA","url":"https://api.github.com/repos/kotadb/kota-db/labels/cross-language","name":"cross-language","color":"0e8a16","default":false,"description":"Cross-language relationship analysis"},{"id":9197456830,"node_id":"LA_kwDOPFZ-b88AAAACJDYNvg","url":"https://api.github.com/repos/kotadb/kota-db/labels/competitive-advantage","name":"competitive-advantage","color":"d73a4a","default":false,"description":"Features that provide unique market advantages"},{"id":9197456871,"node_id":"LA_kwDOPFZ-b88AAAACJDYN5w","url":"https://api.github.com/repos/kotadb/kota-db/labels/high-value","name":"high-value","color":"0075ca","default":false,"description":"High business value features"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-08-30T16:12:45Z","updated_at":"2025-08-30T16:12:45Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Context & Strategic Opportunity\n\nMulti-language support being added via TypeScript (#464) and Python (#463) creates a unique opportunity for cross-language intelligence that **no other tool in the market provides**. While GitHub Copilot, LSPs, and other tools analyze single languages, KotaDB can analyze relationships and dependencies that span multiple languages - creating a distinct competitive advantage.\n\n## Current Architecture Assessment\n\n✅ **Minimal Changes Required**: Our existing architecture already supports multi-language data:\n- Symbol storage includes `language` field\n- Commands work with multi-language databases\n- No breaking changes needed\n- Storage and index systems language-agnostic\n\n✅ **Foundation Built**: Current Intelligence Pack commands are language-neutral at core level\n\n## Enhancement Categories\n\n### Phase 1: Language Filtering & Enhanced Display\n**Effort**: ~3-5 days | **Value**: High user experience improvement\n\n#### Enhanced Existing Commands\nAdd language awareness to all Intelligence Pack commands:\n\n```bash\n# Language filtering\nkotadb search-symbols \"handle_request\" --language typescript\nkotadb find-callers FileStorage --exclude python,javascript\nkotadb analyze-impact Config --language rust,typescript\n\n# Mixed language display with tags\nkotadb search-symbols \"User*\" --show-language\n# Output: User [TS], UserConfig [RS], user_handler [PY]\n```\n\n#### Implementation Details\n- Add `--language` and `--exclude` flags to all intelligence commands\n- Show language tags in command outputs: `[TS]`, `[PY]`, `[RS]`, `[JS]`\n- Language-aware result formatting and grouping\n- Filter at query level (not post-processing) for performance\n\n### Phase 2: Cross-Language Analysis Commands  \n**Effort**: ~7-10 days | **Value**: Breakthrough competitive advantage\n\n#### New Cross-Language Intelligence Commands\n\n**1. `language-boundaries` - API Boundary Detection**\n```bash\nkotadb language-boundaries\n# Output:\n# HTTP Endpoints (TS → PY):\n#   POST /api/users → user_service.create_user()\n#   GET /api/stats → analytics.get_metrics()\n# \n# FFI Boundaries (RS → C):\n#   unsafe fn parse_native() → libparser.so\n#\n# Import Dependencies (TS → RS):\n#   @kotadb/client → kotadb-mcp-server\n```\n\n**2. `cross-language-impact` - Impact Analysis Across Languages**  \n```bash\nkotadb cross-language-impact \"User\"\n# Output:\n# Cross-Language Impact Analysis for \"User\":\n# \n# TypeScript (3 files):\n#   interface User → affects Python user_service.py\n#   UserValidator → called from Rust validation\n#\n# Python (2 files):  \n#   class User → HTTP API consumed by TS frontend\n#   user_schema → affects Rust type definitions\n```\n\n**3. `type-consistency` - Cross-Language Type Validation**\n```bash\nkotadb type-consistency --api-boundaries\n# Output:\n# Type Consistency Issues Found:\n#\n# API Mismatch (TS ↔ PY):\n#   TS: { userId: string } \n#   PY: { user_id: int }    # ❌ Type & naming mismatch\n#\n# Struct Alignment (RS ↔ FFI):\n#   RS: struct User { id: u64, name: String }\n#   C:  struct User { id: int, name: char* }  # ❌ Size mismatch\n```\n\n#### Implementation Strategy\n- Build on existing symbol extraction and relationship tracking\n- Leverage file extension and Tree-sitter language detection\n- Create cross-language relationship mapping\n- Use graph traversal for boundary detection\n- Pattern matching for API endpoint discovery (HTTP, gRPC, FFI)\n\n### Phase 3: MCP Service Enhancements\n**Effort**: ~2-3 days | **Value**: Enhanced LLM integration\n\n#### Enhanced MCP Tools\n- Language-aware search tools for LLMs\n- Cross-language context gathering\n- Multi-language repository insights for AI assistants\n\n```json\n// Example MCP tool enhancement\n{\n  \"name\": \"search_cross_language_symbols\", \n  \"description\": \"Find symbols and their relationships across all languages\",\n  \"parameters\": {\n    \"pattern\": \"User*\",\n    \"languages\": [\"typescript\", \"python\", \"rust\"],\n    \"include_boundaries\": true\n  }\n}\n```\n\n## Competitive Advantage Analysis\n\n### Market Differentiation\n**No Existing Tool Provides**:\n- Cross-language dependency tracking\n- API boundary detection across language boundaries  \n- Type consistency validation for polyglot codebases\n- Unified symbol search across multiple languages\n- Impact analysis that spans language boundaries\n\n### Existing Tool Limitations\n- **GitHub Copilot**: Single-file, single-language context\n- **LSPs**: Language-specific, no cross-language relationships\n- **grep/ripgrep**: Text search only, no semantic understanding\n- **IDE Search**: Limited to open files, no relationship analysis\n- **SonarQube**: Code quality only, no dependency intelligence\n\n### KotaDB's Unique Value\n✅ **Unified Intelligence**: Single query across all languages  \n✅ **Relationship Mapping**: Understand how TypeScript calls Python APIs  \n✅ **Boundary Detection**: Find all integration points automatically  \n✅ **Impact Analysis**: See how changes ripple across language boundaries  \n✅ **Type Safety**: Detect mismatches before runtime failures  \n\n## Value Examples & Use Cases\n\n### Microservices Architecture\n```bash\n# Find all TypeScript components calling Python services\nkotadb language-boundaries --from typescript --to python\n# Reveals: Frontend components → HTTP endpoints → Python handlers\n\n# Impact analysis for API changes\nkotadb cross-language-impact \"user_service.get_profile\"  \n# Shows: Python change affects 12 TypeScript components\n```\n\n### Full-Stack Development\n```bash\n# Ensure type consistency across stack\nkotadb type-consistency --between typescript python\n# Detects: TS UserProfile !== PY user_profile schema\n\n# Find dead API endpoints  \nkotadb find-callers \"/api/legacy/*\" --language typescript\n# Result: No callers found → safe to remove\n```\n\n### Polyglot Refactoring\n```bash\n# Safe function renaming across languages\nkotadb analyze-impact \"process_payment\" --cross-language\n# Shows impact: Rust → Python → TypeScript call chain\n\n# Dependency cleanup\nkotadb dependency-chain --from rust --to \"*\"\n# Reveals: Which Rust modules are consumed externally\n```\n\n## Implementation Impact & Effort\n\n### Development Timeline\n**Total Effort**: ~2-3 weeks after language parsers complete\n\n- **Phase 1**: 3-5 days (language filtering & display)\n- **Phase 2**: 7-10 days (cross-language commands)  \n- **Phase 3**: 2-3 days (MCP enhancements)\n- **Testing & Polish**: 3-5 days\n\n### Dependencies\n**Critical**: Must complete first\n- Issue #464: TypeScript parser and symbol extraction\n- Issue #463: Python parser and symbol extraction\n\n**Optional**: Can develop in parallel  \n- Enhanced error handling for edge cases\n- Performance optimizations for large polyglot codebases\n\n### Risk Assessment\n**Low Risk**: Builds on proven architecture and patterns\n- Existing symbol extraction framework\n- Proven trigram and vector search\n- Established MCP integration patterns\n\n**High Reward**: Creates unique market positioning\n- First tool to provide cross-language intelligence\n- Addresses major pain point in polyglot development\n- Defensible competitive advantage\n\n## Success Metrics\n\n### Quantitative Targets\n- **Performance**: Cross-language queries < 50ms (vs. grep at 2-5 seconds)\n- **Coverage**: Support 4+ languages simultaneously  \n- **Accuracy**: 95%+ boundary detection accuracy\n- **Adoption**: 80%+ of multi-language repositories use these features\n\n### Qualitative Goals\n- **Developer Experience**: \"Finally understand my full stack dependencies\"\n- **Debugging Speed**: Reduce cross-language debugging time by 60%\n- **Refactoring Safety**: Prevent breaking changes across language boundaries\n- **Market Position**: Establish KotaDB as the definitive polyglot analysis tool\n\n## Future Vision\n\nThis enhancement establishes KotaDB's position as the **definitive codebase intelligence platform** for modern polyglot development. No other tool can answer questions like:\n\n- \"What TypeScript components will break if I change this Python API?\"\n- \"Are there any unused microservice endpoints?\"\n- \"How does data flow through my entire stack?\"\n- \"What are all the integration points in my system?\"\n\nThese capabilities become increasingly valuable as codebases grow and teams adopt more languages.\n\n---\n\n**Labels**: enhancement, multi-language, intelligence-pack, cross-language, competitive-advantage, high-value, effort-medium, killer-feature, codebase-intelligence\n**Dependencies**: #464, #463\n**Priority**: High (competitive advantage opportunity)","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/477/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/477/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/475","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/475/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/475/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/475/events","html_url":"https://github.com/kotadb/kota-db/issues/475","id":3369247277,"node_id":"I_kwDOPFZ-b87I0qIt","number":475,"title":"Feature Pack: Intelligence Commands for AI-Optimized Codebase Analysis","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9066998313,"node_id":"LA_kwDOPFZ-b88AAAACHG9qKQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/high-priority","name":"high-priority","color":"d73a4a","default":false,"description":"High priority issues that need immediate attention"},{"id":9118359037,"node_id":"LA_kwDOPFZ-b88AAAACH38d_Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-medium","name":"effort-medium","color":"fbca04","default":false,"description":"Medium effort (1-3 days)"},{"id":9124823878,"node_id":"LA_kwDOPFZ-b88AAAACH-HDRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/feature","name":"feature","color":"0075ca","default":false,"description":"Major new feature implementation"},{"id":9124823937,"node_id":"LA_kwDOPFZ-b88AAAACH-HDgQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/killer-feature","name":"killer-feature","color":"d73a4a","default":false,"description":"Unique features that differentiate KotaDB"},{"id":9183060638,"node_id":"LA_kwDOPFZ-b88AAAACI1ping","url":"https://api.github.com/repos/kotadb/kota-db/labels/codebase-intelligence","name":"codebase-intelligence","color":"6f42c1","default":false,"description":"Codebase intelligence platform features and direction"},{"id":9187707818,"node_id":"LA_kwDOPFZ-b88AAAACI6FLqg","url":"https://api.github.com/repos/kotadb/kota-db/labels/meta","name":"meta","color":"8B5CF6","default":false,"description":"Meta issues for strategic planning and architecture"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2025-08-30T15:51:11Z","updated_at":"2025-08-30T15:51:28Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Overview\n\nThis meta-issue proposes an \"Intelligence Pack\" - a collection of 5-6 new commands that transform KotaDB from a search tool into a comprehensive codebase intelligence platform. Each command requires 1-3 hours of implementation effort and leverages **existing data** from our symbol storage and relationships system.\n\nThese commands are specifically designed to provide **objective data** that AI assistants can interpret to answer complex codebase questions, dramatically expanding KotaDB's value proposition for AI-powered development workflows.\n\n## Key Design Principles\n\n- **Data-Only Output**: Commands provide raw facts, not interpretive analysis\n- **Zero New Parsing**: All use existing symbol storage and relationship data\n- **AI-Optimized**: Structured output perfect for LLM consumption\n- **Incremental Implementation**: Each command is independent and can ship individually\n- **High Impact**: Collectively transform the platform's intelligence capabilities\n\n## Proposed Commands\n\n### 1. `find-dead-code` - Unused Symbol Detection\n\n**Purpose**: Identify symbols with zero references (excluding entry points)\n\n**Example Output**:\n```json\n{\n  \"unreferenced_symbols\": [\n    {\n      \"symbol\": \"calculate_metrics\",\n      \"file\": \"src/analytics.rs\",\n      \"line\": 45,\n      \"symbol_type\": \"function\",\n      \"visibility\": \"private\"\n    },\n    {\n      \"symbol\": \"LegacyParser\",\n      \"file\": \"src/parsers/old.rs\", \n      \"line\": 12,\n      \"symbol_type\": \"struct\",\n      \"visibility\": \"public\"\n    }\n  ],\n  \"total_unreferenced\": 23,\n  \"total_symbols\": 1456\n}\n```\n\n**Implementation**: Query relationship storage for symbols with `references.len() == 0`, filter out known entry points (main, pub fn, exported symbols).\n\n**Effort**: 2-3 hours  \n**AI Value**: Enables automated code cleanup suggestions and technical debt identification\n\n### 2. `dependency-chain` - Complete Call Path Analysis\n\n**Purpose**: Show full dependency chains from any symbol to its ultimate dependencies\n\n**Example Output**:\n```json\n{\n  \"symbol\": \"FileStorage::write\",\n  \"dependency_chains\": [\n    {\n      \"path\": [\"FileStorage::write\", \"Page::serialize\", \"bincode::serialize\", \"std::io::Write\"],\n      \"depth\": 4\n    },\n    {\n      \"path\": [\"FileStorage::write\", \"WAL::append\", \"std::fs::OpenOptions\", \"std::io::Write\"],\n      \"depth\": 4\n    }\n  ],\n  \"max_depth\": 4,\n  \"unique_dependencies\": 12\n}\n```\n\n**Implementation**: Recursive traversal of relationship graph with cycle detection, building all paths from symbol to leaf nodes.\n\n**Effort**: 3 hours  \n**AI Value**: Impact analysis, refactoring safety assessment, architecture understanding\n\n### 3. `test-coverage-hints` - Test-Symbol Relationship Mapping\n\n**Purpose**: Identify which symbols are/aren't referenced from test files\n\n**Example Output**:\n```json\n{\n  \"coverage_analysis\": {\n    \"tested_symbols\": [\n      {\n        \"symbol\": \"FileStorage::new\",\n        \"referenced_by_tests\": [\"tests/storage_test.rs:45\", \"tests/integration_test.rs:123\"],\n        \"test_count\": 2\n      }\n    ],\n    \"untested_symbols\": [\n      {\n        \"symbol\": \"Config::validate\",\n        \"file\": \"src/config.rs\",\n        \"line\": 67,\n        \"visibility\": \"public\"\n      }\n    ]\n  },\n  \"coverage_summary\": {\n    \"total_symbols\": 234,\n    \"tested_symbols\": 189,\n    \"untested_symbols\": 45,\n    \"coverage_percentage\": 80.8\n  }\n}\n```\n\n**Implementation**: Filter relationships by test file patterns, cross-reference with symbol definitions.\n\n**Effort**: 2 hours  \n**AI Value**: Automated test gap identification, coverage improvement guidance\n\n### 4. `complexity-hotspots` - Codebase Complexity Metrics\n\n**Purpose**: Rank functions by line count, files by symbol density\n\n**Example Output**:\n```json\n{\n  \"function_complexity\": [\n    {\n      \"function\": \"process_document\",\n      \"file\": \"src/processor.rs\", \n      \"line_count\": 156,\n      \"symbol_references\": 23\n    },\n    {\n      \"function\": \"parse_query\",\n      \"file\": \"src/query.rs\",\n      \"line_count\": 89,\n      \"symbol_references\": 15  \n    }\n  ],\n  \"file_density\": [\n    {\n      \"file\": \"src/storage.rs\",\n      \"symbol_count\": 34,\n      \"lines_of_code\": 456,\n      \"symbols_per_100_lines\": 7.46\n    }\n  ]\n}\n```\n\n**Implementation**: Count symbols per file, estimate line ranges from symbol positions, sort and rank.\n\n**Effort**: 2 hours  \n**AI Value**: Refactoring prioritization, code review focus areas, maintainability assessment\n\n### 5. `api-surface` - Public Interface Analysis\n\n**Purpose**: Extract only public/exported symbols for API documentation\n\n**Example Output**:\n```json\n{\n  \"public_api\": [\n    {\n      \"symbol\": \"FileStorage\",\n      \"symbol_type\": \"struct\", \n      \"file\": \"src/storage.rs\",\n      \"line\": 45,\n      \"visibility\": \"pub\",\n      \"methods\": [\"new\", \"write\", \"read\", \"close\"]\n    },\n    {\n      \"symbol\": \"create_storage\",\n      \"symbol_type\": \"function\",\n      \"file\": \"src/lib.rs\", \n      \"line\": 123,\n      \"visibility\": \"pub\"\n    }\n  ],\n  \"api_summary\": {\n    \"public_structs\": 12,\n    \"public_functions\": 23,\n    \"public_traits\": 8,\n    \"total_public_symbols\": 43\n  }\n}\n```\n\n**Implementation**: Filter symbols by visibility markers (pub, pub(crate), exported), organize by type.\n\n**Effort**: 1-2 hours  \n**AI Value**: API documentation generation, breaking change analysis, public interface design\n\n### 6. `symbol-context` - Surrounding Symbol Analysis\n\n**Purpose**: Show symbols defined in the same file/module for context understanding\n\n**Example Output**:\n```json\n{\n  \"target_symbol\": \"FileStorage::write\",\n  \"file_context\": {\n    \"file\": \"src/storage.rs\",\n    \"all_symbols\": [\n      {\"symbol\": \"FileStorage\", \"line\": 12, \"type\": \"struct\"},\n      {\"symbol\": \"FileStorage::new\", \"line\": 23, \"type\": \"method\"},\n      {\"symbol\": \"FileStorage::write\", \"line\": 45, \"type\": \"method\"},  \n      {\"symbol\": \"FileStorage::read\", \"line\": 67, \"type\": \"method\"},\n      {\"symbol\": \"StorageError\", \"line\": 89, \"type\": \"enum\"}\n    ],\n    \"related_symbols\": 5,\n    \"symbol_types\": [\"struct\", \"method\", \"enum\"]\n  }\n}\n```\n\n**Implementation**: Group symbols by file path, return all symbols for files containing the target symbol.\n\n**Effort**: 1 hour  \n**AI Value**: Context-aware code understanding, related symbol discovery, module comprehension\n\n## Implementation Strategy\n\n### Phase 1: Core Commands (Week 1)\n- `find-dead-code` - Foundation for cleanup analysis\n- `api-surface` - Essential for interface documentation\n\n### Phase 2: Relationship Commands (Week 2) \n- `dependency-chain` - Complex but high-value analysis\n- `symbol-context` - Simple but essential for understanding\n\n### Phase 3: Quality Commands (Week 3)\n- `test-coverage-hints` - Development workflow integration\n- `complexity-hotspots` - Code quality insights\n\n### Technical Implementation Notes\n\n**Shared Infrastructure**:\n- All commands use existing `SymbolStorage` and relationship data\n- Implement shared filtering utilities (visibility, file patterns, symbol types)\n- Add JSON output formatting helper functions\n- Reuse existing symbol traversal patterns from `find-callers`\n\n**Performance Considerations**:\n- Commands operate on indexed data - expect sub-100ms response times\n- Dependency chain traversal needs cycle detection for safety\n- Consider caching for repeated complex traversals\n\n**Code Organization**:\n```rust\n// src/intelligence/\n//   mod.rs           - Common utilities and JSON formatting\n//   dead_code.rs     - find-dead-code implementation  \n//   dependencies.rs  - dependency-chain implementation\n//   coverage.rs      - test-coverage-hints implementation\n//   complexity.rs    - complexity-hotspots implementation\n//   api_surface.rs   - api-surface implementation\n//   context.rs       - symbol-context implementation\n```\n\n## Collective Impact\n\n### For AI Assistants\n- **Complete codebase understanding** from multiple analysis angles\n- **Objective data** for informed recommendations without interpretation bias\n- **Structured output** perfect for LLM processing and reasoning\n- **Comprehensive insights** that match human developer mental models\n\n### For Platform Value\n- Transforms KotaDB from \"search tool\" to \"intelligence platform\"\n- Provides unique competitive advantages over generic code search\n- Creates multiple user touchpoints and engagement opportunities\n- Establishes foundation for advanced AI-assisted development workflows\n\n### For Ecosystem Integration\n- Commands work seamlessly with existing MCP server\n- Output format compatible with existing toolchain integrations\n- Natural extension of current symbol tracking and relationship analysis\n- Sets foundation for future advanced intelligence features\n\n## Success Metrics\n\n- **Implementation Speed**: 6 commands delivered in 3 weeks (6-18 total hours)\n- **Data Accuracy**: Commands use battle-tested symbol storage and relationship data\n- **AI Integration**: Structured output immediately usable by AI assistants\n- **User Adoption**: Commands address real developer workflow pain points\n- **Platform Evolution**: Establishes KotaDB as comprehensive intelligence platform\n\nThis Intelligence Pack represents a strategic investment in transforming KotaDB's market position from a search tool to an essential AI development platform, with minimal implementation effort but maximum impact on user value and platform differentiation.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/475/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/475/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/466","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/466/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/466/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/466/events","html_url":"https://github.com/kotadb/kota-db/issues/466","id":3368691732,"node_id":"I_kwDOPFZ-b87IyigU","number":466,"title":"Feature: Auto-reindexing on GitHub Activity (commits, PRs, merges)","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9118359020,"node_id":"LA_kwDOPFZ-b88AAAACH38d7A","url":"https://api.github.com/repos/kotadb/kota-db/labels/git-integration","name":"git-integration","color":"0366d6","default":false,"description":"Git repository and version control features"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9124823878,"node_id":"LA_kwDOPFZ-b88AAAACH-HDRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/feature","name":"feature","color":"0075ca","default":false,"description":"Major new feature implementation"},{"id":9157121677,"node_id":"LA_kwDOPFZ-b88AAAACIc6WjQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/developer-experience","name":"developer-experience","color":"84b6eb","default":false,"description":"Features that improve developer productivity and workflow"},{"id":9195014214,"node_id":"LA_kwDOPFZ-b88AAAACJBDIRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/automation","name":"automation","color":"0e8a16","default":false,"description":"Automated processes and triggers"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-08-30T03:24:53Z","updated_at":"2025-08-30T03:24:53Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n\n**HIGH PRIORITY FOR SEPTEMBER 10, 2025 LAUNCH**\n\nImplement automatic reindexing triggered by Git and GitHub events to ensure KotaDB's codebase intelligence remains current without manual intervention. This feature will dramatically improve developer experience by providing always-up-to-date code analysis and relationships.\n\n## Requirements\n\n### Event Monitoring\nAuto-reindexing should trigger on these events:\n- **Local Git Events**: commits, branch switches, merges, rebases, pulls\n- **GitHub Events**: PR merges, direct pushes, force pushes, branch creation/deletion\n- **File System Events**: Direct file modifications in indexed directories\n\n### Implementation Approaches\n\n#### Local Git Hooks\n- Post-commit hook for local commits\n- Post-merge hook for merge operations\n- Post-checkout hook for branch switches\n- Post-receive hook for remote pushes (if applicable)\n\n#### GitHub Webhook Integration  \n- PR merge events\n- Push events to main branches\n- Branch creation/deletion events\n- Release creation events\n\n#### File System Watching\n- Monitor indexed directories for file changes\n- Debounce rapid changes to avoid excessive reindexing\n- Support for common ignore patterns (.gitignore, .kotaignore)\n\n### Performance Requirements\n- **Incremental Reindex**: <1 second for typical single-file commits\n- **Batch Processing**: Queue multiple rapid changes\n- **Large Merges**: Handle efficiently without blocking development workflow\n- **Memory Efficiency**: Minimal overhead when not actively reindexing\n\n### Configuration System\n```toml\n# kotadb-auto.toml\n[auto-reindex]\nenabled = true\ndebounce_ms = 2000\nmax_queue_size = 100\n\n[triggers]\nlocal_commits = true\nbranch_switches = true\npr_merges = true\ndirect_pushes = true\nfile_changes = false  # Optional for high-frequency projects\n\n[performance]\nmax_files_per_batch = 1000\nbackground_priority = \"low\"\nmax_concurrent_indexes = 2\n```\n\n## Implementation Plan\n\n### Phase 1: Git Hooks Integration\n- [ ] Implement post-commit hook installation\n- [ ] Create post-merge and post-checkout hooks\n- [ ] Add hook management CLI commands (`kotadb hooks install/uninstall`)\n- [ ] Handle hook conflicts with existing tooling\n\n### Phase 2: Incremental Indexing Engine\n- [ ] Implement file change detection and delta analysis\n- [ ] Create efficient incremental update algorithms\n- [ ] Add support for renamed/moved files\n- [ ] Handle deleted files and cleanup orphaned references\n\n### Phase 3: Event Queue System\n- [ ] Implement event batching and deduplication\n- [ ] Add configurable debouncing for rapid changes\n- [ ] Create background processing with priority queues\n- [ ] Add progress reporting and status monitoring\n\n### Phase 4: GitHub Webhook Integration\n- [ ] Implement webhook receiver endpoint\n- [ ] Add authentication and security validation\n- [ ] Support multiple repository configurations\n- [ ] Handle GitHub API rate limiting\n\n### Phase 5: File System Monitoring\n- [ ] Cross-platform file system watching\n- [ ] Ignore pattern support (.gitignore integration)\n- [ ] Efficient change detection for large directories\n- [ ] Handle symbolic links and junction points\n\n## Edge Cases & Challenges\n\n### Large Merge Handling\n- PRs with 1000+ changed files\n- Merge conflicts and resolution impact\n- Rebase operations affecting multiple commits\n- Force push scenarios requiring full re-analysis\n\n### Concurrent Access\n- Multiple developers working simultaneously\n- Parallel indexing operations\n- Lock-free data structures for high concurrency\n- Graceful degradation under load\n\n### Error Recovery\n- Network failures during GitHub webhook processing\n- Partial indexing failures and rollback\n- Git hook execution failures\n- Database corruption recovery\n\n## Success Criteria\n- [ ] Automatic reindexing triggers correctly for all supported events\n- [ ] Incremental updates complete in <1 second for single files\n- [ ] Large merges (100+ files) complete in <10 seconds\n- [ ] Zero data loss during concurrent operations\n- [ ] Hooks install/uninstall without conflicts\n- [ ] GitHub webhook integration handles rate limits gracefully\n- [ ] Configuration system allows fine-grained control\n- [ ] Background processing doesn't impact development workflow\n\n## User Experience Goals\n\n### Installation\n```bash\n# One-time setup\nkotadb auto-reindex enable\n\n# Installs hooks, configures webhooks, starts monitoring\n# Zero additional configuration required\n```\n\n### Status Monitoring\n```bash\n# Check auto-reindex status\nkotadb auto-reindex status\n# Output: Last reindex: 2 minutes ago (3 files updated)\n#         Queue: empty\n#         Next check: 30 seconds\n\n# View recent auto-reindex history\nkotadb auto-reindex history --limit 10\n```\n\n### Troubleshooting\n```bash\n# Force manual reindex if auto fails\nkotadb auto-reindex force\n\n# Disable temporarily for large operations\nkotadb auto-reindex pause\nkotadb auto-reindex resume\n```\n\n## Dependencies\n- Git hook system integration\n- File system watching libraries (notify, watchdog)\n- HTTP webhook server for GitHub events\n- Event queue and background processing system\n- Configuration management system\n\n## Risk Assessment\n- **Medium**: Git hook conflicts with existing development tools\n- **Medium**: File system watching performance on large repositories\n- **Low**: GitHub webhook reliability and rate limiting\n- **Low**: Incremental indexing algorithm correctness\n\n## Testing Strategy\n- Git workflow simulation (commits, merges, rebases)\n- GitHub webhook event replay testing\n- Large repository stress testing\n- Concurrent developer workflow simulation\n- Hook installation/uninstallation across platforms\n\nThis feature will transform KotaDB from a manual tool into an always-current codebase intelligence platform, essential for the seamless developer experience targeted for September 10, 2025 launch.\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/466/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/466/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/465","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/465/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/465/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/465/events","html_url":"https://github.com/kotadb/kota-db/issues/465","id":3368691466,"node_id":"I_kwDOPFZ-b87IyicK","number":465,"title":"[Follow-ups] MCP integration: packaging, auto-discovery, daemon","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9066998489,"node_id":"LA_kwDOPFZ-b88AAAACHG9q2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/mcp","name":"mcp","color":"0052cc","default":false,"description":"Model Context Protocol related"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9118359090,"node_id":"LA_kwDOPFZ-b88AAAACH38eMg","url":"https://api.github.com/repos/kotadb/kota-db/labels/llm-integration","name":"llm-integration","color":"d73a4a","default":false,"description":"LLM-specific features and interfaces"},{"id":9124823878,"node_id":"LA_kwDOPFZ-b88AAAACH-HDRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/feature","name":"feature","color":"0075ca","default":false,"description":"Major new feature implementation"},{"id":9136360593,"node_id":"LA_kwDOPFZ-b88AAAACIJHMkQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/integration","name":"integration","color":"1d76db","default":false,"description":"Integration issues between system components"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2025-08-30T03:24:17Z","updated_at":"2025-09-13T16:13:32Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n\n**CRITICAL PATH FOR SEPTEMBER 10, 2025 LAUNCH**\n\nImplement comprehensive Model Context Protocol (MCP) integration to enable seamless connection between KotaDB and Claude Code (claude.ai/code). This is essential for the September 10 launch as it provides the primary interface for AI assistants to access KotaDB's codebase intelligence capabilities.\n\n## Requirements\n\n### Core MCP Server Implementation\n- Full MCP server implementation exposing KotaDB functionality\n- WebSocket and HTTP/2 transport support\n- Auto-discovery of KotaDB instances in local directories\n- Background process management with daemon mode\n- Configuration via standard `mcp.json` format\n\n### Required MCP Tools\nThe MCP server must expose these essential tools:\n- **find-callers**: Find all references to functions, classes, methods\n- **search-symbols**: Pattern-based symbol search with wildcards\n- **analyze-impact**: Analyze change impact across codebase\n- **search-code**: Full-text search across indexed code\n- **index-status**: Check indexing status and statistics\n- **reindex**: Trigger incremental or full reindexing\n\n### One-Command Setup Goal\nTarget user experience:\n```bash\n# Global installation\nnpm install -g kotadb-mcp\n\n# Auto-configure for current project\nkotadb-mcp init\n\n# Starts automatically in background\n```\n\n### Auto-Discovery Features\n- Detect existing KotaDB instances in current directory and parent directories\n- Automatic database initialization if none exists\n- Smart configuration based on detected project type (Git repo, language mix)\n- Integration with existing `kotadb-mcp-dev.toml` configuration\n\n## Implementation Plan\n\n### Phase 1: MCP Server Core\n- [ ] Implement MCP protocol handlers (WebSocket/HTTP/2)\n- [ ] Create tool registration and dispatch system\n- [ ] Add process lifecycle management (start/stop/status)\n- [ ] Implement configuration loading from mcp.json\n\n### Phase 2: Tool Implementation\n- [ ] find-callers tool with symbol resolution\n- [ ] search-symbols tool with pattern matching\n- [ ] analyze-impact tool with dependency analysis\n- [ ] search-code tool with full-text search\n- [ ] index-status tool with database statistics\n- [ ] reindex tool with incremental/full options\n\n### Phase 3: Auto-Discovery System\n- [ ] Directory traversal for KotaDB instance detection\n- [ ] Project type detection (Git, language files, build configs)\n- [ ] Automatic database initialization workflow\n- [ ] Smart default configuration generation\n\n### Phase 4: Process Management\n- [ ] Background daemon implementation\n- [ ] Process monitoring and health checks\n- [ ] Automatic restart on crashes\n- [ ] Graceful shutdown handling\n\n### Phase 5: NPM Package & Distribution\n- [ ] NPM package creation and publishing\n- [ ] Cross-platform binary distribution\n- [ ] Installation scripts for global setup\n- [ ] Documentation and examples\n\n## MCP Tool Specifications\n\n### find-callers Tool\n```json\n{\n  \"name\": \"find-callers\",\n  \"description\": \"Find all references to a symbol across the codebase\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"symbol\": {\"type\": \"string\", \"description\": \"Symbol name to find callers for\"},\n      \"type\": {\"type\": \"string\", \"enum\": [\"function\", \"class\", \"method\", \"variable\"], \"description\": \"Type of symbol\"}\n    },\n    \"required\": [\"symbol\"]\n  }\n}\n```\n\n### search-symbols Tool\n```json\n{\n  \"name\": \"search-symbols\",\n  \"description\": \"Search for symbols using pattern matching\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"pattern\": {\"type\": \"string\", \"description\": \"Pattern to search for (supports wildcards)\"},\n      \"type\": {\"type\": \"string\", \"enum\": [\"all\", \"function\", \"class\", \"method\", \"variable\"], \"description\": \"Filter by symbol type\"},\n      \"limit\": {\"type\": \"number\", \"description\": \"Maximum number of results\"}\n    },\n    \"required\": [\"pattern\"]\n  }\n}\n```\n\n## Configuration Schema (mcp.json)\n```json\n{\n  \"servers\": {\n    \"kotadb\": {\n      \"command\": \"kotadb-mcp\",\n      \"args\": [\"--database\", \"./kota-db-data\"],\n      \"env\": {\n        \"LOG_LEVEL\": \"info\"\n      }\n    }\n  }\n}\n```\n\n## Success Criteria\n- [ ] MCP server successfully connects to Claude Code\n- [ ] All required tools function correctly through MCP\n- [ ] One-command setup works on Windows, macOS, Linux\n- [ ] Auto-discovery finds existing KotaDB instances reliably\n- [ ] Background process management is stable\n- [ ] NPM package installs and configures correctly\n- [ ] Performance: Tool responses under 100ms for typical queries\n- [ ] Integration tests with actual Claude Code workflows\n\n## Dependencies\n- MCP protocol implementation (WebSocket/HTTP/2)\n- KotaDB CLI integration for tool execution\n- NPM package infrastructure\n- Cross-platform process management\n- Configuration file handling\n\n## Risk Assessment\n- **Medium**: MCP protocol is relatively new, may have edge cases\n- **Medium**: Cross-platform process management complexity\n- **Low**: KotaDB CLI commands already exist and are stable\n- **Low**: NPM packaging and distribution is well-established\n\n## Testing Strategy\n- Unit tests for each MCP tool implementation\n- Integration tests with actual MCP client\n- End-to-end tests with Claude Code\n- Cross-platform installation and setup testing\n- Performance testing with large codebases\n\nThis feature is **essential** for the September 10, 2025 launch and represents the primary way AI assistants will interact with KotaDB's codebase intelligence capabilities. Without this integration, KotaDB cannot fulfill its core value proposition.\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/465/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/465/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/426","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/426/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/426/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/426/events","html_url":"https://github.com/kotadb/kota-db/issues/426","id":3366688715,"node_id":"I_kwDOPFZ-b87Iq5fL","number":426,"title":"[Split Personality] Complete transition to codebase intelligence platform","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504075,"node_id":"LA_kwDOPFZ-b88AAAACEQVxyw","url":"https://api.github.com/repos/kotadb/kota-db/labels/documentation","name":"documentation","color":"0075ca","default":true,"description":"Improvements or additions to documentation"},{"id":9118359026,"node_id":"LA_kwDOPFZ-b88AAAACH38d8g","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-large","name":"effort-large","color":"f85149","default":false,"description":"Large effort - more than 3 days"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9120926036,"node_id":"LA_kwDOPFZ-b88AAAACH6ZJVA","url":"https://api.github.com/repos/kotadb/kota-db/labels/architecture","name":"architecture","color":"1d76db","default":false,"description":"Architectural design and structural issues"},{"id":9157121677,"node_id":"LA_kwDOPFZ-b88AAAACIc6WjQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/developer-experience","name":"developer-experience","color":"84b6eb","default":false,"description":"Features that improve developer productivity and workflow"},{"id":9182337439,"node_id":"LA_kwDOPFZ-b88AAAACI09Znw","url":"https://api.github.com/repos/kotadb/kota-db/labels/technical-debt","name":"technical-debt","color":"fbca04","default":false,"description":"Technical debt that needs to be addressed"},{"id":9182337456,"node_id":"LA_kwDOPFZ-b88AAAACI09ZsA","url":"https://api.github.com/repos/kotadb/kota-db/labels/refactoring","name":"refactoring","color":"fef2c0","default":false,"description":"Code restructuring without feature changes"},{"id":9183060638,"node_id":"LA_kwDOPFZ-b88AAAACI1ping","url":"https://api.github.com/repos/kotadb/kota-db/labels/codebase-intelligence","name":"codebase-intelligence","color":"6f42c1","default":false,"description":"Codebase intelligence platform features and direction"},{"id":9187707818,"node_id":"LA_kwDOPFZ-b88AAAACI6FLqg","url":"https://api.github.com/repos/kotadb/kota-db/labels/meta","name":"meta","color":"8B5CF6","default":false,"description":"Meta issues for strategic planning and architecture"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-08-29T12:19:20Z","updated_at":"2025-08-29T12:19:20Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n\nKotaDB has transitioned from a document database to a codebase intelligence platform specifically designed to reduce LLM context usage by 70%. However, there are still remnants of the old document-focused architecture that create confusion and inconsistency throughout the codebase.\n\n## Work Completed Today\n\n- ✅ Updated `AGENT.md` to reflect codebase intelligence focus with 6-stage methodology\n- ✅ Updated `CLAUDE.md` to reflect new platform direction and GitHub communication protocols  \n- ✅ Removed outdated references to \"distributed human-AI cognition\"\n- ✅ Aligned core documentation with the vision from issues #401, #374, #425\n\n## Remaining Split Personality Issues\n\n### 1. Client Library Examples Still Document-Focused 📚\n- **Problem**: Python and TypeScript client examples still demonstrate document operations that were removed in PR #402\n- **Impact**: 16+ example files mislead developers about KotaDB's actual purpose\n- **Solution**: Update examples to showcase codebase intelligence features:\n  - Symbol extraction and relationship tracking\n  - Code search and pattern matching  \n  - Repository analysis workflows\n  - MCP integration patterns\n\n### 2. Tests Still Reference DocumentBuilder 🧪\n- **Problem**: Many test files still use `DocumentBuilder` and document-centric operations\n- **Impact**: Tests don't validate the actual use cases KotaDB is designed for\n- **Solution**: Refactor tests to use codebase analysis patterns:\n  - Repository ingestion tests\n  - Symbol extraction validation\n  - Code relationship queries\n  - Performance tests for codebase analysis\n\n### 3. Rust Examples Need Major Updates 🦀\n- **Problem**: `examples/file_storage_demo.rs` still demonstrates document storage patterns\n- **Impact**: New developers get confused about KotaDB's actual purpose\n- **Solution**: Replace with codebase intelligence examples:\n  - Repository analysis workflows\n  - Symbol extraction and querying\n  - Integration with development tools\n  - MCP server usage patterns\n\n### 4. Architecture Documentation Inconsistencies 📖\n- **Problem**: Some documentation may still reference document storage as the primary use case\n- **Impact**: Mixed messaging about platform purpose and capabilities\n- **Solution**: Comprehensive documentation audit and updates\n\n## Vision Alignment\n\nPer issues #401, #374, and #425, KotaDB should be positioned as:\n\n- 🎯 **A codebase intelligence platform** that helps AI understand code structure and relationships\n- ❌ **NOT a general document database** - this positioning has been deprecated\n- 🧠 **Focused on reducing LLM context usage** by providing smart code analysis and symbol extraction\n- 🤖 **Optimized for AI assistants** like Claude Code via MCP integration\n- 📊 **Performance-oriented** with sub-10ms query latency for code analysis operations\n\n## Success Criteria\n\n### Phase 1: Client Libraries\n- [ ] Update all Python client examples to demonstrate codebase intelligence\n- [ ] Update all TypeScript client examples to demonstrate codebase intelligence  \n- [ ] Remove or deprecate document-focused API examples\n- [ ] Add comprehensive codebase analysis examples\n\n### Phase 2: Testing Infrastructure\n- [ ] Refactor tests to focus on codebase analysis rather than document operations\n- [ ] Remove `DocumentBuilder` usage where not essential to core functionality\n- [ ] Add comprehensive tests for symbol extraction and relationship tracking\n- [ ] Update performance tests to validate codebase analysis scenarios\n\n### Phase 3: Examples and Documentation\n- [ ] Replace `examples/file_storage_demo.rs` with codebase intelligence demo\n- [ ] Update all README files to emphasize codebase intelligence platform positioning\n- [ ] Audit and update any remaining architecture documentation\n- [ ] Ensure all public-facing documentation aligns with the new vision\n\n### Phase 4: API Consistency\n- [ ] Review public APIs to ensure they emphasize codebase intelligence use cases\n- [ ] Update CLI help text and command descriptions\n- [ ] Ensure MCP server interfaces are properly documented as the primary integration method\n\n## Impact Assessment\n\n### Developer Experience\n- **Current**: Confusion about KotaDB's actual purpose and capabilities\n- **After Fix**: Clear understanding of codebase intelligence platform benefits\n- **Benefit**: Faster onboarding and more appropriate usage patterns\n\n### Platform Adoption\n- **Current**: Mixed messaging may discourage adoption by AI tool developers\n- **After Fix**: Clear value proposition for LLM context reduction and code intelligence\n- **Benefit**: Better market positioning and targeted adoption\n\n### Technical Debt\n- **Current**: Maintaining examples and tests for deprecated use cases\n- **After Fix**: Focused development on actual platform capabilities\n- **Benefit**: Reduced maintenance burden and clearer development direction\n\n## Related Issues\n\n- #401 - Vision and direction discussion\n- #374 - Platform positioning\n- #425 - Codebase intelligence focus\n- #398 - Architecture alignment\n- #399 - API consistency\n- #402 - Document operations removal (completed)\n\n## Implementation Notes\n\nThis is a comprehensive refactoring effort that touches multiple areas of the codebase. It should be approached systematically:\n\n1. **Start with client libraries** - highest impact on developer perception\n2. **Update tests** - ensures we're validating the right functionality  \n3. **Fix examples** - provides clear guidance for new users\n4. **Complete documentation audit** - ensures consistent messaging\n\nThe work can be broken down into smaller, focused issues if needed, but this meta-issue provides the complete picture of the transition requirements.\n\n## Labels Applied\n\n- `codebase-intelligence` - Core platform functionality\n- `architecture` - Architectural alignment work\n- `documentation` - Documentation updates required\n- `refactoring` - Code restructuring without feature changes  \n- `technical-debt` - Legacy code and concepts to address\n- `developer-experience` - Impact on developer onboarding and usage\n- `effort-large` - Comprehensive effort requiring multiple work sessions\n- `priority-high` - Important for platform clarity and adoption\n- `meta` - Strategic planning and platform direction","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/426/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/426/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/389","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/389/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/389/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/389/events","html_url":"https://github.com/kotadb/kota-db/issues/389","id":3363700959,"node_id":"I_kwDOPFZ-b87IfgDf","number":389,"title":"Refactor redundant file processing architecture in repository ingestion","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998567,"node_id":"LA_kwDOPFZ-b88AAAACHG9rJw","url":"https://api.github.com/repos/kotadb/kota-db/labels/performance","name":"performance","color":"fbca04","default":false,"description":"Performance related issues"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9118359026,"node_id":"LA_kwDOPFZ-b88AAAACH38d8g","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-large","name":"effort-large","color":"f85149","default":false,"description":"Large effort - more than 3 days"},{"id":9120926036,"node_id":"LA_kwDOPFZ-b88AAAACH6ZJVA","url":"https://api.github.com/repos/kotadb/kota-db/labels/architecture","name":"architecture","color":"1d76db","default":false,"description":"Architectural design and structural issues"},{"id":9182337439,"node_id":"LA_kwDOPFZ-b88AAAACI09Znw","url":"https://api.github.com/repos/kotadb/kota-db/labels/technical-debt","name":"technical-debt","color":"fbca04","default":false,"description":"Technical debt that needs to be addressed"},{"id":9182337456,"node_id":"LA_kwDOPFZ-b88AAAACI09ZsA","url":"https://api.github.com/repos/kotadb/kota-db/labels/refactoring","name":"refactoring","color":"fef2c0","default":false,"description":"Code restructuring without feature changes"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-08-28T15:07:20Z","updated_at":"2025-08-28T15:07:20Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Problem\n\nThe current repository ingestion architecture processes files through multiple separate phases, creating redundant operations and suboptimal resource utilization. This architectural pattern creates maintenance overhead and performance bottlenecks.\n\n## Current Architecture Issues\n\n### Multi-Phase Processing Problems\n1. **Symbol Extraction Phase**: Files are parsed and processed for symbol information\n2. **Relationship Extraction Phase**: Same files are re-processed for dependency relationships\n3. **Separate I/O Operations**: Each phase performs its own file system operations\n4. **Duplicate State Management**: Repository state and file listings are maintained separately\n\n### Architectural Debt\n- Tight coupling between ingestion phases\n- No clear separation of concerns between file processing stages\n- Limited reusability of parsed ASTs and file content\n- Inefficient resource utilization patterns\n\n## Impact Assessment\n\n**Performance**: Medium-High impact - Current architecture creates unnecessary I/O overhead and memory pressure\n\n**Maintainability**: High impact - Changes require modifications across multiple processing phases\n\n**Scalability**: High impact - Architecture doesn't scale well with repository size or complexity\n\n**Code Quality**: Medium impact - Duplication makes code harder to reason about and test\n\n## Architectural Vision\n\n### Target Architecture: Unified Processing Pipeline\n\n```rust\npub struct IngestionPipeline {\n    processors: Vec<Box<dyn FileProcessor>>,\n    coordinator: ProcessingCoordinator,\n    resource_manager: ResourceManager,\n}\n\ntrait FileProcessor {\n    async fn process(&self, context: &FileProcessingContext) -> ProcessingResult;\n    fn supports_file_type(&self, extension: &str) -> bool;\n    fn resource_requirements(&self) -> ResourceRequirements;\n}\n\nstruct FileProcessingContext {\n    path: PathBuf,\n    content: String,\n    ast: Option<tree_sitter::Tree>,\n    metadata: FileMetadata,\n}\n```\n\n### Benefits of Unified Architecture\n- **Single File Pass**: Each file read and parsed once\n- **Shared State**: ASTs and content shared between processors\n- **Resource Efficiency**: Centralized memory and I/O management\n- **Extensibility**: Easy to add new processing stages\n- **Testability**: Each processor can be tested in isolation\n\n## Suggested Implementation Phases\n\n### Phase 1: Extract Processing Interfaces\n- [ ] Define `FileProcessor` trait for pluggable processing\n- [ ] Create `ProcessingCoordinator` for orchestrating file processing\n- [ ] Establish `FileProcessingContext` for shared state\n\n### Phase 2: Implement Processor Modules\n- [ ] `SymbolProcessor` - Extract symbols from ASTs\n- [ ] `RelationshipProcessor` - Build dependency graphs\n- [ ] `MetadataProcessor` - Collect file metadata\n- [ ] `ValidationProcessor` - Validate processing results\n\n### Phase 3: Pipeline Integration\n- [ ] Implement unified ingestion pipeline\n- [ ] Add resource management and limits\n- [ ] Create processing progress tracking\n- [ ] Add error handling and recovery\n\n### Phase 4: Performance Optimization\n- [ ] Implement AST caching between processors\n- [ ] Add parallel processing capabilities  \n- [ ] Optimize memory usage patterns\n- [ ] Add performance metrics collection\n\n## Architecture Design Patterns\n\n### 1. Pipeline Pattern\n```rust\nimpl IngestionPipeline {\n    pub async fn process_repository(&self, repo_path: &Path) -> Result<IngestionResult> {\n        let files = self.discover_files(repo_path).await?;\n        \n        for file_batch in files.chunks(self.batch_size) {\n            let contexts = self.prepare_contexts(file_batch).await?;\n            \n            for processor in &self.processors {\n                processor.process_batch(&contexts).await?;\n            }\n            \n            self.coordinator.commit_batch(contexts).await?;\n        }\n        \n        Ok(self.coordinator.finalize().await?)\n    }\n}\n```\n\n### 2. Context Sharing Pattern\n```rust\nimpl FileProcessingContext {\n    pub fn ast(&mut self) -> Result<&tree_sitter::Tree> {\n        if self.ast.is_none() {\n            self.ast = Some(self.parse_content()?);\n        }\n        Ok(self.ast.as_ref().unwrap())\n    }\n    \n    pub fn lazy_load<T>(&mut self, key: &str, loader: impl FnOnce() -> T) -> &T {\n        // Lazy loading pattern for expensive computations\n    }\n}\n```\n\n### 3. Resource Management Pattern\n```rust\nstruct ResourceManager {\n    memory_limit: usize,\n    current_usage: AtomicUsize,\n    processing_semaphore: Semaphore,\n}\n\nimpl ResourceManager {\n    pub async fn acquire_processing_slot(&self) -> ProcessingGuard {\n        self.processing_semaphore.acquire().await\n    }\n    \n    pub fn check_memory_pressure(&self) -> Result<(), ResourceExhausted> {\n        // Memory pressure detection\n    }\n}\n```\n\n## Migration Strategy\n\n### Backward Compatibility\n- Keep existing API surface during transition\n- Implement new architecture behind feature flags\n- Gradual migration of processing logic\n\n### Testing Strategy\n- Unit tests for individual processors\n- Integration tests for pipeline orchestration\n- Performance benchmarks comparing old vs new architecture\n- Stress testing with large repositories\n\n## Success Metrics\n\n### Performance Targets\n- [ ] 40%+ reduction in file I/O operations\n- [ ] 25%+ reduction in memory usage during ingestion\n- [ ] 30%+ improvement in large repository processing time\n- [ ] Sub-linear memory growth with repository size\n\n### Code Quality Targets\n- [ ] Eliminate code duplication between ingestion phases\n- [ ] Achieve >90% test coverage for new architecture\n- [ ] Clear separation of concerns between processing stages\n- [ ] Pluggable architecture for future processors\n\n## Risk Mitigation\n\n### Implementation Risks\n- **Complexity**: Start with simple processors and gradually add features\n- **Performance Regression**: Comprehensive benchmarking throughout development\n- **Breaking Changes**: Maintain API compatibility during migration\n\n### Rollback Strategy\n- Feature flags for architecture switching\n- Comprehensive test suite for both architectures\n- Performance monitoring in production\n\n## Related Issues\n\nThis addresses the architectural foundation for issues #386 (duplicate file processing) and #387 (memory management) identified during code review of PR #385.\n\n## Priority Rationale\n\nMedium priority with large effort - This is foundational architectural work that will improve performance and maintainability, but requires significant development effort. Should be planned as a multi-sprint effort with careful coordination.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/389/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/389/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/388","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/388/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/388/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/388/events","html_url":"https://github.com/kotadb/kota-db/issues/388","id":3363698762,"node_id":"I_kwDOPFZ-b87IffhK","number":388,"title":"Address TOCTOU race conditions in file system operations","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9113577132,"node_id":"LA_kwDOPFZ-b88AAAACHzYmrA","url":"https://api.github.com/repos/kotadb/kota-db/labels/security","name":"security","color":"d73a4a","default":false,"description":"Security vulnerabilities and concerns"},{"id":9118155942,"node_id":"LA_kwDOPFZ-b88AAAACH3wEpg","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-low","name":"priority-low","color":"0e8a16","default":false,"description":"Low priority issues"},{"id":9182337439,"node_id":"LA_kwDOPFZ-b88AAAACI09Znw","url":"https://api.github.com/repos/kotadb/kota-db/labels/technical-debt","name":"technical-debt","color":"fbca04","default":false,"description":"Technical debt that needs to be addressed"},{"id":9186724604,"node_id":"LA_kwDOPFZ-b88AAAACI5JK_A","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-small","name":"effort-small","color":"c2e0c6","default":false,"description":"Small effort - less than 1 day"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-08-28T15:06:46Z","updated_at":"2025-08-28T15:06:46Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Problem\n\nThe current file processing implementation has theoretical Time-of-Check-Time-of-Use (TOCTOU) race conditions where file system state can change between checking file existence/metadata and actually reading the file.\n\n## Current Implementation Pattern\n\nThe typical pattern in our codebase:\n```rust\n// Check if file exists and get metadata\nif path.exists() && path.is_file() {\n    // Time gap - file system state can change here\n    let content = std::fs::read_to_string(path)?; // File might not exist anymore\n}\n```\n\n## Specific Locations\n\n### Repository Ingestion\n- File enumeration followed by individual file reads\n- Checking file extensions before reading content\n- Metadata checks before processing files\n\n### Index Operations  \n- Checking if index files exist before reading\n- Validating file permissions before operations\n\n## Risk Assessment\n\n**Impact**: Low - In practice, this is primarily a theoretical concern for our use cases\n\n**Likelihood**: Very Low - Files are typically static during ingestion operations\n\n**Security Impact**: Minimal - Could potentially cause application errors but unlikely to be exploitable\n\n## Real-World Scenarios\n\nThis could theoretically occur if:\n- Files are deleted between check and read operations\n- File permissions change during processing\n- Concurrent processes modify files during ingestion\n- Network file systems with high latency\n\n## Suggested Solutions\n\n### Option 1: Atomic Operations (Recommended)\nReplace check-then-use patterns with atomic operations that handle missing files gracefully:\n\n```rust\n// Instead of checking then reading\nmatch std::fs::read_to_string(path) {\n    Ok(content) => process_file(content),\n    Err(e) if e.kind() == io::ErrorKind::NotFound => {\n        // Handle missing file gracefully\n        warn!(\"File disappeared during processing: {}\", path.display());\n        continue;\n    }\n    Err(e) => return Err(e.into()),\n}\n```\n\n### Option 2: File Handle Pattern\nOpen files first, then operate on the handle:\n\n```rust\nlet file = std::fs::File::open(path)?;\nlet metadata = file.metadata()?;\nif metadata.is_file() {\n    let mut content = String::new();\n    file.read_to_string(&mut content)?;\n    process_file(content);\n}\n```\n\n### Option 3: Comprehensive Error Handling\nImprove error handling to gracefully handle race conditions:\n\n```rust\npub fn process_file_safe(path: &Path) -> anyhow::Result<ProcessResult> {\n    match std::fs::read_to_string(path) {\n        Ok(content) => Ok(ProcessResult::Success(process_content(content))),\n        Err(e) => match e.kind() {\n            io::ErrorKind::NotFound => Ok(ProcessResult::FileDisappeared),\n            io::ErrorKind::PermissionDenied => Ok(ProcessResult::AccessDenied),\n            _ => Err(e.into()),\n        }\n    }\n}\n```\n\n## Implementation Areas\n\n### Files to Review\n- `src/ingestion.rs` - Repository file processing\n- `src/file_storage.rs` - File storage operations  \n- `src/*_index.rs` - Index file operations\n- Any file enumeration and processing code\n\n### Patterns to Replace\n- `path.exists() && path.is_file()` followed by file operations\n- Metadata checks before file reads\n- Directory listing followed by individual file processing\n\n## Acceptance Criteria\n\n- [ ] All file operations use atomic patterns or proper error handling\n- [ ] No check-then-use patterns remain in critical code paths\n- [ ] File disappearance during processing is handled gracefully\n- [ ] Error messages distinguish between different failure modes\n- [ ] No functional regressions in file processing\n- [ ] Performance impact is negligible\n\n## Testing Strategy\n\n- Create tests that simulate file deletion during processing\n- Test permission changes during operations\n- Verify graceful handling of concurrent file system modifications\n\n## Priority Rationale\n\nLow priority - This is a theoretical security/reliability concern that is unlikely to manifest in our typical usage patterns. Can be addressed as part of general code quality improvements, but not urgent for functionality or security.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/388/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/388/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/366","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/366/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/366/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/366/events","html_url":"https://github.com/kotadb/kota-db/issues/366","id":3360999112,"node_id":"I_kwDOPFZ-b87IVMbI","number":366,"title":"Add comprehensive integration tests for HybridRelationshipEngine","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9066998984,"node_id":"LA_kwDOPFZ-b88AAAACHG9syA","url":"https://api.github.com/repos/kotadb/kota-db/labels/tests","name":"tests","color":"c2e0c6","default":false,"description":"Testing related"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9118359037,"node_id":"LA_kwDOPFZ-b88AAAACH38d_Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-medium","name":"effort-medium","color":"fbca04","default":false,"description":"Medium effort (1-3 days)"},{"id":9121238907,"node_id":"LA_kwDOPFZ-b88AAAACH6sPew","url":"https://api.github.com/repos/kotadb/kota-db/labels/tree-sitter-parsing","name":"tree-sitter-parsing","color":"0052cc","default":false,"description":"Tree-sitter parsing engine and AST generation"},{"id":9136360593,"node_id":"LA_kwDOPFZ-b88AAAACIJHMkQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/integration","name":"integration","color":"1d76db","default":false,"description":"Integration issues between system components"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2025-08-27T22:14:04Z","updated_at":"2025-08-27T22:14:12Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n\nIntegration tests for HybridRelationshipEngine were started but could not be completed due to API changes in dependency_extractor types. These tests are critical for validating the full binary symbols + dependency graph integration that was implemented in Phase 3 of the binary symbol optimization.\n\n## Background\n\nDuring the implementation of issue #358 (binary symbol optimization), integration tests were designed to validate the complete workflow of:\n1. Binary symbol extraction from code\n2. Dependency graph construction\n3. Symbol relationship queries\n4. Cross-reference validation\n\nThe test file structure was designed but needs adjustments to match current struct definitions in the dependency_extractor module.\n\n## Technical Details\n\n### File Affected\n- `tests/hybrid_relationship_engine_integration.rs` (currently removed from codebase)\n\n### Main API Changes Requiring Updates\n1. **DependencyEdge struct fields changed**:\n   - No longer has `confidence` field\n   - No longer has `location` field\n   - Structure simplified in current implementation\n\n2. **SymbolNode field changes**:\n   - Uses `qualified_name` instead of `name` field\n   - Field access patterns need updating throughout tests\n\n3. **Import requirements**:\n   - Need proper imports for `SymbolType` enum\n   - Need `PathBuf` import for path handling\n   - Module structure may have changed\n\n### Expected Test Coverage\nThe integration tests should validate:\n- [ ] Full pipeline from code parsing to symbol relationships\n- [ ] Cross-language symbol resolution (Rust, TypeScript, Python)\n- [ ] Dependency graph construction accuracy\n- [ ] Symbol lookup and relationship queries\n- [ ] Performance characteristics of integrated system\n- [ ] Error handling in multi-step pipeline\n\n### Test Structure Design\nThe tests should follow the established pattern:\n```rust\n#[tokio::test]\nasync fn test_full_symbol_relationship_pipeline() {\n    // 1. Setup test repository with known relationships\n    // 2. Run symbol extraction\n    // 3. Build dependency graph\n    // 4. Query relationships\n    // 5. Validate expected connections exist\n}\n```\n\n## Acceptance Criteria\n- [ ] Integration tests compile without errors\n- [ ] Tests validate full symbol + dependency workflow\n- [ ] Tests cover multiple programming languages\n- [ ] Tests include performance benchmarks\n- [ ] Tests validate graph construction accuracy\n- [ ] All tests pass consistently\n\n## Context\nThis is follow-up work from Phase 3 of issue #358 (binary symbol optimization). The core functionality is implemented and working, but comprehensive integration testing was deferred due to API evolution during development.\n\n## Priority\nMedium - Core functionality works, but comprehensive testing is needed for production confidence and regression prevention.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/366/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/366/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/359","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/359/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/359/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/359/events","html_url":"https://github.com/kotadb/kota-db/issues/359","id":3360089732,"node_id":"I_kwDOPFZ-b87IRuaE","number":359,"title":"Performance Validation: Comprehensive testing of complete hybrid solution (binary + relationships)","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998567,"node_id":"LA_kwDOPFZ-b88AAAACHG9rJw","url":"https://api.github.com/repos/kotadb/kota-db/labels/performance","name":"performance","color":"fbca04","default":false,"description":"Performance related issues"},{"id":9118359024,"node_id":"LA_kwDOPFZ-b88AAAACH38d8A","url":"https://api.github.com/repos/kotadb/kota-db/labels/validation","name":"validation","color":"c2e0c6","default":false,"description":"Validation and testing of features"},{"id":9118359037,"node_id":"LA_kwDOPFZ-b88AAAACH38d_Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-medium","name":"effort-medium","color":"fbca04","default":false,"description":"Medium effort (1-3 days)"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9157095354,"node_id":"LA_kwDOPFZ-b88AAAACIc4vug","url":"https://api.github.com/repos/kotadb/kota-db/labels/testing-needed","name":"testing-needed","color":"fbca04","default":false,"description":"Feature implemented but needs testing"},{"id":9167968383,"node_id":"LA_kwDOPFZ-b88AAAACInQYfw","url":"https://api.github.com/repos/kotadb/kota-db/labels/milestone","name":"milestone","color":"0e8a16","default":false,"description":"Milestone tracking and planning"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-08-27T16:43:23Z","updated_at":"2025-08-27T16:43:23Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n\nComprehensive performance validation to ensure the complete hybrid solution (binary symbol extraction + relationship building + query integration) achieves significant performance gains over the original legacy method while maintaining accuracy and reliability.\n\n## Background\n\nAfter Phases 2 and 3 implementation, we need to validate that:\n- Original problem: 2+ minute timeouts with legacy symbol extraction\n- Binary format alone: 5 seconds, 19,853 symbols, but 0 relationships  \n- **Target**: Complete hybrid solution maintains performance gains with full functionality\n\n## Validation Requirements\n\n### Performance Benchmarks\n- [ ] **Total Processing Time**: < 10 seconds (extraction + relationships)\n- [ ] **Query Response Time**: < 10ms for relationship queries\n- [ ] **Memory Usage**: < 2.5x raw codebase size\n- [ ] **Startup Time**: < 10 seconds for complete initialization\n- [ ] **Concurrent Performance**: > 1000 queries/second\n\n### Accuracy Validation\n- [ ] **Symbol Count**: Verify binary format extracts same symbol count as legacy\n- [ ] **Relationship Accuracy**: Compare relationship graphs between hybrid and legacy methods\n- [ ] **Query Results**: Ensure relationship queries return identical results\n- [ ] **Edge Cases**: Test complex inheritance hierarchies, generic types, macros\n- [ ] **Cross-Reference Validation**: Verify bidirectional relationships are consistent\n\n### Real-World Testing\n- [ ] **KotaDB Self-Analysis**: Test on KotaDB codebase itself (dogfooding)\n- [ ] **Large Codebases**: Test on codebases > 100k lines of code  \n- [ ] **Multiple Languages**: Validate performance across Rust, TypeScript, Python, etc.\n- [ ] **Complex Projects**: Test on projects with deep dependency graphs\n- [ ] **Memory-Constrained Environments**: Test on systems with limited RAM\n\n## Test Scenarios\n\n### Performance Regression Tests\n```bash\n# Baseline comparison with legacy method\njust test-perf --feature binary-symbols --baseline legacy\ncargo test --release --features bench performance_regression_test\njust db-bench --hybrid-mode\n```\n\n### Stress Testing\n- [ ] **Concurrent Users**: 100+ simultaneous relationship queries\n- [ ] **Large Repositories**: Repositories with 500k+ lines of code\n- [ ] **Memory Pressure**: Testing under low-memory conditions\n- [ ] **Network Latency**: MCP server performance under network conditions\n- [ ] **Long-Running Sessions**: 24+ hour stability testing\n\n### Integration Testing\n- [ ] **CLI Commands**: All relationship commands work correctly\n- [ ] **MCP Server**: All relationship endpoints perform well\n- [ ] **Client Libraries**: Python/TypeScript clients maintain performance\n- [ ] **Incremental Updates**: Performance of relationship updates on file changes\n- [ ] **Recovery Testing**: Performance after crash recovery scenarios\n\n## Success Criteria\n\n### Performance Targets\n- ✅ **Total time**: < 10 seconds (vs 2+ minute legacy timeouts)\n- ✅ **Query latency**: < 10ms average response time\n- ✅ **Memory efficiency**: < 2.5x raw data overhead  \n- ✅ **Throughput**: > 1000 relationship queries/second\n- ✅ **Concurrent users**: Support 100+ simultaneous users\n\n### Accuracy Requirements\n- ✅ **Zero regressions**: All existing relationship queries return same results\n- ✅ **Complete coverage**: No missing symbols or relationships vs legacy method\n- ✅ **Consistency**: Bidirectional relationships are properly maintained\n- ✅ **Edge case handling**: Complex language features work correctly\n\n### Reliability Standards\n- ✅ **Crash recovery**: Performance maintained after recovery\n- ✅ **Memory stability**: No memory leaks over extended sessions\n- ✅ **Error handling**: Graceful degradation under failure conditions\n- ✅ **Data integrity**: No corruption under concurrent access\n\n## Testing Infrastructure\n\n### Automated Benchmarks\n- [ ] Add performance regression tests to CI/CD pipeline\n- [ ] Implement automated performance monitoring\n- [ ] Create performance dashboards and alerting\n- [ ] Set up baseline performance tracking\n\n### Manual Testing Procedures\n- [ ] Create testing checklist for hybrid solution validation\n- [ ] Document performance testing procedures\n- [ ] Establish performance baseline measurements\n- [ ] Create rollback procedures if performance targets not met\n\n## Dependencies\n\n- Depends on Phase 2: Binary-to-Relationship Bridge (#357)  \n- Depends on Phase 3: Relationship Query Integration (#358)\n- Related to original issue #342 (Binary symbol format implementation)\n- Uses existing performance testing infrastructure\n\n## Deliverables\n\n- [ ] **Performance Report**: Comprehensive analysis of hybrid solution performance\n- [ ] **Benchmark Results**: Detailed comparison with legacy method\n- [ ] **Accuracy Validation**: Verification that relationship extraction is complete and correct\n- [ ] **Recommendations**: Any optimizations or improvements identified during testing\n- [ ] **Production Readiness**: Go/no-go decision for hybrid solution deployment\n\nThis validation phase is critical to ensure that the binary symbol format delivers on its promise of dramatically improved performance while maintaining KotaDB's core intelligence and accuracy.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/359/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/359/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/318","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/318/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/318/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/318/events","html_url":"https://github.com/kotadb/kota-db/issues/318","id":3352732717,"node_id":"I_kwDOPFZ-b87H1qQt","number":318,"title":"OpenAI embeddings integration needs testing framework improvements","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9066998489,"node_id":"LA_kwDOPFZ-b88AAAACHG9q2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/mcp","name":"mcp","color":"0052cc","default":false,"description":"Model Context Protocol related"},{"id":9157095231,"node_id":"LA_kwDOPFZ-b88AAAACIc4vPw","url":"https://api.github.com/repos/kotadb/kota-db/labels/embeddings","name":"embeddings","color":"0e8a16","default":false,"description":"Embedding generation and vector search functionality"},{"id":9157095354,"node_id":"LA_kwDOPFZ-b88AAAACIc4vug","url":"https://api.github.com/repos/kotadb/kota-db/labels/testing-needed","name":"testing-needed","color":"fbca04","default":false,"description":"Feature implemented but needs testing"},{"id":9167968420,"node_id":"LA_kwDOPFZ-b88AAAACInQYpA","url":"https://api.github.com/repos/kotadb/kota-db/labels/v1.0.0","name":"v1.0.0","color":"b60205","default":false,"description":"Version 1.0.0 release items"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-08-25T18:05:39Z","updated_at":"2025-08-25T18:05:39Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n\nDuring v1.0.0 dogfooding validation (issue #303), we attempted to test OpenAI embeddings integration with a real API key. While KotaDB has comprehensive OpenAI provider support built-in, the testing infrastructure needs improvements to properly validate this functionality.\n\n## What We Attempted\n\n- Tried to test OpenAI embeddings integration with real API key\n- Attempted to validate semantic search functionality with OpenAI text-embedding-3-small model\n- Investigated embedding configuration and provider selection\n\n## What We Found\n\n### ✅ Full OpenAI Support Exists\n- **Complete provider implementation**: `src/embeddings.rs` contains full OpenAI embeddings support\n- **Configuration structure**: Supports OpenAI via `models::openai_text_embedding_3_small()`  \n- **6 integration tests**: Comprehensive test suite exists in `tests/` directory\n- **Vector index**: HNSW implementation ready for OpenAI embeddings\n\n### ❌ Testing Infrastructure Gaps\n- **MCP server hardcoded**: Initialization expects local ONNX models only\n- **Ignored tests**: Integration tests marked with `#[ignore]` and require `KOTADB_ENABLE_EMBEDDING_TESTS=1`\n- **No direct CLI testing**: Missing `kotadb embeddings test` command for validation\n- **Configuration complexity**: No clear documentation for switching between providers\n\n## What's Blocking Testing\n\n1. **MCP Server Limitations**: \n   - Hardcoded to expect local ONNX models in `src/bin/mcp_server.rs`\n   - No dynamic provider selection based on configuration\n   \n2. **Test Environment**: \n   - Integration tests require environment variable setup\n   - No streamlined way to test with real API keys\n   \n3. **CLI Gap**: \n   - No direct command for embeddings functionality testing\n   - Difficult to validate embedding generation without full integration\n\n4. **Documentation**: \n   - Missing guide for configuring different embedding providers\n   - No clear instructions for running integration tests with real APIs\n\n## Required Improvements\n\n### High Priority\n- [ ] **Update MCP server**: Dynamic embedding provider selection based on config\n- [ ] **Add CLI command**: `kotadb embeddings test --provider openai` for direct testing\n- [ ] **Environment variable support**: `OPENAI_API_KEY` integration in embedding configs\n\n### Medium Priority  \n- [ ] **Documentation**: How to run integration tests with real API keys\n- [ ] **Test streamlining**: Remove `#[ignore]` from tests when environment is properly configured\n- [ ] **Provider validation**: Automatic provider availability checking\n\n### Nice to Have\n- [ ] **Provider benchmarking**: Compare performance across different embedding providers\n- [ ] **Fallback mechanisms**: Graceful degradation when preferred provider unavailable\n\n## Context\n\nThis issue was discovered during comprehensive v1.0.0 validation testing where we're dogfooding KotaDB on itself. The embedding functionality is production-ready but lacks proper testing infrastructure for validation.\n\n## Acceptance Criteria\n\n- [ ] Can run `kotadb embeddings test --provider openai` with API key\n- [ ] MCP server dynamically selects embedding provider from config  \n- [ ] Integration tests run without `#[ignore]` when properly configured\n- [ ] Clear documentation for embedding provider configuration\n- [ ] All existing embedding functionality continues to work\n\n## Related Issues\n\n- #303 - v1.0.0 dogfooding validation","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/318/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/318/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/303","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/303/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/303/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/303/events","html_url":"https://github.com/kotadb/kota-db/issues/303","id":3351932756,"node_id":"I_kwDOPFZ-b87Hym9U","number":303,"title":"🎯 v1.0.0 Release Milestone - Production Readiness Checklist","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9113577095,"node_id":"LA_kwDOPFZ-b88AAAACHzYmhw","url":"https://api.github.com/repos/kotadb/kota-db/labels/critical","name":"critical","color":"d73a4a","default":false,"description":"Critical issues requiring immediate attention"},{"id":9117715428,"node_id":"LA_kwDOPFZ-b88AAAACH3VL5A","url":"https://api.github.com/repos/kotadb/kota-db/labels/release","name":"release","color":"0e8a16","default":false,"description":"Release-related PRs and issues"},{"id":9167968383,"node_id":"LA_kwDOPFZ-b88AAAACInQYfw","url":"https://api.github.com/repos/kotadb/kota-db/labels/milestone","name":"milestone","color":"0e8a16","default":false,"description":"Milestone tracking and planning"},{"id":9167968420,"node_id":"LA_kwDOPFZ-b88AAAACInQYpA","url":"https://api.github.com/repos/kotadb/kota-db/labels/v1.0.0","name":"v1.0.0","color":"b60205","default":false,"description":"Version 1.0.0 release items"},{"id":9167968495,"node_id":"LA_kwDOPFZ-b88AAAACInQY7w","url":"https://api.github.com/repos/kotadb/kota-db/labels/production-readiness","name":"production-readiness","color":"d93f0b","default":false,"description":"Production deployment readiness items"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2025-08-25T13:45:56Z","updated_at":"2025-08-26T19:57:18Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"# 🎯 v1.0.0 Release Milestone - Production Readiness Checklist\n\nThis issue tracks all requirements that must be completed before KotaDB v1.0.0 can be released for production use. Each item must be verified and checked off by a team member with appropriate testing evidence.\n\n## 🏗️ Core Stability Requirements\n\n### Database Engine Stability\n- [ ] **WAL Recovery Testing**: Complete WAL corruption and recovery testing under various failure scenarios\n- [ ] **Concurrent Access**: Stress test with >1000 concurrent connections without data corruption\n- [ ] **Memory Safety**: Valgrind/sanitizer clean runs on all critical paths\n- [ ] **Page Storage**: Verify 4KB page-based storage handles edge cases (partial writes, disk full)\n- [ ] **Crash Recovery**: Database recovers correctly from crashes during write operations\n- [x] **Transaction Isolation**: ACID properties maintained under concurrent operations\n\n### Index System Robustness  \n- [ ] **Primary Index**: B+ tree maintains consistency under heavy concurrent updates\n- [ ] **Trigram Index**: Full-text search handles Unicode, special characters, and large documents\n- [ ] **Vector Index**: HNSW index maintains accuracy and performance with >100k vectors\n- [ ] **Index Consistency**: All indices stay synchronized during concurrent read/write operations\n- [ ] **Recovery**: Index rebuilding from storage works correctly after corruption\n\n### Type Safety & Validation\n- [ ] **Validated Types**: All `ValidatedPath`, `ValidatedDocumentId`, `ValidatedTimestamp` edge cases covered\n- [ ] **Input Sanitization**: Comprehensive testing against malicious inputs and injection attacks  \n- [ ] **Factory Functions**: All `create_*` functions handle error cases gracefully\n- [ ] **Contract Validation**: Runtime contract validation catches all documented pre/post conditions\n\n## ⚡ Performance Benchmarks (Must Meet Targets)\n\n### Query Performance Targets\n- [ ] **Document Retrieval**: <1ms average latency for single document retrieval\n- [ ] **Text Search**: <10ms average latency for trigram-based full-text search\n- [ ] **Graph Traversals**: <50ms average latency for relationship queries\n- [ ] **Semantic Search**: <100ms average latency for vector similarity queries\n- [ ] **Wildcard Queries**: <5ms average latency for primary index pattern matching\n\n### System Performance Targets  \n- [ ] **Memory Overhead**: <2.5x raw data size including all indices and caches\n- [ ] **Write Throughput**: >5,000 documents/second sustained write performance\n- [ ] **Concurrent Connections**: Handle >1,000 concurrent connections without degradation\n- [ ] **WAL Recovery**: <5 seconds recovery time for 1GB WAL file\n- [ ] **Cold Start**: <3 seconds from process start to ready for queries\n\n### Benchmark Validation\n- [ ] **Performance Regression Suite**: All benchmarks pass with <5% variance from baseline\n- [ ] **Load Testing**: System remains stable under 10x normal load for 24+ hours  \n- [ ] **Memory Leak Detection**: No memory leaks detected in 72-hour continuous operation\n- [ ] **Resource Usage**: CPU and memory usage within acceptable limits under load\n\n## 🔍 Cross-Codebase Validation (Critical for Production)\n\n**REQUIREMENT**: Test on minimum 5 diverse, real-world codebases beyond KotaDB itself\n\n### Large-Scale Codebases (>10k files)\n- [ ] **Linux Kernel**: Test repository ingestion and symbol extraction performance\n- [ ] **Chromium/WebKit**: Validate handling of large C++ codebase with complex dependencies\n- [ ] **React/Angular**: Test JavaScript/TypeScript parsing and relationship tracking\n- [ ] **TensorFlow**: Validate Python codebase analysis and performance at scale\n- [ ] **Rust Compiler**: Test self-analysis capabilities on large Rust codebase\n\n### Diverse Language Ecosystems\n- [ ] **Multi-language Repository**: Test repository with 5+ different programming languages\n- [ ] **Legacy Codebase**: Test on older codebase with deprecated patterns and syntax\n- [ ] **Microservices Architecture**: Test analysis of distributed system with multiple repos\n- [ ] **Scientific Computing**: Test Jupyter notebook and data science workflow integration\n- [ ] **Enterprise Codebase**: Validate on proprietary enterprise-scale application\n\n### Stress Testing Scenarios\n- [ ] **Repository Size**: Successfully ingest and index repository >50GB total size\n- [ ] **File Count**: Handle repository with >100k files without performance degradation  \n- [ ] **Symbol Density**: Process codebase with >1M symbols and maintain query performance\n- [ ] **Deep Nesting**: Handle deeply nested directory structures (>20 levels)\n- [ ] **Large Files**: Process individual source files >10MB without memory issues\n\n## 📚 Documentation & Developer Experience\n\n### User Documentation\n- [ ] **Installation Guide**: Complete installation instructions for all supported platforms\n- [ ] **Quick Start Tutorial**: 5-minute tutorial gets users to their first successful query\n- [ ] **API Documentation**: Complete API reference with examples for all endpoints\n- [ ] **Configuration Guide**: Comprehensive configuration options and tuning guidance\n- [ ] **Troubleshooting**: Common issues and solutions documented with examples\n\n### Developer Documentation  \n- [ ] **Architecture Overview**: High-level system architecture and component interactions\n- [ ] **Contributing Guide**: Clear guidelines for code contributions, testing, and reviews\n- [ ] **Development Setup**: Complete development environment setup instructions\n- [ ] **Performance Guide**: Performance optimization best practices and tuning\n- [ ] **Security Guide**: Security considerations and hardening recommendations\n\n### Code Quality Standards\n- [ ] **Code Coverage**: >90% test coverage across all critical components\n- [ ] **Documentation Coverage**: All public APIs documented with examples\n- [ ] **Linting Standards**: Zero clippy warnings with -D warnings configuration\n- [ ] **Format Consistency**: All code formatted with `just fmt` passing\n- [ ] **Example Code**: Working examples for all major use cases and integrations\n\n## 🔐 Security & Production Hardening  \n\n### Security Audit Requirements\n- [ ] **Input Validation**: Comprehensive input sanitization prevents injection attacks\n- [ ] **Path Traversal**: Directory traversal attacks prevented in file operations\n- [ ] **Resource Limits**: DOS protection via configurable resource limits and timeouts\n- [ ] **Dependency Audit**: All dependencies scanned for known vulnerabilities  \n- [ ] **Memory Safety**: Address sanitizer and fuzzing testing completed\n\n### Production Configuration\n- [ ] **Logging Standards**: Structured logging with appropriate levels and no sensitive data\n- [ ] **Monitoring Integration**: Metrics exported for Prometheus/observability systems\n- [ ] **Error Handling**: Graceful error handling prevents crashes and data corruption  \n- [ ] **Resource Management**: Proper cleanup of file handles, memory, and connections\n- [ ] **Configuration Validation**: Invalid configurations detected and reported clearly\n\n### Deployment Readiness\n- [ ] **Docker Images**: Official Docker images built and tested for production deployment\n- [ ] **Service Dependencies**: Clear documentation of all runtime dependencies\n- [ ] **Backup/Restore**: Data backup and restoration procedures documented and tested\n- [ ] **Upgrade Path**: Database migration and upgrade procedures validated\n- [ ] **Health Checks**: HTTP health check endpoints for load balancer integration\n\n## 🚀 Business & Commercial Readiness\n\n### Multi-Client Library Support\n- [ ] **Python Client**: Feature-complete Python client library with PyPI package\n- [ ] **TypeScript Client**: Feature-complete TypeScript client with npm package  \n- [ ] **Documentation**: All client libraries documented with usage examples\n- [ ] **Version Compatibility**: Client library versioning strategy and compatibility matrix\n- [ ] **Testing**: Integration tests between server and all client libraries\n\n### MCP Integration Excellence  \n- [ ] **MCP Server Stability**: MCP server handles all protocol edge cases correctly\n- [ ] **LLM Integration**: Validated integration with Claude, GPT-4, and other major LLMs\n- [ ] **Configuration Management**: MCP server configuration simple and well-documented\n- [ ] **Error Recovery**: Robust error handling and connection recovery for MCP clients\n- [ ] **Performance**: MCP operations meet latency requirements for interactive use\n\n### Platform & Distribution\n- [ ] **Cross-Platform**: Verified working on Linux, macOS, and Windows\n- [ ] **Package Management**: Official packages available for major package managers\n- [ ] **Binary Distribution**: Pre-built binaries available for all supported platforms  \n- [ ] **Container Registry**: Official container images in Docker Hub and GitHub Registry\n- [ ] **Version Management**: Clear semantic versioning and backward compatibility policy\n\n### Business Process Readiness\n- [ ] **Release Process**: Automated release pipeline tested and documented\n- [ ] **Support Channels**: Community support channels established and monitored\n- [ ] **Issue Triage**: Process for triaging and responding to user issues\n- [ ] **Roadmap Communication**: Public roadmap with clear feature planning\n- [ ] **License Clarity**: Open source license clearly documented and compatible\n\n## 📋 Pre-Release Checklist\n\n### Final Validation Steps  \n- [ ] **Integration Test Suite**: Complete integration test suite passes on all platforms\n- [ ] **Performance Baseline**: Performance benchmarks recorded for regression detection\n- [ ] **Security Scan**: Final security scan completed with no high/critical findings\n- [ ] **Documentation Review**: All documentation reviewed for accuracy and completeness  \n- [ ] **Dependency Updates**: All dependencies updated to latest stable versions\n\n### Release Preparation\n- [ ] **Changelog Complete**: CHANGELOG.md updated with all user-facing changes since last release\n- [ ] **Version Consistency**: Version numbers consistent across all components and documentation\n- [ ] **Release Notes**: Release notes drafted highlighting key features and breaking changes\n- [ ] **Migration Guide**: Breaking changes documented with clear migration instructions\n- [ ] **Announcement Ready**: Release announcement prepared for community channels\n\n---\n\n## Success Criteria\n\n**v1.0.0 will be released when:**\n1. ✅ ALL checklist items above are completed and verified\n2. ✅ Cross-codebase validation completed on minimum 5 diverse codebases  \n3. ✅ All performance targets met consistently across test environments\n4. ✅ Security audit completed with no unresolved high/critical findings\n5. ✅ Documentation complete and validated by external reviewers\n6. ✅ Production deployment successfully tested in staging environment\n\n## Timeline & Ownership\n\n**Target Release Date**: TBD (based on completion of all requirements)\n\n**Release Manager**: @jayminwest  \n**QA Lead**: TBD\n**Security Review**: TBD  \n**Documentation Lead**: TBD\n\n---\n\n**Next Steps**: Begin systematic completion of checklist items. Each completed item should include:\n- ✅ Completion verification by assignee\n- 📊 Supporting evidence (test results, benchmarks, etc.)  \n- 📝 Brief summary of validation performed\n- 🔗 Links to related issues, PRs, or documentation\n\nLet's ship a production-ready v1.0.0 that developers can trust with their most important codebases! 🚀","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/303/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/303/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/300","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/300/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/300/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/300/events","html_url":"https://github.com/kotadb/kota-db/issues/300","id":3347707826,"node_id":"I_kwDOPFZ-b87Hifey","number":300,"title":"Feature: Auto-update dogfooding data with git hooks/file watching","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9118359001,"node_id":"LA_kwDOPFZ-b88AAAACH38d2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/dogfooding","name":"dogfooding","color":"6f42c1","default":false,"description":"Self-analysis and validation features"},{"id":9118359020,"node_id":"LA_kwDOPFZ-b88AAAACH38d7A","url":"https://api.github.com/repos/kotadb/kota-db/labels/git-integration","name":"git-integration","color":"0366d6","default":false,"description":"Git repository and version control features"},{"id":9157121677,"node_id":"LA_kwDOPFZ-b88AAAACIc6WjQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/developer-experience","name":"developer-experience","color":"84b6eb","default":false,"description":"Features that improve developer productivity and workflow"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-08-23T07:08:44Z","updated_at":"2025-08-23T07:08:44Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Current Pain Point\n\nCurrently, developers working on KotaDB must manually run the `ingest-repo` command every time they want to update dogfooding data after making code changes. This creates several friction points:\n\n- Must remember to re-ingest after every significant change\n- Full re-ingestion takes time and blocks development workflow  \n- Easy to forget, leading to testing against stale data\n- Slows down the development/testing cycle\n- Reduces effectiveness of dogfooding for catching integration issues\n\n## Problem Impact\n\nUsers developing KotaDB need to constantly re-ingest to test latest changes, which is inefficient and creates barriers to effective dogfooding validation (as referenced in our codebase analysis practices).\n\n## Proposed Solution\n\nImplement automatic update mechanisms that keep dogfooding data synchronized with repository changes without manual intervention:\n\n### 1. File System Watcher\n- Use `notify` crate for real-time file system monitoring\n- Watch for changes in source code files (`.rs`, `.toml`, etc.)\n- Trigger incremental updates only for changed files\n- Debounce rapid changes to avoid excessive processing\n\n### 2. Git Hooks Integration\n- **post-commit hook**: Update data after each commit\n- **post-checkout hook**: Update when switching branches\n- **post-merge hook**: Update after merging branches\n- Hooks placed in `.git/hooks/` for automatic execution\n\n### 3. Incremental Processing\n- **Differential analysis**: Use `git2` library to identify changed files\n- **Selective ingestion**: Only process modified/added/deleted files\n- **Preserve existing data**: Don't re-process unchanged files\n- **Smart updates**: Handle file renames and moves efficiently\n\n### 4. Background Update Process\n- **Non-blocking**: Updates run in background without interrupting development\n- **Optional daemon mode**: systemd service (Linux) or launchd agent (macOS)\n- **Progress reporting**: Show update status when requested\n- **Error handling**: Graceful failure with logging and retry logic\n\n## Implementation Approaches\n\n### Phase 1: File Watcher Foundation\n```rust\n// Use notify crate for cross-platform file watching\nuse notify::{Watcher, RecursiveMode, watcher};\n\n// Watch specific file patterns relevant to ingestion\nlet paths_to_watch = [\"src/\", \"Cargo.toml\", \"*.md\"];\n```\n\n### Phase 2: Git Integration\n```rust\n// Use git2 for repository operations\nuse git2::{Repository, Diff, DiffOptions};\n\n// Detect changes since last ingestion\nlet repo = Repository::open(\".\")?;\nlet diff = repo.diff_tree_to_workdir(last_commit, None)?;\n```\n\n### Phase 3: Smart Incremental Updates\n- Track ingestion timestamps per file\n- Compare with file modification times\n- Build dependency graphs for cascading updates\n- Handle symbol extraction updates efficiently\n\n### Phase 4: Background Service\n- Optional always-on background process\n- Configuration via `kotadb-dev.toml`\n- Integration with existing development server (`just dev`)\n\n## Benefits\n\n### Developer Experience\n- **Seamless dogfooding**: Always testing against latest code\n- **Faster iteration**: No manual re-ingestion steps\n- **Better testing**: Catches integration issues immediately\n- **Reduced cognitive load**: One less thing to remember\n\n### Quality Assurance\n- **Consistent validation**: Every change is automatically validated\n- **Early issue detection**: Problems caught before commits\n- **Comprehensive coverage**: All changes are tested, not just remembered ones\n- **Reliable dogfooding**: Ensures our self-analysis features work continuously\n\n### Performance\n- **Incremental efficiency**: Only process changed files\n- **Background processing**: No development workflow interruption  \n- **Smart updates**: Avoid unnecessary work\n- **Resource optimization**: Minimal CPU/memory overhead\n\n## Configuration Options\n\n```toml\n# kotadb-dev.toml\n[auto_update]\nenabled = true\nwatch_paths = [\"src/\", \"tests/\", \"Cargo.toml\"]\ndebounce_ms = 500\nbackground_mode = false  # true for daemon mode\ngit_hooks = [\"post-commit\", \"post-checkout\", \"post-merge\"]\nincremental_only = true\n```\n\n## Success Criteria\n\n- [ ] File changes trigger automatic data updates within 5 seconds\n- [ ] Incremental updates are 10x faster than full re-ingestion\n- [ ] Zero manual intervention required during normal development\n- [ ] Background mode uses <5% CPU when active\n- [ ] Git hooks execute reliably across different git workflows\n- [ ] Integration with existing `just dev` command\n- [ ] Comprehensive error handling and logging\n- [ ] Cross-platform compatibility (Linux, macOS, Windows)\n\n## Related Issues\n\nThis feature directly supports the dogfooding validation approach mentioned in our development guidelines and will improve the effectiveness of self-analysis testing.\n\n🤖 Generated with [Claude Code](https://claude.ai/code)","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/300/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/300/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/298","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/298/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/298/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/298/events","html_url":"https://github.com/kotadb/kota-db/issues/298","id":3347688845,"node_id":"I_kwDOPFZ-b87Hia2N","number":298,"title":"Test local embedding functionality on high-spec systems","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9124823970,"node_id":"LA_kwDOPFZ-b88AAAACH-HDog","url":"https://api.github.com/repos/kotadb/kota-db/labels/blocked","name":"blocked","color":"d73a49","default":false,"description":"Blocked by external factors or other issues"},{"id":9157095231,"node_id":"LA_kwDOPFZ-b88AAAACIc4vPw","url":"https://api.github.com/repos/kotadb/kota-db/labels/embeddings","name":"embeddings","color":"0e8a16","default":false,"description":"Embedding generation and vector search functionality"},{"id":9157095291,"node_id":"LA_kwDOPFZ-b88AAAACIc4vew","url":"https://api.github.com/repos/kotadb/kota-db/labels/local-inference","name":"local-inference","color":"6f42c1","default":false,"description":"Local model inference and ONNX runtime"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2025-08-23T07:00:27Z","updated_at":"2025-08-23T07:03:14Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\nLocal embeddings are implemented but untested during dogfooding. The current system has excellent specs (Apple M2 Ultra with 192GB RAM) that are perfect for testing local embedding models, which would eliminate dependency on external APIs.\n\n## Background\n- Local embeddings are implemented via ONNX Runtime (feature: `embeddings-onnx`)\n- Multiple models supported: MiniLM-L6-v2, BGE-small, E5-small-v2, Nomic-embed-v2, BERT-base\n- System has excellent specs: Apple M2 Ultra with 192GB RAM - perfect for local models\n- During dogfooding, embeddings were not tested due to focus on symbol extraction and search issues\n- Local embeddings would eliminate dependency on external APIs and provide better privacy/performance\n\n## Action Items\n1. **Download a compatible ONNX model** (suggest MiniLM-L6-v2 for initial testing)\n2. **Configure local embedding provider** in the system configuration\n3. **Test vector index functionality** with real document corpus\n4. **Benchmark performance on M2 Ultra** - measure throughput and memory usage\n5. **Document setup process** for other users with similar high-spec systems\n\n## Expected Benefits\n- Eliminate external API dependencies for embeddings\n- Improved privacy by keeping all data local\n- Potentially better performance on high-spec systems\n- Cost reduction by avoiding API fees\n- Better control over embedding model choice\n\n## Test Plan\n- [ ] Enable `embeddings-onnx` feature\n- [ ] Download and configure MiniLM-L6-v2 model\n- [ ] Test vector index creation with sample documents\n- [ ] Test semantic search queries\n- [ ] Benchmark embedding generation speed\n- [ ] Compare results with external API embeddings\n- [ ] Document configuration and performance findings","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/298/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/298/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/228","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/228/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/228/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/228/events","html_url":"https://github.com/kotadb/kota-db/issues/228","id":3328408062,"node_id":"I_kwDOPFZ-b87GY3n-","number":228,"title":"Feature: Comprehensive integration test suite for LLM code intelligence features","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":9066998984,"node_id":"LA_kwDOPFZ-b88AAAACHG9syA","url":"https://api.github.com/repos/kotadb/kota-db/labels/tests","name":"tests","color":"c2e0c6","default":false,"description":"Testing related"},{"id":9118359024,"node_id":"LA_kwDOPFZ-b88AAAACH38d8A","url":"https://api.github.com/repos/kotadb/kota-db/labels/validation","name":"validation","color":"c2e0c6","default":false,"description":"Validation and testing of features"},{"id":9118359026,"node_id":"LA_kwDOPFZ-b88AAAACH38d8g","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-large","name":"effort-large","color":"f85149","default":false,"description":"Large effort - more than 3 days"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9118359090,"node_id":"LA_kwDOPFZ-b88AAAACH38eMg","url":"https://api.github.com/repos/kotadb/kota-db/labels/llm-integration","name":"llm-integration","color":"d73a4a","default":false,"description":"LLM-specific features and interfaces"},{"id":9118362867,"node_id":"LA_kwDOPFZ-b88AAAACH38s8w","url":"https://api.github.com/repos/kotadb/kota-db/labels/codebase-analysis","name":"codebase-analysis","color":"6f42c1","default":false,"description":"Codebase analysis and intelligence platform features"},{"id":9124793917,"node_id":"LA_kwDOPFZ-b88AAAACH-FOPQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/code-analysis","name":"code-analysis","color":"6f42c1","default":false,"description":"Code analysis features and functionality"},{"id":9124823878,"node_id":"LA_kwDOPFZ-b88AAAACH-HDRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/feature","name":"feature","color":"0075ca","default":false,"description":"Major new feature implementation"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2025-08-17T15:10:33Z","updated_at":"2025-08-19T16:42:27Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## 🚀 Feature Request\n\n### ⚠️ BLOCKED BY:\n- **MUST FIX FIRST**: Unicode crash (#220) - Can't test with real codebases\n- **MUST FIX FIRST**: Search reliability (#221, #222) - Can't validate features on broken search\n- **PREREQUISITE**: Issues #224, #226, #227 must be implemented first\n\n**This test suite should be built AFTER the blocking bugs are fixed and the new features are implemented.**\n\n### Description\nCreate a comprehensive integration test suite that validates KotaDB's effectiveness as an LLM code intelligence tool, going beyond unit tests to ensure the entire pipeline delivers value for machine consumption.\n\n### Problem Statement\nCurrent testing (issue #186) focuses on individual components, but we need to validate:\n- Does natural language → code understanding actually work?\n- Are search results genuinely useful for LLMs?\n- Do relationship queries provide actionable insights?\n- Is the output format optimal for machine parsing?\n\nWithout this validation, we can't prove KotaDB is better than grep for LLMs.\n\n### Proposed Test Suite Structure\n\n#### 1. Natural Language → Code Understanding Pipeline\n```rust\n#[test]\nfn test_natural_language_to_code_complete_pipeline() {\n    // Test: \"Find error handling in the storage module\"\n    let query = \"Find error handling in the storage module\";\n    let results = kotadb.query(query);\n    \n    assert!(results.includes_symbol(\"StorageError\"));\n    assert!(results.includes_pattern(\"Result<\"));\n    assert!(results.relevance_score > 0.8);\n    assert!(results.includes_context(\"callers\", \"error_recovery\"));\n}\n```\n\n#### 2. LLM Consumption Validation\nTest that outputs are actually useful for LLMs:\n```rust\n#[test]\nfn test_output_optimized_for_llm_context() {\n    let results = kotadb.search(\"complex query with many results\");\n    \n    // Verify token optimization\n    assert!(results.estimated_tokens() < 4000);\n    assert!(results.has_summary_for_large_resultset());\n    \n    // Verify structure for machine parsing\n    assert!(results.is_valid_json());\n    assert!(results.has_field(\"relevance\"));\n    assert!(results.has_field(\"context.related_symbols\"));\n    \n    // Verify ranking quality\n    assert!(results[0].relevance > results[1].relevance);\n}\n```\n\n#### 3. Relationship Query Accuracy\n```rust\n#[test]\nfn test_impact_analysis_accuracy() {\n    // Setup: Known codebase with documented dependencies\n    let codebase = load_test_codebase(\"sample_project\");\n    \n    // Test: What breaks if we change this function?\n    let impact = kotadb.query_impact(\"core::process_data\");\n    \n    // Verify finds all actual dependencies\n    assert_eq!(impact.direct_callers, vec![\"api::handler\", \"batch::processor\"]);\n    assert_eq!(impact.affected_tests, vec![\"test_process_data\", \"test_integration\"]);\n    assert!(impact.suggested_review_files.contains(\"api/handler.rs\"));\n}\n```\n\n#### 4. Pattern Recognition Validation\n```rust\n#[test]\nfn test_semantic_pattern_recognition() {\n    // Test multiple representations of the same concept\n    let error_patterns = kotadb.search_pattern(\"error_handling\");\n    \n    // Should find ALL these different error handling approaches\n    assert!(error_patterns.contains(\"Result<T, Error>\"));\n    assert!(error_patterns.contains(\"try { } catch\"));\n    assert!(error_patterns.contains(\".unwrap_or_else\"));\n    assert!(error_patterns.contains(\"match ... Err\"));\n    \n    // Should NOT include false positives\n    assert!(!error_patterns.contains(\"// This handles errors\")); // Just a comment\n}\n```\n\n#### 5. Dogfooding Meta-Test\nTest KotaDB on itself:\n```rust\n#[test]\nfn test_kotadb_can_understand_itself() {\n    // KotaDB should be able to analyze its own codebase\n    let kotadb_on_kotadb = KotaDB::ingest(\".\");\n    \n    // Can it find its own core components?\n    let storage = kotadb_on_kotadb.query(\"How does storage work?\");\n    assert!(storage.references(\"FileStorage\"));\n    assert!(storage.references(\"WAL\"));\n    \n    // Can it trace its own dependencies?\n    let deps = kotadb_on_kotadb.query_callers(\"FileStorage::insert\");\n    assert!(!deps.is_empty());\n    \n    // Can it identify its own patterns?\n    let patterns = kotadb_on_kotadb.search_pattern(\"error_handling\");\n    assert!(patterns.count() > 50); // KotaDB has lots of error handling\n}\n```\n\n#### 6. Performance Benchmarks for LLM Usage\n```rust\n#[bench]\nfn bench_typical_llm_queries() {\n    // Measure performance of common LLM query patterns\n    benchmark(\"simple function search\", || {\n        kotadb.query(\"find the main function\")\n    });\n    \n    benchmark(\"relationship query\", || {\n        kotadb.query_impact(\"core_function\")\n    });\n    \n    benchmark(\"pattern search\", || {\n        kotadb.search_pattern(\"api_endpoints\")\n    });\n    \n    // All should complete in <100ms for LLM responsiveness\n}\n```\n\n### Success Metrics\n- **Coverage**: Every LLM-facing feature has integration tests\n- **Realism**: Tests use actual code patterns from real projects\n- **Performance**: All queries complete within LLM-acceptable timeframes\n- **Accuracy**: Pattern recognition has >90% precision and recall\n- **Usefulness**: Output format validated as parseable and actionable\n\n### Implementation Requirements\n1. Create test codebase fixtures with known patterns and relationships\n2. Build test harness for natural language query validation\n3. Implement output format validators (JSON schema, token counting)\n4. Add performance benchmarking framework\n5. Create \"golden\" test cases from successful real-world queries\n\n### Why This Test Suite Matters\nThis isn't just about correctness - it's about proving KotaDB delivers on its value proposition:\n- **Validation**: Proves KotaDB > grep for LLM usage\n- **Regression Prevention**: Ensures features stay useful as code evolves\n- **Performance Guarantee**: Maintains responsiveness for interactive LLM usage\n- **Documentation**: Tests serve as examples of proper usage\n\n### Related Issues\n- **Blocked by**: #220, #221, #222 (must have working foundation)\n- **Tests features from**: #224, #226, #227 (LLM-specific features)\n- **Extends**: #186 (basic test suite)\n- **Validates**: #214 (continuous dogfooding)","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/228/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/228/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/227","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/227/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/227/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/227/events","html_url":"https://github.com/kotadb/kota-db/issues/227","id":3328406612,"node_id":"I_kwDOPFZ-b87GY3RU","number":227,"title":"Feature: AST-based code pattern detection and analysis","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9113577180,"node_id":"LA_kwDOPFZ-b88AAAACHzYm3A","url":"https://api.github.com/repos/kotadb/kota-db/labels/search","name":"search","color":"0e8a16","default":false,"description":"Search functionality related issues"},{"id":9124823878,"node_id":"LA_kwDOPFZ-b88AAAACH-HDRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/feature","name":"feature","color":"0075ca","default":false,"description":"Major new feature implementation"},{"id":9124830369,"node_id":"LA_kwDOPFZ-b88AAAACH-HcoQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/pattern-matching","name":"pattern-matching","color":"6f42c1","default":false,"description":"Pattern recognition and matching algorithms"},{"id":9124830394,"node_id":"LA_kwDOPFZ-b88AAAACH-Hcug","url":"https://api.github.com/repos/kotadb/kota-db/labels/semantic-analysis","name":"semantic-analysis","color":"0052cc","default":false,"description":"Semantic code analysis and understanding"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2025-08-17T15:08:55Z","updated_at":"2025-08-30T18:41:46Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## 🚀 Feature Request\n\n### ⚠️ BLOCKED BY:\n- **MUST FIX FIRST**: Unicode crash (#220) - Need to load real codebases\n- **MUST FIX FIRST**: Basic search reliability (#221, #222) - Foundation must work first\n\n**This feature requires working search infrastructure before implementation.**\n\n### Description\nEnable KotaDB to recognize and search for semantic code patterns, not just text matches. This transforms search from \"find this string\" to \"find code that does this.\"\n\n### Problem Statement\nLLMs often need to find code patterns that can't be expressed as simple text searches:\n- \"Find error handling\" - includes try/catch, Result<T>, Option<T>, .unwrap_or(), ? operator\n- \"Find state mutations\" - any code that modifies struct fields\n- \"Find API endpoints\" - route definitions across different frameworks\n- \"Find validation logic\" - patterns that check input constraints\n\nCurrent text search can't understand that `Result<T, E>` and `try { } catch` are both error handling patterns.\n\n### Proposed Pattern Recognition System\n\n#### 1. Pattern Categories\n```yaml\nerror_handling:\n  - rust: [\"Result<\", \"Option<\", \".unwrap()\", \"?\", \".expect(\", \"match.*Err\"]\n  - javascript: [\"try {\", \"catch (\", \".catch(\", \"throw new\", \"Promise.reject\"]\n  - python: [\"try:\", \"except:\", \"raise\", \"finally:\"]\n\nstate_mutation:\n  - rust: [\"&mut self\", \"self.\", \"mut \", \".set_\", \".update_\"]\n  - general: [\"setState\", \"UPDATE\", \"INSERT\", \"DELETE\"]\n\napi_endpoints:\n  - rust: [\"#[get(\", \"#[post(\", \"route(\", \"Router::\"]\n  - javascript: [\"app.get(\", \"app.post(\", \"router.\", \"@Get(\", \"@Post(\"]\n  - python: [\"@app.route\", \"@get(\", \"@post(\", \"def get_\", \"def post_\"]\n\nvalidation:\n  - patterns: [\".is_valid()\", \"validate_\", \"check_\", \"assert\", \"require(\"]\n  - conditions: [\"if.*len.*>\", \"if.*==\", \"match.*Some\"]\n```\n\n#### 2. Query Interface\n```bash\n# Find by pattern name\nkotadb search --pattern \"error_handling\"\nkotadb search --pattern \"api_endpoints\"\n\n# Combine patterns\nkotadb search --pattern \"validation AND state_mutation\"\n\n# Natural language to pattern mapping\nkotadb search \"find error handling\"  # Maps to error_handling pattern\nkotadb search \"where do we validate input\"  # Maps to validation pattern\n```\n\n#### 3. Smart Pattern Detection\nBeyond simple regex, understand context:\n- Recognize that `fn process() -> Result<Data, Error>` is error handling even without explicit error keywords\n- Identify that `impl From<CustomError> for ApiError` is error conversion\n- Understand that `#[derive(Validate)]` indicates validation logic\n- Detect patterns across multiple lines (function signature + body)\n\n#### 4. Output Format\n```json\n{\n  \"query\": \"error handling\",\n  \"patterns_matched\": [\"error_handling\", \"error_recovery\"],\n  \"results\": [\n    {\n      \"path\": \"src/storage.rs:45\",\n      \"pattern_type\": \"result_type\",\n      \"confidence\": 0.95,\n      \"context\": \"Function returns Result with custom error type\",\n      \"snippet\": \"pub fn insert(&mut self, doc: Document) -> Result<(), StorageError>\",\n      \"related_patterns\": [\"error_propagation\", \"custom_error_type\"]\n    },\n    {\n      \"path\": \"src/api.rs:102\",\n      \"pattern_type\": \"error_recovery\",\n      \"confidence\": 0.88,\n      \"context\": \"Retry logic with exponential backoff\",\n      \"snippet\": \"retry_with_backoff(|| storage.insert(doc))\",\n      \"related_patterns\": [\"retry_pattern\", \"resilience\"]\n    }\n  ],\n  \"statistics\": {\n    \"total_error_handlers\": 47,\n    \"error_types_found\": [\"StorageError\", \"ApiError\", \"ValidationError\"],\n    \"most_common_pattern\": \"result_type\"\n  }\n}\n```\n\n#### 5. Learning Patterns\n- Allow users to define custom patterns\n- Learn from corrections: \"This is/isn't error handling\"\n- Build pattern library specific to codebase conventions\n- Share patterns across projects\n\n### Implementation Approach\n1. Build pattern definition language (YAML/JSON based)\n2. Create pattern matching engine that goes beyond regex\n3. Implement context-aware matching using AST from tree-sitter\n4. Add pattern composition (AND, OR, NOT operations)\n5. Build pattern learning/customization system\n\n### Success Criteria\n- Can find all error handling in codebase regardless of implementation style\n- Identifies patterns that would require complex regex or multiple searches\n- Provides confidence scores for pattern matches\n- Reduces false positives through context understanding\n- Query time remains under 100ms for pattern searches\n\n### Why This Matters for LLMs\nLLMs think in concepts, not text strings:\n- \"Fix the error handling\" requires finding ALL error patterns\n- \"Add validation\" needs to understand existing validation approaches\n- \"Secure the API\" must identify all endpoint definitions\n- \"Improve performance\" needs to find bottleneck patterns\n\nThis feature makes KotaDB speak the same conceptual language as LLMs.\n\n### Technical Requirements\n- Leverage tree-sitter AST for accurate pattern matching\n- Support pattern definitions for multiple languages\n- Allow runtime pattern registration without recompilation\n- Cache pattern matching results for performance\n- Handle partial/broken code gracefully\n\n### Related Issues\n- **Blocked by**: #220, #221, #222 (need working search first)\n- **Builds on**: #181 (symbol extraction), #182 (code-specific search)\n- **Enhances**: #185 (natural language queries)\n- **Complements**: #226 (relationship queries)\n- **Validated by**: #214 (dogfooding)","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/227/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/227/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/226","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/226/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/226/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/226/events","html_url":"https://github.com/kotadb/kota-db/issues/226","id":3328405393,"node_id":"I_kwDOPFZ-b87GY2-R","number":226,"title":"Feature: Advanced relationship query capabilities","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9067343356,"node_id":"LA_kwDOPFZ-b88AAAACHHSt_A","url":"https://api.github.com/repos/kotadb/kota-db/labels/dependencies","name":"dependencies","color":"0366d6","default":false,"description":"Pull requests that update a dependency file"},{"id":9118359026,"node_id":"LA_kwDOPFZ-b88AAAACH38d8g","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-large","name":"effort-large","color":"f85149","default":false,"description":"Large effort - more than 3 days"},{"id":9118359063,"node_id":"LA_kwDOPFZ-b88AAAACH38eFw","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-high","name":"priority-high","color":"d93f0b","default":false,"description":"High priority issues"},{"id":9118359090,"node_id":"LA_kwDOPFZ-b88AAAACH38eMg","url":"https://api.github.com/repos/kotadb/kota-db/labels/llm-integration","name":"llm-integration","color":"d73a4a","default":false,"description":"LLM-specific features and interfaces"},{"id":9124823878,"node_id":"LA_kwDOPFZ-b88AAAACH-HDRg","url":"https://api.github.com/repos/kotadb/kota-db/labels/feature","name":"feature","color":"0075ca","default":false,"description":"Major new feature implementation"},{"id":9124823902,"node_id":"LA_kwDOPFZ-b88AAAACH-HDXg","url":"https://api.github.com/repos/kotadb/kota-db/labels/graph","name":"graph","color":"1d76db","default":false,"description":"Graph data structures and algorithms"},{"id":9124823937,"node_id":"LA_kwDOPFZ-b88AAAACH-HDgQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/killer-feature","name":"killer-feature","color":"d73a4a","default":false,"description":"Unique features that differentiate KotaDB"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2025-08-17T15:07:15Z","updated_at":"2025-08-30T18:42:00Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## 🚀 Feature Request\n\n### ⚠️ BLOCKED BY:\n- **MUST FIX FIRST**: Unicode crash (#220) - Can't load codebases to build dependency graphs\n- **MUST FIX FIRST**: Trigram search bugs (#221, #222) - Need reliable search first\n\n**Do not begin this feature until blockers are resolved.**\n\n### Description\nExpose the dependency mapping (#183) through a powerful query interface that allows LLMs to navigate code relationships - the killer feature that grep can never provide.\n\n### Problem Statement\nWe have built dependency mapping infrastructure (#183) but there's no way to query it! LLMs need to understand:\n- What calls this function?\n- What would break if I change this?\n- How does data flow through the system?\n- What's the call chain from A to B?\n\nThese relationship queries are impossible with text search but essential for code understanding.\n\n### Proposed Query Interface\n\n#### 1. Direct Relationship Queries\n```bash\n# What calls this function?\nkotadb query --callers \"FileStorage::insert\"\n\n# What does this function call?\nkotadb query --callees \"process_request\"\n\n# What would break if I change this?\nkotadb query --impact \"StorageError\"\n\n# Show the call chain\nkotadb query --call-chain \"main\" \"handle_error\"\n```\n\n#### 2. Natural Language Relationship Queries\nThe system should understand:\n- \"What calls the insert function?\"\n- \"Show me how data flows from the API to the database\"\n- \"What tests cover FileStorage?\"\n- \"Find all modifications to the User struct\"\n- \"What's the dependency tree for this module?\"\n\n#### 3. Output Format\n```json\n{\n  \"query_type\": \"callers\",\n  \"target\": \"FileStorage::insert\",\n  \"results\": {\n    \"direct_callers\": [\n      {\n        \"function\": \"create_document\",\n        \"path\": \"src/api/handlers.rs:45\",\n        \"context\": \"Called during document creation\"\n      },\n      {\n        \"function\": \"bulk_import\",\n        \"path\": \"src/import.rs:123\",\n        \"context\": \"Called in batch processing loop\"\n      }\n    ],\n    \"indirect_callers\": [\n      {\n        \"function\": \"main\",\n        \"call_path\": [\"main\", \"run_server\", \"handle_request\", \"create_document\", \"FileStorage::insert\"],\n        \"distance\": 4\n      }\n    ],\n    \"test_coverage\": [\n      \"tests/storage_test.rs::test_insert\"\n    ]\n  }\n}\n```\n\n#### 4. Complex Relationship Queries\n- **Circular dependencies**: \"Find circular dependencies in the codebase\"\n- **Unused code**: \"Find functions that are never called\"\n- **Hot paths**: \"Show the most frequently called functions\"\n- **Change impact**: \"What's affected if I rename this struct field?\"\n\n### Implementation Approach\n1. Build query parser for relationship commands\n2. Create graph traversal algorithms for different query types\n3. Implement natural language mapping to graph queries\n4. Add caching for expensive graph operations\n5. Provide both CLI and API interfaces\n\n### Success Criteria\n- LLMs can answer \"what would break?\" questions instantly\n- Call chain analysis replaces manual code tracing\n- Circular dependencies are detected automatically\n- Test coverage gaps are immediately visible\n- Query performance < 100ms for typical codebases\n\n### Why This Is The Killer Feature\n**This is what makes KotaDB fundamentally better than grep for LLMs:**\n- Grep can only find text patterns\n- KotaDB understands code relationships\n- This enables impact analysis, refactoring safety, and architectural understanding\n- No other tool provides this for LLM consumption\n\n### Technical Requirements\n- Dependency graph must be incrementally updated as code changes\n- Must handle incomplete or broken code gracefully\n- Should work across multiple languages (leveraging tree-sitter)\n- Graph queries must be efficient even for large codebases\n\n### Related Issues\n- **Blocked by**: #220, #221, #222 (must fix search first)\n- **Builds on**: #183 (dependency mapping infrastructure)\n- **Enhances**: #185 (natural language queries)\n- **Validated by**: #214 (continuous dogfooding)","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/226/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/226/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/223","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/223/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/223/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/223/events","html_url":"https://github.com/kotadb/kota-db/issues/223","id":3328399599,"node_id":"I_kwDOPFZ-b87GY1jv","number":223,"title":"feat(benchmarks): enhance code analysis performance benchmarks","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9066998567,"node_id":"LA_kwDOPFZ-b88AAAACHG9rJw","url":"https://api.github.com/repos/kotadb/kota-db/labels/performance","name":"performance","color":"fbca04","default":false,"description":"Performance related issues"},{"id":9066998984,"node_id":"LA_kwDOPFZ-b88AAAACHG9syA","url":"https://api.github.com/repos/kotadb/kota-db/labels/tests","name":"tests","color":"c2e0c6","default":false,"description":"Testing related"},{"id":9124793917,"node_id":"LA_kwDOPFZ-b88AAAACH-FOPQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/code-analysis","name":"code-analysis","color":"6f42c1","default":false,"description":"Code analysis features and functionality"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2025-08-17T14:59:32Z","updated_at":"2025-08-18T17:45:42Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n\nFollowing the comprehensive test suite implementation in PR #219 and addressing issue #186, we need to enhance our benchmarking capabilities for code analysis features. The current benchmarks provide basic measurements for parsing and dependency extraction, but we need more sophisticated performance monitoring to ensure optimal performance as the codebase scales.\n\n## Proposed Enhancements\n\n### 1. Granular Operation Benchmarks\n- **Symbol extraction timing**: Measure individual symbol type extraction (functions, structs, traits, etc.)\n- **AST parsing performance**: Benchmark Tree-sitter parsing for different language complexities\n- **Dependency graph construction**: Time the building of call graphs and dependency networks\n- **Index operations**: Separate benchmarks for symbol index updates vs. queries\n\n### 2. File Size and Complexity Scaling\n- **Small files** (< 100 lines): Baseline performance measurements\n- **Medium files** (100-1000 lines): Typical source file complexity\n- **Large files** (1000+ lines): Complex modules and generated code\n- **Nested complexity**: Deep inheritance hierarchies, complex generics\n- **Repository scale**: Benchmark on codebases of varying sizes (10, 100, 1000+ files)\n\n### 3. Memory Usage Profiling\n- **Peak memory consumption**: Track maximum memory usage during operations\n- **Memory efficiency**: Measure memory overhead vs. data size ratios\n- **Memory leak detection**: Long-running benchmark sessions to detect leaks\n- **Cache efficiency**: Memory usage patterns for symbol and dependency caches\n\n### 4. Baseline Performance Metrics\n- **Regression detection thresholds**: Establish performance baselines (±5% tolerance)\n- **CI integration**: Automated performance regression detection in GitHub Actions\n- **Historical tracking**: Store benchmark results to track performance trends\n- **Performance targets**: Define target metrics for each operation type\n\n### 5. Concurrent Operations at Scale\n- **Parallel file processing**: Benchmark concurrent analysis of multiple files\n- **Thread safety performance**: Measure overhead of concurrent index access\n- **Contention analysis**: Identify bottlenecks in high-concurrency scenarios\n- **Scalability limits**: Find breaking points for concurrent operations\n\n### 6. Index Rebuild Performance\n- **Full rebuild timing**: Complete symbol index reconstruction\n- **Incremental updates**: Performance of partial index updates\n- **Recovery operations**: Index rebuilding after corruption or errors\n- **Optimization strategies**: Compare different indexing approaches\n\n### 7. Query Complexity Benchmarks\n- **Simple symbol lookups**: Basic symbol resolution performance\n- **Complex dependency queries**: Multi-hop dependency resolution\n- **Cross-reference searches**: Finding all references to symbols\n- **Pattern matching queries**: Regex and wildcard symbol searches\n- **Semantic queries**: Natural language to code mapping performance\n\n## Implementation Details\n\n### Benchmark Structure\n```rust\n// Example benchmark categories\nmod benchmarks {\n    mod parsing {\n        // Tree-sitter parsing benchmarks\n        // AST construction timing\n    }\n    \n    mod symbols {\n        // Symbol extraction benchmarks\n        // Index update performance\n    }\n    \n    mod dependencies {\n        // Dependency graph construction\n        // Call graph analysis\n    }\n    \n    mod queries {\n        // Simple vs complex query performance\n        // Concurrent query handling\n    }\n    \n    mod memory {\n        // Memory usage profiling\n        // Cache efficiency measurements\n    }\n}\n```\n\n### Performance Targets\nBased on our current architecture, establish these baseline targets:\n- **Symbol extraction**: < 50ms per 1000 lines of code\n- **Dependency resolution**: < 100ms for typical file\n- **Index queries**: < 10ms for simple lookups\n- **Memory overhead**: < 2.5x raw file size\n- **Concurrent operations**: > 100 parallel file analyses\n\n### Integration Points\n- **CI/CD pipeline**: Add performance regression detection\n- **Development workflow**: Include benchmark results in PR reviews\n- **Monitoring**: Real-time performance tracking in production\n- **Documentation**: Performance characteristics documentation\n\n## Benefits\n\n1. **Proactive performance monitoring**: Catch regressions before they impact users\n2. **Optimization guidance**: Identify specific areas needing performance improvements\n3. **Scalability planning**: Understand performance characteristics at scale\n4. **Resource planning**: Better memory and CPU usage predictions\n5. **Quality assurance**: Ensure consistent performance across releases\n\n## Testing Strategy\n\nFollow our 6-stage risk reduction methodology:\n- **Stage 1**: TDD approach with benchmark tests first\n- **Stage 2**: Contract-first design for benchmark interfaces\n- **Stage 3**: Pure function benchmarks for isolated performance measurement\n- **Stage 4**: Comprehensive observability in benchmark execution\n- **Stage 5**: Adversarial testing with pathological inputs\n- **Stage 6**: Use validated benchmark component library\n\n## References\n\n- PR #219: Comprehensive test suite implementation\n- Issue #186: Original code analysis enhancement request\n- Current benchmarks: `benches/` directory\n- Performance targets: See architecture documentation\n\n## Acceptance Criteria\n\n- [ ] Granular benchmarks for all major code analysis operations\n- [ ] Scalability benchmarks across different file and repository sizes\n- [ ] Memory usage profiling integrated into benchmark suite\n- [ ] Baseline performance metrics established and documented\n- [ ] Concurrent operation benchmarks implemented\n- [ ] Index rebuild performance measurements\n- [ ] Query complexity benchmarks covering simple to complex scenarios\n- [ ] CI integration for automated performance regression detection\n- [ ] Documentation of performance characteristics and targets\n- [ ] Historical performance tracking system","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/223/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/223/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/214","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/214/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/214/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/214/events","html_url":"https://github.com/kotadb/kota-db/issues/214","id":3327702612,"node_id":"I_kwDOPFZ-b87GWLZU","number":214,"title":"Continuous Dogfooding: Validate new features on KotaDB codebase","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9118359001,"node_id":"LA_kwDOPFZ-b88AAAACH38d2Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/dogfooding","name":"dogfooding","color":"6f42c1","default":false,"description":"Self-analysis and validation features"},{"id":9118359024,"node_id":"LA_kwDOPFZ-b88AAAACH38d8A","url":"https://api.github.com/repos/kotadb/kota-db/labels/validation","name":"validation","color":"c2e0c6","default":false,"description":"Validation and testing of features"},{"id":9118362867,"node_id":"LA_kwDOPFZ-b88AAAACH38s8w","url":"https://api.github.com/repos/kotadb/kota-db/labels/codebase-analysis","name":"codebase-analysis","color":"6f42c1","default":false,"description":"Codebase analysis and intelligence platform features"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2025-08-16T22:16:00Z","updated_at":"2025-08-18T17:45:48Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Summary\n\nThis issue tracks ongoing dogfooding efforts to validate new KotaDB features using our own codebase. This builds on the successful initial dogfooding work (#104, #184) that identified and helped fix critical bugs in git ingestion and core functionality.\n\n## Background\n\nPrevious dogfooding efforts successfully:\n- Validated git ingestion pipeline (#104)\n- Discovered and fixed critical race conditions (#184) \n- Revealed integration issues missed by unit tests\n- Provided real-world complexity testing that improved robustness\n\nAs we continue developing new features, we need systematic dogfooding to ensure they work correctly on actual codebases before release.\n\n## Target Features for Validation\n\n### 1. Symbol Extraction Pipeline (#181)\n**Success Criteria:**\n- [ ] Successfully extracts all function/method definitions from KotaDB Rust code\n- [ ] Correctly identifies struct/enum definitions and their fields\n- [ ] Handles complex generic types and trait implementations\n- [ ] Extracts documentation comments and associates them with symbols\n- [ ] Performance: Completes symbol extraction in <30 seconds for full codebase\n\n### 2. Code-Specific Search Indices (#182)\n**Success Criteria:**\n- [ ] Enables search by symbol name (e.g., \"FileStorage\", \"create_file_storage\")\n- [ ] Supports fuzzy matching for partial symbol names\n- [ ] Allows filtering by symbol type (functions, structs, traits, etc.)\n- [ ] Integrates seamlessly with existing trigram index\n- [ ] Query performance: <5ms for symbol lookups\n\n### 3. Dependency Mapping (#183)\n**Success Criteria:**\n- [ ] Maps all internal module dependencies within KotaDB\n- [ ] Identifies external crate dependencies and their usage\n- [ ] Tracks function call relationships across modules\n- [ ] Generates accurate dependency graphs\n- [ ] Handles complex Rust ownership and borrowing patterns\n\n### 4. Natural Language Queries (#185)\n**Success Criteria:**\n- [ ] Accurately interprets queries like \"show me storage layer implementation\"\n- [ ] Handles questions about architecture: \"how does indexing work?\"\n- [ ] Finds relevant code for feature queries: \"where is error handling implemented?\"\n- [ ] Provides contextual results with code snippets\n- [ ] Response quality: Returns relevant results for 90%+ of architectural questions\n\n## Dogfooding Process\n\nFor each new feature:\n\n1. **Setup Test Environment**\n   ```bash\n   # Create temporary dogfooding config\n   cp kotadb-dev.toml kotadb-dogfood.toml\n   # Set data directory to data/dogfooding/ in config\n   ```\n\n2. **Execute Feature Testing**\n   ```bash\n   # Ingest KotaDB codebase\n   cargo run -- --config kotadb-dogfood.toml git-ingest .\n   \n   # Test new feature functionality\n   # (specific commands depend on feature being tested)\n   ```\n\n3. **Validation Checks**\n   - Verify feature works correctly on real complexity\n   - Test edge cases found in actual codebase\n   - Measure performance with realistic data volume\n   - Document any issues or limitations discovered\n\n4. **Cleanup**\n   ```bash\n   # Remove dogfooding artifacts (never commit these)\n   rm kotadb-dogfood.toml\n   rm -rf data/dogfooding/\n   ```\n\n## Continuous Validation\n\nThis issue should remain open and be updated as new features are developed. Each feature validation should:\n- Update the appropriate checklist above\n- Document findings in comments\n- Create separate issues for any bugs discovered\n- Include performance measurements\n\n## Definition of Done\n\n- [ ] All target features have been validated using KotaDB codebase\n- [ ] Performance benchmarks meet stated criteria\n- [ ] Integration issues identified and resolved\n- [ ] Documentation updated with real-world usage examples\n\n## Related Issues\n\n- #104 - Initial dogfooding implementation\n- #184 - Critical race condition found during dogfooding\n- #181 - Symbol extraction pipeline\n- #182 - Code-specific search indices  \n- #183 - Dependency mapping\n- #185 - Natural language queries","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/214/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/214/timeline","performed_via_github_app":null,"state_reason":null},{"url":"https://api.github.com/repos/kotadb/kota-db/issues/201","repository_url":"https://api.github.com/repos/kotadb/kota-db","labels_url":"https://api.github.com/repos/kotadb/kota-db/issues/201/labels{/name}","comments_url":"https://api.github.com/repos/kotadb/kota-db/issues/201/comments","events_url":"https://api.github.com/repos/kotadb/kota-db/issues/201/events","html_url":"https://github.com/kotadb/kota-db/issues/201","id":3327434434,"node_id":"I_kwDOPFZ-b87GVJ7C","number":201,"title":"Add resource monitoring and memory usage tracking to search validation","user":{"login":"jayminwest","id":28354219,"node_id":"MDQ6VXNlcjI4MzU0MjE5","avatar_url":"https://avatars.githubusercontent.com/u/28354219?v=4","gravatar_id":"","url":"https://api.github.com/users/jayminwest","html_url":"https://github.com/jayminwest","followers_url":"https://api.github.com/users/jayminwest/followers","following_url":"https://api.github.com/users/jayminwest/following{/other_user}","gists_url":"https://api.github.com/users/jayminwest/gists{/gist_id}","starred_url":"https://api.github.com/users/jayminwest/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jayminwest/subscriptions","organizations_url":"https://api.github.com/users/jayminwest/orgs","repos_url":"https://api.github.com/users/jayminwest/repos","events_url":"https://api.github.com/users/jayminwest/events{/privacy}","received_events_url":"https://api.github.com/users/jayminwest/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":8875504084,"node_id":"LA_kwDOPFZ-b88AAAACEQVx1A","url":"https://api.github.com/repos/kotadb/kota-db/labels/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"},{"id":9066998567,"node_id":"LA_kwDOPFZ-b88AAAACHG9rJw","url":"https://api.github.com/repos/kotadb/kota-db/labels/performance","name":"performance","color":"fbca04","default":false,"description":"Performance related issues"},{"id":9117255557,"node_id":"LA_kwDOPFZ-b88AAAACH25HhQ","url":"https://api.github.com/repos/kotadb/kota-db/labels/priority-medium","name":"priority-medium","color":"fbca04","default":false,"description":"Medium priority issues"},{"id":9118359024,"node_id":"LA_kwDOPFZ-b88AAAACH38d8A","url":"https://api.github.com/repos/kotadb/kota-db/labels/validation","name":"validation","color":"c2e0c6","default":false,"description":"Validation and testing of features"},{"id":9118359037,"node_id":"LA_kwDOPFZ-b88AAAACH38d_Q","url":"https://api.github.com/repos/kotadb/kota-db/labels/effort-medium","name":"effort-medium","color":"fbca04","default":false,"description":"Medium effort (1-3 days)"},{"id":9121095307,"node_id":"LA_kwDOPFZ-b88AAAACH6jeiw","url":"https://api.github.com/repos/kotadb/kota-db/labels/monitoring","name":"monitoring","color":"0052cc","default":false,"description":"System monitoring and observability features"},{"id":9121095451,"node_id":"LA_kwDOPFZ-b88AAAACH6jfGw","url":"https://api.github.com/repos/kotadb/kota-db/labels/memory-management","name":"memory-management","color":"0e8a16","default":false,"description":"Memory usage and resource management"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2025-08-16T16:40:35Z","updated_at":"2025-08-16T16:40:35Z","closed_at":null,"author_association":"COLLABORATOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"## Problem\n\nThe current validation system can consume significant memory with large datasets but has no monitoring or safeguards for resource usage.\n\n## Current State\n\n- Validation processes up to 10,000 documents with no memory monitoring\n- Large HashSet operations and search results can cause memory spikes\n- No rate limiting or environment-aware resource management\n- Missing visibility into resource consumption during validation operations\n\n## Proposed Solution\n\n- Add memory usage monitoring during validation operations\n- Implement environment-aware limits (e.g., different limits for containers vs bare metal)\n- Add progress reporting for long-running validations\n- Include memory usage in validation reports\n- Add configurable memory thresholds with graceful degradation\n- Integrate with existing tracing infrastructure for observability\n\n## Acceptance Criteria\n\n- [ ] Memory usage tracking during validation operations\n- [ ] Environment detection (container vs bare metal) for appropriate limits\n- [ ] Progress reporting for validations taking >5 seconds\n- [ ] Memory usage included in ValidationReport structure\n- [ ] Graceful degradation when memory limits are approached\n- [ ] Configuration options for memory thresholds\n- [ ] Integration with existing MeteredIndex wrapper for consistency\n- [ ] Documentation of recommended resource requirements\n- [ ] Unit tests for memory monitoring functionality\n- [ ] Integration tests with various dataset sizes\n\n## Implementation Notes\n\n- Consider using `sysinfo` crate for cross-platform memory monitoring\n- Leverage existing tracing spans for progress reporting\n- Ensure compatibility with Stage 6 component library patterns\n- Follow factory function patterns for wrapped validation components\n\n## Impact\n\n**Medium Priority** - Important for production deployments but not critical for basic functionality. This enhancement will improve system reliability and provide better visibility into resource usage patterns.","closed_by":null,"reactions":{"url":"https://api.github.com/repos/kotadb/kota-db/issues/201/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/kotadb/kota-db/issues/201/timeline","performed_via_github_app":null,"state_reason":null}]