# Supabase + Fly.io Architecture Guide

## Overview

KotaDB uses a clean separation of concerns between data storage and API processing:

- **Supabase**: All persistent data storage, authentication, and API key management
- **Fly.io**: Stateless API server for processing requests and business logic

## Architecture Diagram

```
┌─────────────────────────────────────────────────────────────┐
│                         Frontend                            │
│                    (React/Vue/Next.js)                      │
└──────────────┬──────────────────┬──────────────────────────┘
               │                  │
               │                  │ Direct queries for
               │                  │ public data & auth
               │                  │
               ▼                  ▼
    ┌──────────────────┐   ┌──────────────────┐
    │   Fly.io API     │   │    Supabase      │
    │  (Stateless)     │   │   (Database)     │
    │                  │   │                  │
    │ • Business Logic │   │ • User Data      │
    │ • Code Analysis  │◄──┤ • API Keys       │
    │ • Rate Limiting  │   │ • Documents      │
    │ • Processing     │   │ • Usage Metrics  │
    └──────────────────┘   └──────────────────┘
```

## Data Storage in Supabase

### Database Schema

```sql
-- API Keys table (managed by Supabase)
CREATE TABLE api_keys (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
    key_hash TEXT NOT NULL UNIQUE,
    name TEXT NOT NULL,
    permissions JSONB DEFAULT '{"read": true, "write": false}'::jsonb,
    rate_limit INTEGER DEFAULT 60,
    monthly_quota INTEGER DEFAULT 1000000,
    usage_count INTEGER DEFAULT 0,
    last_used_at TIMESTAMPTZ,
    expires_at TIMESTAMPTZ,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Documents table
CREATE TABLE documents (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
    path TEXT NOT NULL,
    title TEXT,
    content TEXT NOT NULL,
    content_hash TEXT,
    tags TEXT[],
    metadata JSONB DEFAULT '{}'::jsonb,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(user_id, path)
);

-- Usage metrics table
CREATE TABLE usage_metrics (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    api_key_id UUID REFERENCES api_keys(id) ON DELETE CASCADE,
    endpoint TEXT NOT NULL,
    method TEXT NOT NULL,
    status_code INTEGER,
    response_time_ms INTEGER,
    tokens_used INTEGER DEFAULT 0,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Indexes for performance
CREATE INDEX idx_api_keys_user_id ON api_keys(user_id);
CREATE INDEX idx_api_keys_key_hash ON api_keys(key_hash);
CREATE INDEX idx_documents_user_path ON documents(user_id, path);
CREATE INDEX idx_usage_metrics_api_key ON usage_metrics(api_key_id, created_at);
```

### Repository & Job Tables

Hosted deployments store onboarding state, webhook activity, and indexing progress in Supabase. New tables introduced for the SaaS launch include:

```sql
CREATE TABLE repositories (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
    api_key_id UUID REFERENCES api_keys(id) ON DELETE SET NULL,
    name TEXT NOT NULL,
    git_url TEXT NOT NULL,
    provider TEXT DEFAULT 'github',
    status TEXT NOT NULL DEFAULT 'pending',
    sync_state TEXT NOT NULL DEFAULT 'pending',
    webhook_secret_hash TEXT,
    settings JSONB DEFAULT '{}'::jsonb,
    metadata JSONB DEFAULT '{}'::jsonb,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE indexing_jobs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    repository_id UUID REFERENCES repositories(id) ON DELETE CASCADE,
    requested_by UUID REFERENCES api_keys(id) ON DELETE SET NULL,
    job_type TEXT NOT NULL,
    status TEXT NOT NULL DEFAULT 'queued',
    priority INTEGER DEFAULT 0,
    payload JSONB DEFAULT '{}'::jsonb,
    queued_at TIMESTAMPTZ DEFAULT NOW(),
    started_at TIMESTAMPTZ,
    finished_at TIMESTAMPTZ,
    error_message TEXT
);

CREATE TABLE indexing_job_events (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    job_id UUID REFERENCES indexing_jobs(id) ON DELETE CASCADE,
    event_type TEXT NOT NULL,
    message TEXT,
    context JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE webhook_deliveries (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    repository_id UUID REFERENCES repositories(id) ON DELETE CASCADE,
    delivery_id TEXT,
    event_type TEXT,
    status TEXT NOT NULL DEFAULT 'received',
    received_at TIMESTAMPTZ DEFAULT NOW(),
    processed_at TIMESTAMPTZ,
    payload JSONB,
    error_message TEXT
);

CREATE TABLE token_usage (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_key_id UUID REFERENCES api_keys(id) ON DELETE CASCADE,
    repository_id UUID REFERENCES repositories(id) ON DELETE SET NULL,
    job_id UUID REFERENCES indexing_jobs(id) ON DELETE SET NULL,
    usage_type TEXT NOT NULL,
    tokens_used INTEGER NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW()
);
```

Row-Level Security (RLS) policies ensure that end users can only access repositories and jobs they own, while the server (running with the Supabase service role) can orchestrate background work. See `supabase/migrations/20250922_saas_repositories_jobs.sql` for the authoritative definitions, including indexes and helper views.

### Row Level Security (RLS) Policies

```sql
-- Enable RLS
ALTER TABLE api_keys ENABLE ROW LEVEL SECURITY;
ALTER TABLE documents ENABLE ROW LEVEL SECURITY;
ALTER TABLE usage_metrics ENABLE ROW LEVEL SECURITY;

-- API Keys policies
CREATE POLICY "Users can view their own API keys"
    ON api_keys FOR SELECT
    USING (auth.uid() = user_id);

CREATE POLICY "Users can create their own API keys"
    ON api_keys FOR INSERT
    WITH CHECK (auth.uid() = user_id);

CREATE POLICY "Users can update their own API keys"
    ON api_keys FOR UPDATE
    USING (auth.uid() = user_id);

CREATE POLICY "Users can delete their own API keys"
    ON api_keys FOR DELETE
    USING (auth.uid() = user_id);

-- Documents policies
CREATE POLICY "Users can view their own documents"
    ON documents FOR SELECT
    USING (auth.uid() = user_id);

CREATE POLICY "Users can create their own documents"
    ON documents FOR INSERT
    WITH CHECK (auth.uid() = user_id);

CREATE POLICY "Users can update their own documents"
    ON documents FOR UPDATE
    USING (auth.uid() = user_id);

CREATE POLICY "Users can delete their own documents"
    ON documents FOR DELETE
    USING (auth.uid() = user_id);

-- Usage metrics policies (read-only for users)
CREATE POLICY "Users can view metrics for their API keys"
    ON usage_metrics FOR SELECT
    USING (
        api_key_id IN (
            SELECT id FROM api_keys WHERE user_id = auth.uid()
        )
    );
```

## API Server on Fly.io

### Stateless Design Principles

1. **No Local Storage**: All data fetched from Supabase on each request
2. **JWT Validation**: Verify Supabase JWTs for authentication
3. **Connection Pooling**: Efficient database connections to Supabase
4. **In-Memory Caching**: Optional, with TTL for temporary performance boost
5. **Horizontal Scaling**: Can run multiple instances without coordination

### Environment Variables

```bash
# Required for Fly.io deployment
DATABASE_URL="postgresql://postgres.[PROJECT_REF]:[PASSWORD]@aws-0-[REGION].pooler.supabase.com:6543/postgres"
SUPABASE_URL="https://[PROJECT_REF].supabase.co"
SUPABASE_ANON_KEY="[YOUR_ANON_KEY]"
SUPABASE_SERVICE_KEY="[YOUR_SERVICE_KEY]"  # For admin operations only

# Optional performance tuning
DATABASE_POOL_SIZE="20"
DATABASE_MAX_CONNECTIONS="25"
CACHE_TTL_SECONDS="300"
```

### Migration Workflow

1. Spin up the local Supabase stack and recreate the database: `just supabase-reset`. This command targets only the Dockerised dev stack and reapplies everything under `supabase/migrations/` plus the seed file.
2. Make schema changes through the Supabase SQL editor or the CLI, then capture them with `just supabase-generate <short_name>` so they land in version-controlled SQL.
3. Commit the new migration file and run the reset command again to confirm it replays cleanly.
4. Deployments call `scripts/supabase-apply-remote.sh` (via `just supabase-apply`) against staging/production URLs before shipping the Fly.io release to keep the database in lockstep with the application. The helper shells out to `supabase db push`, so the CLI-managed migration history (`supabase_migrations.schema_migrations`) remains authoritative and only new migrations execute remotely.

## Frontend Integration

### Direct Supabase Access (Recommended for most operations)

```javascript
import { createClient } from '@supabase/supabase-js'

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY
)

// Fetch user's API keys directly
const { data: apiKeys } = await supabase
  .from('api_keys')
  .select('*')
  .order('created_at', { ascending: false })

// Create new API key
const { data: newKey } = await supabase
  .from('api_keys')
  .insert({
    name: 'Production API Key',
    permissions: { read: true, write: true },
    rate_limit: 100
  })
  .select()
  .single()
```

### KotaDB API Access (For code analysis features)

```javascript
// Use KotaDB API for code intelligence features
const response = await fetch('https://kotadb-api.fly.dev/api/v1/symbols/search', {
  headers: {
    'Authorization': `Bearer ${apiKey}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    pattern: 'FileStorage',
    limit: 50
  })
})
```

## API Key Management Flow

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant Supabase
    participant FlyAPI as Fly.io API

    User->>Frontend: Create API Key
    Frontend->>Supabase: Insert into api_keys table
    Supabase-->>Frontend: Return key details
    Frontend-->>User: Display API key (one-time)
    
    User->>Frontend: Make API request
    Frontend->>FlyAPI: Request with API key
    FlyAPI->>Supabase: Validate key & check limits
    Supabase-->>FlyAPI: Key valid, quotas OK
    FlyAPI->>FlyAPI: Process request
    FlyAPI->>Supabase: Log usage metrics
    FlyAPI-->>Frontend: Return response
    Frontend-->>User: Display results
```

## Benefits of This Architecture

### For Frontend Development
- **Direct Database Access**: Query Supabase directly for user data
- **Real-time Updates**: Use Supabase subscriptions for live data
- **Simplified Auth**: Supabase handles all authentication
- **Type Safety**: Generate TypeScript types from database schema

### For Backend Scalability
- **Stateless Servers**: Easy horizontal scaling on Fly.io
- **No Data Sync Issues**: Single source of truth in Supabase
- **Cost Effective**: Scale compute and storage independently
- **Global Distribution**: Deploy API servers in multiple regions

### For Security
- **RLS Policies**: Database-level security in Supabase
- **API Key Rotation**: Managed through Supabase
- **Audit Trails**: All changes tracked in database
- **Separation of Concerns**: API server can't access other users' data

## Storage Strategy

- **Source of Truth**: Persist all relational state—API keys, quotas, usage metrics, documents—in Supabase Postgres. This keeps data co-located with the frontend, enforces RLS once, and lets both the SaaS site and Fly API share a single schema.
- **Fly.io Volumes as Cache**: Mount a small volume per environment so the API server's on-disk indexes (`/data/storage`, `/data/primary`, `/data/trigram`) survive restarts. Treat these as rebuildable caches; Supabase still owns the canonical records.
- **Object Storage (Optional)**: Reach for Supabase Storage buckets only when you need to persist large binary artifacts across deploys. Today's flow sticks to the volume-backed cache, so buckets remain opt-in.

## Migration Checklist

- [ ] Set up Supabase project
- [ ] Run database migrations (create tables)
- [ ] Configure RLS policies
- [ ] Generate API keys for service account
- [ ] Update Fly.io secrets with Supabase credentials
- [ ] Test API key validation flow
- [ ] Verify rate limiting works
- [ ] Test usage metrics logging
- [ ] Update frontend to use Supabase directly

## Common Patterns

### 1. API Key Validation in Fly.io

```rust
async fn validate_api_key(
    key: &str,
    pool: &PgPool
) -> Result<ApiKeyInfo> {
    // Hash the provided key
    let key_hash = hash_api_key(key);
    
    // Query Supabase for the key
    let key_info = sqlx::query_as!(
        ApiKeyInfo,
        r#"
        SELECT id, user_id, permissions, rate_limit, monthly_quota, usage_count
        FROM api_keys
        WHERE key_hash = $1
          AND (expires_at IS NULL OR expires_at > NOW())
        "#,
        key_hash
    )
    .fetch_optional(pool)
    .await?
    .ok_or(Error::InvalidApiKey)?;
    
    // Update last_used_at
    sqlx::query!(
        "UPDATE api_keys SET last_used_at = NOW() WHERE id = $1",
        key_info.id
    )
    .execute(pool)
    .await?;
    
    Ok(key_info)
}
```

### 2. Rate Limiting Check

```rust
async fn check_rate_limit(
    api_key_id: Uuid,
    pool: &PgPool
) -> Result<bool> {
    let count = sqlx::query_scalar!(
        r#"
        SELECT COUNT(*)
        FROM usage_metrics
        WHERE api_key_id = $1
          AND created_at > NOW() - INTERVAL '1 minute'
        "#,
        api_key_id
    )
    .fetch_one(pool)
    .await?;
    
    Ok(count < rate_limit)
}
```

### 3. Usage Tracking

```rust
async fn track_usage(
    api_key_id: Uuid,
    endpoint: &str,
    response_time_ms: i32,
    pool: &PgPool
) -> Result<()> {
    sqlx::query!(
        r#"
        INSERT INTO usage_metrics (api_key_id, endpoint, method, status_code, response_time_ms)
        VALUES ($1, $2, $3, $4, $5)
        "#,
        api_key_id,
        endpoint,
        method,
        status_code,
        response_time_ms
    )
    .execute(pool)
    .await?;
    
    // Update usage count
    sqlx::query!(
        "UPDATE api_keys SET usage_count = usage_count + 1 WHERE id = $1",
        api_key_id
    )
    .execute(pool)
    .await?;
    
    Ok(())
}
```

### Webhook Orchestration

- Repository provisioning generates a per-repository webhook secret. The plaintext is returned once so deployments can configure the GitHub webhook signature and the hashed value is persisted in Supabase.
- GitHub events are delivered to `POST /webhooks/github/:repository_id`. The services layer verifies the `X-Hub-Signature-256` header, captures the payload in `webhook_deliveries`, and enqueues `incremental_update` jobs in the `indexing_jobs` table.
- Push events aggregate commit diffs (`added`/`modified`/`removed`) into the job payload so downstream workers (and future incremental indexing) can scope their work without refetching the webhook body.
- `SupabaseJobWorker` polls for queued jobs, clones the repository (respecting any branch overrides), runs the indexing pipeline, and marks the webhook delivery `queued → processing → processed/failed`.
- Public `/health` responses now expose Supabase connectivity (`supabase_status`, latency) and job queue depth so Fly smoke tests can assert the pipeline is healthy after a deploy.

## Troubleshooting

### Connection Issues
- Verify DATABASE_URL is using connection pooling endpoint
- Check Supabase project is not paused
- Ensure IP restrictions allow Fly.io connections

### Performance Issues
- Enable connection pooling in Supabase
- Increase DATABASE_POOL_SIZE on Fly.io
- Add database indexes for frequent queries
- Consider caching strategy for hot data

### API Key Issues
- Verify RLS policies are correctly configured
- Check key hasn't expired
- Ensure usage quotas haven't been exceeded
- Verify key hash is being calculated correctly
