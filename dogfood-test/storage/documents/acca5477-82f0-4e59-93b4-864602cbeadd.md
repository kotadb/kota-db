---
tags:
- file
- kota-db
- ext_rs
---
// BenchmarkService - Unified performance testing and benchmarking functionality
//
// This service extracts benchmarking, stress testing, and performance analysis logic from main.rs
// to provide consistent performance evaluation across all KotaDB interfaces.

use anyhow::Result;
use serde_json::{json, Value};
use std::collections::HashMap;
use std::path::PathBuf;
use std::time::{Duration, Instant};

use super::DatabaseAccess;

/// Configuration options for benchmarking operations
#[derive(Debug, Clone)]
pub struct BenchmarkOptions {
    pub operations: usize,
    pub benchmark_type: String,
    pub format: String,
    pub max_search_queries: usize,
    pub quiet: bool,
    pub warm_up_operations: Option<usize>,
    pub concurrent_operations: Option<usize>,
}

impl Default for BenchmarkOptions {
    fn default() -> Self {
        Self {
            operations: 10000,
            benchmark_type: "all".to_string(),
            format: "human".to_string(),
            max_search_queries: 100,
            quiet: false,
            warm_up_operations: Some(100),
            concurrent_operations: Some(1),
        }
    }
}

/// Configuration options for stress testing
#[derive(Debug, Clone)]
pub struct StressTestOptions {
    pub duration_seconds: u64,
    pub concurrent_operations: usize,
    pub operation_mix: OperationMix,
    pub memory_limit_mb: Option<u64>,
    pub target_throughput: Option<u64>,
    pub quiet: bool,
}

impl Default for StressTestOptions {
    fn default() -> Self {
        Self {
            duration_seconds: 60,
            concurrent_operations: 10,
            operation_mix: OperationMix::default(),
            memory_limit_mb: None,
            target_throughput: None,
            quiet: false,
        }
    }
}

/// Configuration for operation mix in stress tests
#[derive(Debug, Clone)]
pub struct OperationMix {
    pub read_percent: u8,
    pub write_percent: u8,
    pub search_percent: u8,
    pub analysis_percent: u8,
}

impl Default for OperationMix {
    fn default() -> Self {
        Self {
            read_percent: 40,
            write_percent: 20,
            search_percent: 30,
            analysis_percent: 10,
        }
    }
}

/// Configuration options for capacity planning
#[derive(Debug, Clone)]
pub struct CapacityPlanningOptions {
    pub current_data_size_mb: u64,
    pub projected_growth_percent: u64,
    pub time_horizon_months: u64,
    pub target_performance_ms: u64,
    pub quiet: bool,
}

impl Default for CapacityPlanningOptions {
    fn default() -> Self {
        Self {
            current_data_size_mb: 1000,
            projected_growth_percent: 100,
            time_horizon_months: 12,
            target_performance_ms: 10,
            quiet: false,
        }
    }
}

/// Benchmark results for a specific operation type
#[derive(Debug, Clone, serde::Serialize)]
pub struct BenchmarkTypeResult {
    pub operations: usize,
    pub total_time_ms: u64,
    pub average_time_ms: f64,
    pub median_time_ms: f64,
    pub p95_time_ms: f64,
    pub p99_time_ms: f64,
    pub operations_per_second: f64,
    pub success_rate: f64,
    pub errors: Vec<String>,
}

/// Overall benchmark results
#[derive(Debug, Clone, serde::Serialize)]
pub struct BenchmarkResult {
    pub operations_completed: usize,
    pub total_time_ms: u64,
    pub operations_per_second: f64,
    pub results_by_type: HashMap<String, BenchmarkTypeResult>,
    pub formatted_output: String,
    pub json_output: Option<Value>,
}

/// Stress test results
#[derive(Debug, Clone, serde::Serialize)]
pub struct StressTestResult {
    pub duration_ms: u64,
    pub total_operations: usize,
    pub operations_per_second: f64,
    pub concurrent_peak: usize,
    pub error_rate: f64,
    pub memory_usage_peak_mb: f64,
    pub latency_percentiles: LatencyPercentiles,
    pub operation_results: HashMap<String, BenchmarkTypeResult>,
    pub stability_score: f64,
    pub bottlenecks_identified: Vec<String>,
}

/// Latency percentile measurements
#[derive(Debug, Clone, serde::Serialize)]
pub struct LatencyPercentiles {
    pub p50_ms: f64,
    pub p90_ms: f64,
    pub p95_ms: f64,
    pub p99_ms: f64,
    pub p999_ms: f64,
}

/// Capacity planning recommendations
#[derive(Debug, Clone, serde::Serialize)]
pub struct CapacityPlanningResult {
    pub current_capacity: CapacityMetrics,
    pub projected_capacity: CapacityMetrics,
    pub recommendations: Vec<CapacityRecommendation>,
    pub resource_requirements: ResourceRequirements,
    pub scaling_thresholds: ScalingThresholds,
}

/// Current or projected capacity metrics
#[derive(Debug, Clone, serde::Serialize)]
pub struct CapacityMetrics {
    pub data_size_mb: u64,
    pub estimated_operations_per_second: u64,
    pub memory_requirement_mb: u64,
    pub storage_requirement_mb: u64,
    pub index_size_mb: u64,
}

/// Capacity planning recommendation
#[derive(Debug, Clone, serde::Serialize)]
pub struct CapacityRecommendation {
    pub category: String,
    pub priority: RecommendationPriority,
    pub description: String,
    pub estimated_impact: String,
    pub implementation_effort: ImplementationEffort,
}

/// Priority levels for recommendations
#[derive(Debug, Clone, serde::Serialize)]
pub enum RecommendationPriority {
    Low,
    Medium,
    High,
    Critical,
}

/// Implementation effort estimates
#[derive(Debug, Clone, serde::Serialize)]
pub enum ImplementationEffort {
    Minimal,
    Low,
    Medium,
    High,
    Extensive,
}

/// Resource requirements projection
#[derive(Debug, Clone, serde::Serialize)]
pub struct ResourceRequirements {
    pub cpu_cores: u32,
    pub memory_gb: u32,
    pub storage_gb: u32,
    pub network_bandwidth_mbps: u32,
    pub estimated_monthly_cost: f64,
}

/// Scaling thresholds and triggers
#[derive(Debug, Clone, serde::Serialize)]
pub struct ScalingThresholds {
    pub cpu_utilization_percent: u8,
    pub memory_utilization_percent: u8,
    pub storage_utilization_percent: u8,
    pub response_time_ms: u64,
    pub throughput_ops_per_second: u64,
}

/// Regression test results comparing against baseline
#[derive(Debug, Clone, serde::Serialize)]
pub struct RegressionTestResult {
    pub overall_regression: bool,
    pub baseline_version: String,
    pub current_version: String,
    pub performance_comparison: PerformanceComparison,
    pub regressions_found: Vec<RegressionIssue>,
    pub improvements_found: Vec<PerformanceImprovement>,
}

/// Performance comparison between versions
#[derive(Debug, Clone, serde::Serialize)]
pub struct PerformanceComparison {
    pub operation_comparisons: HashMap<String, OperationComparison>,
    pub overall_performance_change: f64, // Percentage change
    pub memory_usage_change: f64,
    pub throughput_change: f64,
}

/// Comparison for a specific operation
#[derive(Debug, Clone, serde::Serialize)]
pub struct OperationComparison {
    pub baseline_time_ms: f64,
    pub current_time_ms: f64,
    pub performance_change_percent: f64,
    pub regression_detected: bool,
    pub significance_level: f64,
}

/// Detected regression issue
#[derive(Debug, Clone, serde::Serialize)]
pub struct RegressionIssue {
    pub operation: String,
    pub severity: RegressionSeverity,
    pub performance_impact_percent: f64,
    pub description: String,
    pub suggested_investigation: String,
}

/// Severity levels for regressions
#[derive(Debug, Clone, serde::Serialize)]
pub enum RegressionSeverity {
    Minor,
    Moderate,
    Major,
    Critical,
}

/// Detected performance improvement
#[derive(Debug, Clone, serde::Serialize)]
pub struct PerformanceImprovement {
    pub operation: String,
    pub improvement_percent: f64,
    pub description: String,
}

/// BenchmarkService handles all performance testing, benchmarking, and capacity planning
#[allow(dead_code)]
pub struct BenchmarkService<'a> {
    database: &'a dyn DatabaseAccess,
    db_path: PathBuf,
}

impl<'a> BenchmarkService<'a> {
    /// Create a new BenchmarkService instance
    pub fn new(database: &'a dyn DatabaseAccess, db_path: PathBuf) -> Self {
        Self { database, db_path }
    }

    /// Run comprehensive benchmarks on database operations
    ///
    /// This method extracts the benchmarking logic from main.rs, providing
    /// consistent performance testing across all interfaces.
    pub async fn run_benchmark(&self, options: BenchmarkOptions) -> Result<BenchmarkResult> {
        let start_time = Instant::now();
        let mut results_by_type = HashMap::new();
        let mut formatted_output = String::new();

        if !options.quiet {
            formatted_output.push_str("\nüöÄ Running KotaDB Benchmarks\n");
            formatted_output.push_str(&format!("   Operations: {}\n", options.operations));
            formatted_output.push_str(&format!("   Type: {}\n", options.benchmark_type));
            formatted_output.push_str(&format!("   Format: {}\n", options.format));
            formatted_output.push('\n');
        }

        // Warm up if specified
        if let Some(warmup_ops) = options.warm_up_operations {
            if !options.quiet {
                formatted_output.push_str(&format!(
                    "üî• Warming up with {} operations...\n",
                    warmup_ops
                ));
            }
            self.run_warmup_operations(warmup_ops).await?;
        }

        // Run benchmarks based on type
        match options.benchmark_type.as_str() {
            "storage" => {
                let result = self.benchmark_storage_operations(&options).await?;
                results_by_type.insert("storage".to_string(), result);
            }
            "index" => {
                let result = self.benchmark_index_operations(&options).await?;
                results_by_type.insert("index".to_string(), result);
            }
            "query" => {
                let result = self.benchmark_query_operations(&options).await?;
                results_by_type.insert("query".to_string(), result);
            }
            "search" => {
                let result = self.benchmark_search_operations(&options).await?;
                results_by_type.insert("search".to_string(), result);
            }
            _ => {
                // Run all benchmark types
                let storage_result = self.benchmark_storage_operations(&options).await?;
                results_by_type.insert("storage".to_string(), storage_result);

                let index_result = self.benchmark_index_operations(&options).await?;
                results_by_type.insert("index".to_string(), index_result);

                let query_result = self.benchmark_query_operations(&options).await?;
                results_by_type.insert("query".to_string(), query_result);

                let search_result = self.benchmark_search_operations(&options).await?;
                results_by_type.insert("search".to_string(), search_result);
            }
        }

        // Calculate overall statistics
        let total_operations: usize = results_by_type.values().map(|r| r.operations).sum();
        let total_time_ms = start_time.elapsed().as_millis() as u64;
        let operations_per_second = if total_time_ms > 0 {
            (total_operations as f64 * 1000.0) / total_time_ms as f64
        } else {
            0.0
        };

        // Format output based on requested format
        match options.format.as_str() {
            "json" => {
                let json_output = self.format_benchmark_json(
                    &results_by_type,
                    total_operations,
                    total_time_ms,
                    operations_per_second,
                )?;
                formatted_output.push_str(&serde_json::to_string_pretty(&json_output)?);
            }
            "csv" => {
                formatted_output.push_str(&self.format_benchmark_csv(&results_by_type)?);
            }
            _ => {
                formatted_output.push_str(&self.format_benchmark_human(
                    &results_by_type,
                    total_operations,
                    total_time_ms,
                    operations_per_second,
                )?);
            }
        }

        let json_output = if options.format == "json" {
            Some(self.format_benchmark_json(
                &results_by_type,
                total_operations,
                total_time_ms,
                operations_per_second,
            )?)
        } else {
            None
        };

        Ok(BenchmarkResult {
            operations_completed: total_operations,
            total_time_ms,
            operations_per_second,
            results_by_type,
            formatted_output,
            json_output,
        })
    }

    /// Run stress test with concurrent operations
    pub async fn stress_test(&self, options: StressTestOptions) -> Result<StressTestResult> {
        let mut formatted_output = String::new();

        if !options.quiet {
            formatted_output.push_str(&format!(
                "üß™ Running stress test for {} seconds\n",
                options.duration_seconds
            ));
            formatted_output.push_str(&format!(
                "   Concurrent operations: {}\n",
                options.concurrent_operations
            ));
        }

        // TODO: Implement comprehensive stress testing
        // This would include:
        // - Concurrent operation execution
        // - Memory usage monitoring
        // - Error rate tracking
        // - Latency distribution analysis
        // - Bottleneck identification

        if !options.quiet {
            formatted_output
                .push_str("‚ö†Ô∏è  Comprehensive stress testing not yet fully implemented\n");
            formatted_output.push_str("   Use benchmark command for current performance testing\n");
        }

        Ok(StressTestResult {
            duration_ms: options.duration_seconds * 1000,
            total_operations: 0,
            operations_per_second: 0.0,
            concurrent_peak: options.concurrent_operations,
            error_rate: 0.0,
            memory_usage_peak_mb: 0.0,
            latency_percentiles: LatencyPercentiles {
                p50_ms: 0.0,
                p90_ms: 0.0,
                p95_ms: 0.0,
                p99_ms: 0.0,
                p999_ms: 0.0,
            },
            operation_results: HashMap::new(),
            stability_score: 0.0,
            bottlenecks_identified: Vec::new(),
        })
    }

    /// Run performance regression test against baseline
    pub async fn regression_test(
        &self,
        baseline_path: Option<PathBuf>,
    ) -> Result<RegressionTestResult> {
        // TODO: Implement regression testing
        // This would include:
        // - Load baseline performance data
        // - Run current benchmarks
        // - Compare results with statistical significance
        // - Identify regressions and improvements

        Ok(RegressionTestResult {
            overall_regression: false,
            baseline_version: "Not implemented".to_string(),
            current_version: "Not implemented".to_string(),
            performance_comparison: PerformanceComparison {
                operation_comparisons: HashMap::new(),
                overall_performance_change: 0.0,
                memory_usage_change: 0.0,
                throughput_change: 0.0,
            },
            regressions_found: Vec::new(),
            improvements_found: Vec::new(),
        })
    }

    /// Generate capacity planning recommendations
    pub async fn capacity_planning(
        &self,
        options: CapacityPlanningOptions,
    ) -> Result<CapacityPlanningResult> {
        // TODO: Implement capacity planning analysis
        // This would include:
        // - Current capacity assessment
        // - Growth projection modeling
        // - Resource requirement calculation
        // - Scaling threshold recommendations

        Ok(CapacityPlanningResult {
            current_capacity: CapacityMetrics {
                data_size_mb: options.current_data_size_mb,
                estimated_operations_per_second: 1000,
                memory_requirement_mb: 512,
                storage_requirement_mb: options.current_data_size_mb * 2,
                index_size_mb: options.current_data_size_mb / 4,
            },
            projected_capacity: CapacityMetrics {
                data_size_mb: options.current_data_size_mb
                    * (100 + options.projected_growth_percent)
                    / 100,
                estimated_operations_per_second: 2000,
                memory_requirement_mb: 1024,
                storage_requirement_mb: options.current_data_size_mb * 4,
                index_size_mb: options.current_data_size_mb / 2,
            },
            recommendations: Vec::new(),
            resource_requirements: ResourceRequirements {
                cpu_cores: 4,
                memory_gb: 8,
                storage_gb: (options.current_data_size_mb * 4 / 1024) as u32,
                network_bandwidth_mbps: 100,
                estimated_monthly_cost: 150.0,
            },
            scaling_thresholds: ScalingThresholds {
                cpu_utilization_percent: 70,
                memory_utilization_percent: 80,
                storage_utilization_percent: 85,
                response_time_ms: options.target_performance_ms,
                throughput_ops_per_second: 1500,
            },
        })
    }

    // Private implementation methods

    async fn run_warmup_operations(&self, warmup_ops: usize) -> Result<()> {
        // TODO: Implement warmup operations to stabilize performance
        Ok(())
    }

    async fn benchmark_storage_operations(
        &self,
        options: &BenchmarkOptions,
    ) -> Result<BenchmarkTypeResult> {
        let mut timings = Vec::new();
        let errors = Vec::new();
        let start_time = Instant::now();

        // TODO: Implement actual storage benchmarking
        // This would include:
        // - Document insertion performance
        // - Document retrieval performance
        // - Bulk operations performance
        // - Storage compaction performance

        // Placeholder implementation
        for _i in 0..std::cmp::min(options.operations, 1000) {
            let op_start = Instant::now();

            // Simulate storage operation
            tokio::time::sleep(Duration::from_micros(100)).await;

            timings.push(op_start.elapsed().as_micros() as f64 / 1000.0);
        }

        let total_time_ms = start_time.elapsed().as_millis() as u64;
        let operations = timings.len();
        let average_time_ms = if !timings.is_empty() {
            timings.iter().sum::<f64>() / timings.len() as f64
        } else {
            0.0
        };

        timings.sort_by(|a, b| a.partial_cmp(b).unwrap());
        let median_time_ms = if !timings.is_empty() {
            timings[timings.len() / 2]
        } else {
            0.0
        };

        let p95_time_ms = if timings.len() > 20 {
            timings[(timings.len() * 95) / 100]
        } else {
            average_time_ms
        };

        let p99_time_ms = if timings.len() > 100 {
            timings[(timings.len() * 99) / 100]
        } else {
            average_time_ms
        };

        let operations_per_second = if total_time_ms > 0 {
            (operations as f64 * 1000.0) / total_time_ms as f64
        } else {
            0.0
        };

        Ok(BenchmarkTypeResult {
            operations,
            total_time_ms,
            average_time_ms,
            median_time_ms,
            p95_time_ms,
            p99_time_ms,
            operations_per_second,
            success_rate: if operations > 0 {
                1.0 - (errors.len() as f64 / operations as f64)
            } else {
                0.0
            },
            errors,
        })
    }

    async fn benchmark_index_operations(
        &self,
        options: &BenchmarkOptions,
    ) -> Result<BenchmarkTypeResult> {
        // TODO: Implement index benchmarking
        // Similar structure to storage benchmarking but for index operations
        self.benchmark_storage_operations(options).await
    }

    async fn benchmark_query_operations(
        &self,
        options: &BenchmarkOptions,
    ) -> Result<BenchmarkTypeResult> {
        // TODO: Implement query benchmarking
        // Test query performance across different patterns and complexity levels
        self.benchmark_storage_operations(options).await
    }

    async fn benchmark_search_operations(
        &self,
        options: &BenchmarkOptions,
    ) -> Result<BenchmarkTypeResult> {
        // TODO: Implement search benchmarking
        // Test search performance with various query types and result sizes
        self.benchmark_storage_operations(options).await
    }

    fn format_benchmark_human(
        &self,
        results: &HashMap<String, BenchmarkTypeResult>,
        total_ops: usize,
        total_time_ms: u64,
        ops_per_sec: f64,
    ) -> Result<String> {
        let mut output = String::new();

        output.push_str("üìä Benchmark Results\n");
        output.push_str("===================\n\n");

        output.push_str("Overall Performance:\n");
        output.push_str(&format!("   Total operations: {}\n", total_ops));
        output.push_str(&format!(
            "   Total time: {:.2}s\n",
            total_time_ms as f64 / 1000.0
        ));
        output.push_str(&format!("   Throughput: {:.2} ops/sec\n\n", ops_per_sec));

        for (bench_type, result) in results {
            output.push_str(&format!("{}:\n", bench_type.to_uppercase()));
            output.push_str(&format!("   Operations: {}\n", result.operations));
            output.push_str(&format!(
                "   Average time: {:.2}ms\n",
                result.average_time_ms
            ));
            output.push_str(&format!("   Median time: {:.2}ms\n", result.median_time_ms));
            output.push_str(&format!(
                "   95th percentile: {:.2}ms\n",
                result.p95_time_ms
            ));
            output.push_str(&format!(
                "   99th percentile: {:.2}ms\n",
                result.p99_time_ms
            ));
            output.push_str(&format!(
                "   Throughput: {:.2} ops/sec\n",
                result.operations_per_second
            ));
            output.push_str(&format!(
                "   Success rate: {:.1}%\n",
                result.success_rate * 100.0
            ));
            output.push('\n');
        }

        Ok(output)
    }

    fn format_benchmark_json(
        &self,
        results: &HashMap<String, BenchmarkTypeResult>,
        total_ops: usize,
        total_time_ms: u64,
        ops_per_sec: f64,
    ) -> Result<Value> {
        Ok(json!({
            "overall": {
                "total_operations": total_ops,
                "total_time_ms": total_time_ms,
                "operations_per_second": ops_per_sec,
                "timestamp": chrono::Utc::now().to_rfc3339()
            },
            "results_by_type": results
        }))
    }

    fn format_benchmark_csv(
        &self,
        results: &HashMap<String, BenchmarkTypeResult>,
    ) -> Result<String> {
        let mut output = String::new();

        output.push_str("benchmark_type,operations,total_time_ms,average_time_ms,median_time_ms,p95_time_ms,p99_time_ms,operations_per_second,success_rate\n");

        for (bench_type, result) in results {
            output.push_str(&format!(
                "{},{},{},{:.2},{:.2},{:.2},{:.2},{:.2},{:.3}\n",
                bench_type,
                result.operations,
                result.total_time_ms,
                result.average_time_ms,
                result.median_time_ms,
                result.p95_time_ms,
                result.p99_time_ms,
                result.operations_per_second,
                result.success_rate
            ));
        }

        Ok(output)
    }
}
